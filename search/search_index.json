{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Roberts Lab Handbook!","text":"<p>Our hope is this is a one-stop locale for relevant information. You can use navigation at the left, the search function, and a few quick pages of interest are highlighted below. If you see something needing updating, you should be able to click on the pencil on each page and go directly to the source to edit, or simply submit an issue. Do not hesitate to join the Discussion.</p> <p> </p>"},{"location":"#just-getting-started","title":"Just Getting Started?","text":"<p>Be sure have a look at the following:</p> <ul> <li> <p>Read and adhere to:</p> <ul> <li> <p>Code of Conduct</p> </li> <li> <p>Lab Environment and Expectations</p> </li> </ul> </li> <li> <p>Onboarding Documentation</p> </li> <li> <p>Complete all Lab Safety Trainings</p> </li> <li> <p>Lab Communication - Digital and scheduling tools that we use to stay connected.</p> </li> </ul>"},{"location":"#ready-to-pick-up-a-pipette","title":"Ready to Pick up a Pipette?","text":"<ul> <li> <p>Lab Safety</p> </li> <li> <p>Chemical Standard Operating Protocols (SOPs)</p> </li> <li> <p>Lab Inventory - Materials, purchasing log, freezer contents, histology samples, primer database.</p> </li> <li> <p>Lab Protocols - Protocols for benchwork in the lab (e.g. RNA isolation), for commonly used instruments and software (e.g. proteomics data analysis in Skyline), and for commonly performed hatchery practices and tissue sampling.</p> </li> <li> <p>Alarm Information - Description of active alarms in the lab, how to configure, and what phone calls mean.</p> </li> </ul>"},{"location":"#sticking-to-the-keyboard","title":"Sticking to the Keyboard?","text":"<ul> <li> <p>Computing Hardware - Computing resources we have available &amp; links to help you begin learning.</p> </li> <li> <p>Agentic Coding Tools - Guide to using AI-powered coding assistants like GitHub Copilot with VS Code, web interfaces, and integration with UW Klone HPC and Raven.</p> </li> <li> <p>Lab Software - A list of software installed on lab computers.</p> </li> <li> <p>Data Management - This page is intended to document all aspects of data management, from the day-to-day, formal NGS and proteomics plans, and general archiving options.</p> </li> <li> <p>Genomic Resources - Here we try to compile genomic resources such that they are readily available and somewhat described.</p> </li> <li> <p>Digital Media - Where and how to store media including photos, videos and audio</p> </li> </ul>"},{"location":"#even-more","title":"Even More!","text":"<ul> <li> <p>Experiment Database - Database of all Roberts Lab experiments</p> </li> <li> <p>External Communication &amp; Funding - Conferences, community outreach, and funding sources that past and present lab members recommend. Also contains tips on printing posters.</p> </li> <li> <p>Lab Notebooks - Links to notebooks of current and past Roberts Lab members, as well as archived notebooks.</p> </li> <li> <p>Pubathon - Annual \"pubathon\" roster, links to and status of manuscripts.</p> </li> <li> <p>Purchasing &amp; Reimbursement - Procedure for purchases.</p> </li> </ul>"},{"location":"Agentic-Coding-Tools/","title":"Agentic Coding Tools and AI Assistants","text":"<p>AI-powered coding assistants can influence how we write and interact with code. This guide covers how we might use these tools.</p> <p>\\ General tips for Using AI Coding Assistants\\ 1. Use branches. This will protect main branch if you go off the rails.\\ 2. Provide an instructions.md and tasks.md. This will help keep agent on track</p> <p>Below we cover GitHub Copilot (w/VScode), ChatGPT, and local models</p>"},{"location":"Agentic-Coding-Tools/#github-copilot","title":"GitHub Copilot","text":"<p>GitHub Copilot is an AI-powered coding assistant that helps you write code by providing intelligent suggestions and completions.</p>"},{"location":"Agentic-Coding-Tools/#getting-started-with-github-copilot","title":"Getting Started with GitHub Copilot","text":""},{"location":"Agentic-Coding-Tools/#prerequisites","title":"Prerequisites","text":"<p>You'll need: - A GitHub account with Copilot access (available through GitHub Education) - VS Code or compatible IDE - Active internet connection</p>"},{"location":"Agentic-Coding-Tools/#checking-copilot-access","title":"Checking Copilot Access","text":"<ol> <li>Visit GitHub Copilot to check your     subscription status</li> <li>Students and educators get free access through GitHub     Education</li> </ol>"},{"location":"Agentic-Coding-Tools/#setting-up-github-copilot-with-vs-code","title":"Setting Up GitHub Copilot with VS Code","text":""},{"location":"Agentic-Coding-Tools/#1-install-the-github-copilot-extension","title":"1. Install the GitHub Copilot Extension","text":"<ol> <li>Open VS Code</li> <li>Go to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>)</li> <li>Search for \"GitHub Copilot\"</li> <li>Install the official \"GitHub Copilot\" extension by GitHub</li> <li>Optionally install \"GitHub Copilot Chat\" for conversational AI     assistance</li> </ol>"},{"location":"Agentic-Coding-Tools/#2-sign-in-and-activate","title":"2. Sign In and Activate","text":"<ol> <li>After installation, you'll see a Copilot icon in the status bar</li> <li>Click on it and select \"Sign in to GitHub\"</li> <li>Follow the authentication flow in your browser</li> <li>Return to VS Code - Copilot should now be active</li> </ol>"},{"location":"Agentic-Coding-Tools/#3-verify-installation","title":"3. Verify Installation","text":"<p>Create a new file (e.g., <code>test.py</code>) and start typing a function:</p> <pre><code>def calculate_gc_content(\n</code></pre> <p>Copilot should suggest completions in gray text.</p>"},{"location":"Agentic-Coding-Tools/#practical-use-cases-and-notes","title":"Practical use cases and notes","text":"<ul> <li> <p>Tab completion.</p> </li> <li> <p>Have it develop, refactor, buid code based on natural language     instructions to \"Agent\".</p> </li> <li> <p>There is a limit to use, so will need to keep an eye on this. Can     see on Github website.</p> <ul> <li>Aspects that influence this if you \"Ask\" versus \"Agent\" and what     model you select.</li> </ul> </li> </ul>"},{"location":"Agentic-Coding-Tools/#vs-code-copilot-commands","title":"VS Code Copilot Commands","text":"<p>In VS Code with GitHub Copilot, there are three main ways to interact with the AI assistant:</p> <p>1. Ask - Opens a chat-like panel (Copilot Chat) - Type natural language questions (\"What does this function do?\", \"How do I write a regex for emails?\") - Copilot responds with explanations, code snippets, or suggestions, but doesn't automatically change your code - Best for Q&amp;A, explanations, or guidance</p> <p>2. Agent - Runs a Copilot \"task agent\" that can perform multi-step or tool-like actions - Examples: debugging, running tests, explaining diagnostics, or walking through refactors - Agents are more goal-oriented and can combine different steps (like reading docs, analyzing code, generating edits) - Best for complex workflows where Copilot needs context beyond a single answer</p> <p>3. Edit - Lets you select code in the editor, then ask Copilot to modify it - Example: highlight a function \u2192 Edit with Copilot \u2192 \"Convert this to async/await\" - Copilot rewrites the selection directly in your file, showing a diff you can accept or reject - Best for direct code changes/refactoring</p> <p>\u2705 Rule of thumb: - Use Ask when you want to understand - Use Edit when you want to change - Use Agent when you want Copilot to do something bigger/more involved (like debugging, running tests, or analyzing errors)</p>"},{"location":"Agentic-Coding-Tools/#using-github-copilot-on-the-web","title":"Using GitHub Copilot on the Web","text":"<p>GitHub offers Copilot directly in the web interface, making it accessible even when working remotely on repositories.</p>"},{"location":"Agentic-Coding-Tools/#1-accessing-web-copilot","title":"1. Accessing Web Copilot","text":"<ol> <li>Navigate to any GitHub repository</li> <li>Press <code>.</code> (period) to open the web-based VS Code editor</li> <li>Or go to <code>github.dev/owner/repository</code> directly</li> <li>The Copilot extension should be available if you have access</li> </ol>"},{"location":"Agentic-Coding-Tools/#2-using-copilot-in-githubs-web-editor","title":"2. Using Copilot in GitHub's Web Editor","text":"<ul> <li>Code completions: Start typing and Copilot will suggest     completions</li> <li>Chat interface: Use Copilot Chat for questions and explanations</li> <li>Inline suggestions: Accept suggestions with <code>Tab</code> or reject with     <code>Esc</code></li> </ul>"},{"location":"Agentic-Coding-Tools/#3-githubcom-code-view-features","title":"3. GitHub.com Code View Features","text":"<p>When viewing code files on GitHub.com:</p> <p>- Look for the Copilot icon in file views</p> <p>- Click to get AI-powered explanations of code blocks</p> <p>- Get suggestions for improvements and alternative approaches</p>"},{"location":"Agentic-Coding-Tools/#4-assigning-copilot-issues","title":"4. Assigning Copilot Issues","text":"<p>Arguably one of the most powerful features is the ability to assign issues to Copilot.\\ Copilot will create a plan, implement on a new branch, then you (or someone else can review). If you like it, you can merge it in using a pull request.</p> <p>Copilot in action on the web</p> <p>{width=\"50%\"}</p>"},{"location":"Agentic-Coding-Tools/#using-copilot-with-uw-klone-hpc","title":"Using Copilot with UW Klone HPC","text":""},{"location":"Agentic-Coding-Tools/#remote-development-setup","title":"Remote Development Setup","text":"<ol> <li> <p>SSH with VS Code</p> <pre><code># Install Remote-SSH extension in VS Code\n# Connect to Klone through VS Code's Remote SSH\nssh your_netid@klone.hyak.uw.edu\n</code></pre> </li> <li> <p>OPTION 2 - more coming soon</p> </li> </ol>"},{"location":"Agentic-Coding-Tools/#documentation-and-tutorials","title":"Documentation and Tutorials","text":"<ul> <li>GitHub Copilot Documentation</li> <li>VS Code Copilot     Guide</li> <li>Copilot Best     Practices</li> </ul>"},{"location":"Agentic-Coding-Tools/#chatgpt","title":"ChatGPT","text":"<p>Most are familar with ChatGPT chat features (online or standalone). There is also ChatGPT codex that allows you to interact directly with a GitHub repository online or in the terminal</p>"},{"location":"Agentic-Coding-Tools/#ollama-local-models","title":"Ollama (local models)","text":"<p>There are certain use cases where having everything on your machine makes sense such as asking simple regex questions. For this installing Ollama is an option.</p>"},{"location":"Agentic-Coding-Tools/#image-generation","title":"Image Generation","text":"<p>more coming soon</p> <p>.</p>"},{"location":"Alarm-Information/","title":"Alarm Information","text":"<p>Description of active alarms in the lab, how to configure, and what phone calls mean.</p>"},{"location":"Alarm-Information/#alarm-sensaphone-model-1104","title":"Alarm: Sensaphone Model 1104","text":"<p>The Sensaphone monitors power status, room temperature, and -80<sup>o</sup>C freezer temperature limits.</p> <p>User Manual here</p> <p>Incoming Phone Number: 1-206-685-7806</p> <p>This allows for you to call the alarm and receive updates on connected alarms, as well as listen to what is happening inside of the room for 15 seconds.</p> <p>Current numbers programmed to be called in the event of an alarm state:</p> <ul> <li> <p>1: 206-866-5141 : Steven</p> </li> <li> <p>2: Sam (home number)</p> </li> <li> <p>3: 206-914-3735 :</p> </li> <li> <p>4: 206-685-3273 : Sam</p> </li> </ul> <p>Sensaphone Connections:</p> <ul> <li> <p>1: Temperature sensor for ambient temperature inside of room.</p> </li> <li> <p>2: Temperature limit sensor for Roberts Lab -80<sup>o</sup>C freezer (Normally closed trigger)</p> </li> <li> <p>3: Temperature limit sensor for former Horner-Devine Lab -80<sup>o</sup>C freezer (i.e. \"middle\" freezer. Normally closed trigger) (disabled 20240104 by SJW)</p> </li> <li> <p>4: Not hooked to anything.</p> </li> </ul> <p>Example alarm meaning and acknowledgement:</p> <p>The alarm indicates only lack of power being supplied to freezer 1.</p> <p>To acknowledge receipt of the alarm, press \"555\" at any time during the recorded message.</p> <p>This only acknowledges receipt, the alarm condition still exists.</p> <p>Sensaphone alarm sequence:</p> <p>When the power goes off, Alarm 2 waits 10 minutes, then issues an alarm status.</p> <p>It then waits 5 further minutes to begin calling numbers on the list. There is a 1 minute pause between phone number calls.</p> <p>Upshot: We currently do not know of a power outage until a minimum of 15 minutes after it happens.</p> <p>To add/change phone numbers (The sensaphone can hold 4 phone numbers):</p> <ul> <li> <p>Press Set</p> </li> <li> <p>Press Phone Number</p> </li> <li> <p>Press Number on number pad corresponding to number you would like to change</p> </li> <li> <p>Enter Phone number on number pad</p> </li> <li> <p>Press Enter</p> </li> <li> <p>Sensaphone should respond with \"Enter\" if number updated correctly.</p> </li> </ul> <p>VWR freezer alarm set points:</p> <ul> <li> <p>-60<sup>o</sup>C High</p> </li> <li> <p>-90<sup>o</sup>C Low.</p> </li> </ul>"},{"location":"Alarm-Information/#alarm-avtech","title":"Alarm: Avtech","text":"<p>Alarms:</p> <ul> <li> <p>1: FTR-213 Large Freezer [High Alarm: -20, Low Alarm: -50]. Not set up as of 2021-08-27</p> </li> <li> <p>2: FTR-209 Refrigerator [High Alarm: 15, Low Alarm: -5]</p> </li> <li> <p>3: FTR-213 Freezer [High Alarm: 5, Low Alarm: -50]</p> </li> <li> <p>4: FTR-213 Refrigerator [High Alarm: 15, Low Alarm: -5]</p> </li> </ul> <p>Current numbers programmed to be called in the event of an alarm state:</p> <ul> <li> <p>1: 206-866-5141 : Steven</p> </li> <li> <p>2: 206-685-3273 : Sam</p> </li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/","title":"Chemical SOPs","text":""},{"location":"Chemical-Standard-Operating-Protocols/#university-of-washington-lab-safety-manual","title":"University of Washington Lab Safety Manual","text":""},{"location":"Chemical-Standard-Operating-Protocols/#chemical-material-safety-data-sheets-msds-on-mychem-website","title":"Chemical Material Safety Data Sheets (MSDS) on MyChem website.","text":""},{"location":"Chemical-Standard-Operating-Protocols/#uw-hazardous-waste-online-collection-request","title":"UW Hazardous Waste Online Collection Request","text":""},{"location":"Chemical-Standard-Operating-Protocols/#rnazol-rt","title":"RNAzol RT","text":"<p>Purpose: RNAzol RT is used for separating RNA from cells.</p> <p>Specific Hazards: RNAzol RT is corrosive and harmful if inhaled.</p> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li> <p>Gloves</p> </li> <li> <p>Chemical fume hood</p> </li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for RNAzol waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual RNAzol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#isopropanol-2-propanol","title":"Isopropanol (2-propanol)","text":"<p>Purpose: Used in the precipitation of nucleic acids.</p> <p>Specific Hazards: Highly flammable - keep away from ignition sources.</p> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li> <p>Safety goggles</p> </li> <li> <p>Lab Coat</p> </li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for isopropanol waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual isopropanol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#diethylpyrocarbonate-depc","title":"Diethylpyrocarbonate (DEPC)","text":"<p>Purpose: Used as an RNase inhibitor during handling and storage of RNA.</p> <p>Specific Hazards:</p> <ul> <li>Skin irritant and harmful if inhaled.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> <li>Chemical fume hood</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for DEPC waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual DEPC should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#dnazol","title":"DNAzol","text":"<p>Purpose: DNAzol is used for separating DNA from cells.</p> <p>Specific Hazards:</p> <ul> <li>DNAzol is corrosive.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for DNAzol waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual DNAzol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#ethanol","title":"Ethanol","text":"<p>Purpose: Used in the precipitation of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Highly flammable - keep away from ignition sources.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for ethanol waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual ethanol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#phenolchloroformiaa-25241","title":"Phenol:chloroform:IAA (25:24:1)","text":"<p>Purpose: Used for purification of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Phenol:chloroform:IAA is corrosive and harmful if inhaled.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> <li>Chemical fume hood</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for phenol:chloroform:IAA waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual phenol:chloroform:IAA should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#proteinase-k","title":"Proteinase K","text":"<p>Purpose: Enzyme used to degrade proteins during DNA isolation.</p> <p>Specific Hazards:</p> <ul> <li>None.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>No requirements.</li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#resazurin-assay","title":"Resazurin assay","text":"<p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> </ul> <p>Chemical exposures:</p> <ul> <li> <p>dimethyl sulfoxide (DMSO)</p> </li> <li> <p>flammable</p> </li> <li> <p>skin irritant</p> </li> <li> <p>HyClone antibiotic antimycotic (PEN/STREP/FUNGIZONE) solution</p> </li> <li> <p>skin irritant</p> </li> <li> <p>resazurin</p> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Dispose of all waste in labelled resazurin waste container.</p> </li> <li> <p>Plate oysters (1/well; if testing in 2-3 mm spat one can use a 96 well plate and 300 ul of assay media. If using larger oysters you can use a 48 well plate and 1 mL of assay media.)    When you plate them you can do so in seawater with antibiotics and fungizone. Weigh oysters as you plate them so you can correct for weight. Alternatively, plate them, take a picture and measure area using image J.</p> </li> <li> <p>Seawater: (Volume/100 mL)</p> <ol> <li>Sterile seawater with appropriate Salinity \u2013 99 mL (Sterile Filter or Autoclave)</li> <li>100X Penn/Strep/Fungizone \u2013 1 mL</li> </ol> </li> <li> <p>Allow oysters to be in Antibiotic/Fungizone seawater for at least 1 h</p> </li> <li> <p>Make Resazurin Stock Solution (This can be frozen; 50 mg/ml)</p> </li> <li>0.5 g of resazurin sodium salt (Sigma-Aldrich Corp., St. Louis, MO)</li> <li>10 mL of distilled water</li> <li> <p>10 \u03bcL of dimethyl sulfoxide (0.1% DMSO, Sigma-Aldrich Corp., St. Louis, MO)</p> </li> <li> <p>Make Assay Media</p> </li> <li>Sterile seawater with appropriate Salinity \u2013 97.9 mL (Sterile Filter or Autoclave)</li> <li>Resazurin Stock Solution \u2013 1 mL (This can be replaced with AlamarBlue, which is used at 1.6%)</li> <li>100X Penn/Strep/Fungizone \u2013 1 mL</li> <li> <p>DMSO \u2013 100 uL</p> </li> <li> <p>Set Gain on Plate Reader</p> </li> <li>Plate 300 ul into blank well of 96 well plate and read (Excitation 530; Emission 590)</li> <li> <p>Adjust gain manually until signal is around 500. This is essential to ensure sensitivity.</p> </li> <li> <p>Add Assay Media to each well (300 ul in 96-well plate or 1 mL in 48 well plate).</p> </li> <li> <p>Read plate immediately upon adding Assay media</p> </li> <li> <p>Read plate at intervals thereafter (if you are at 30 ppt this should occur at 1, 3, and 6 h; if you are at 4 ppt you may want 6, 12, and 24h).    This allows you to show that signal increased linearly with time. If you find that you have a specific timepoint that you like for future studies you can just use that timepoint.</p> </li> <li> <p>Calculate the change in fluorescence.</p> </li> <li> <p>Calculate the change in fluorescence/area or mass.</p> </li> <li> <p>Sort oysters according to a high or low change in fluorescence/area or mass (low change will grow more quickly).</p> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2024-07-19</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#sodium-acetate","title":"Sodium acetate","text":"<p>Purpose: Used to precipitate nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Skin irritant.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li>REQUIRED:<ul> <li>Gloves</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Dispose in sink.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual sodium acetate can be disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#ethidium-bromide-etbr","title":"Ethidium bromide (EtBr)","text":"<p>Purpose: Use for staining nucleic acids in agarose gels.</p> <p>Specific Hazards:</p> <ul> <li>Mutagen and potential carcinogen.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <p>NOTE: Disposal instructions are only for dilute EtBr concentrations (&lt; 10ug/mL) that are used in the lab. Concentrations higher than this are hazardous waste and should be placed in a labeled, dedicated container.</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Dispose in sink.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves/gels should be double bagged, labelled \"non-hazardous\", and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#qiagen-kits","title":"Qiagen Kits","text":"<p>Purpose: Use for isolation of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Harmful, irritant.</li> </ul> <p>NOTE: Do not combine kit reagents with bleach (sodium hypchlorite)!</p> <p>Personal Protective Equipment:</p> <ul> <li>REQUIRED:<ul> <li>Gloves</li> </ul> </li> <li>WHEN SPLASH POTENTIAL EXISTS<ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for Qiagen Kit waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual sodium acetate can be disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Code-of-Conduct/","title":"Code of Conduct","text":"<p>All members of the lab, along with visitors, are expected to agree with the following code of conduct. We expect cooperation from all members to help ensure a safe environment for everybody.</p> <p>In our lab we:</p> <ul> <li> <p>Recognize our differences as strengths</p> </li> <li> <p>Promote continuing education in diversity, equity, and inclusion (DEI). See non-exhaustive list of DEI resources offered by UW and beyond</p> </li> <li> <p>Provide educational and emotional support for each other</p> </li> <li> <p>Provide resources for educational and emotional support</p> </li> <li> <p>Provide resources for personal and professional growth</p> </li> </ul> <p>Harassment includes offensive verbal comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, religion, sexual images in public spaces, deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of talks or other events, inappropriate physical contact, and unwelcome sexual attention.</p> <p>We do not tolerate harassment and/or discrimination of lab members in any form. Sexual language and imagery is generally not appropriate for any lab venue, including lab meetings, presentations, or discussions (however, do note that we work on biological matters so work-related discussions of e.g. animal reproduction are appropriate).</p> <p>We expect members to follow these guidelines at any lab-related event.</p> <p>If you have experienced harassment, notice that someone else is being harassed, or have any other concerns, please contact Steven Roberts  (SAFS Graduate Program Coordinator and PI) or Amy Fox (SAFS Graduate Program Adviser) immediately.</p>"},{"location":"Code-of-Conduct/#code-of-conduct-for-dei-meetings","title":"Code of Conduct for DEI Meetings","text":"<p>We are dedicated to providing a welcoming and supportive environment for all people, regardless of background, identity, physical appearance, or manner of communication. Any form of language or behavior used to exclude, intimidate, or cause discomfort will not be tolerated. This applies to all course participants (instructor, students, guests). In order to foster a positive and professional learning environment, we will be using progressive stack discussion methods and these discussion rules:</p> <p>Discussion Rules</p> <ol> <li>We will listen with the intent to understand.</li> <li>We will monitor our own air time, aiming to share the space and time so others may participate as well.</li> <li>We will respect those who do not wish to speak.</li> <li>We will use \"I\" statements as opposed to generalizations.</li> <li>We will not ask anyone to speak on behalf of any group we perceive them to identify with, or that they self-identify with.</li> <li>We will expect discomfort.</li> <li>We will resist the urge to \"fix\" others' discomfort.</li> <li>We will elevate impact above intent, and we will apologize when necessary.</li> <li>We will expect and accept non-closure. We acknowledge that these conversations may not be resolved in a single meeting.</li> <li>We will take lessons learned, but not others' stories, out of this space.</li> <li>We will not participate in ad hominem attacks.</li> </ol>"},{"location":"Code-of-Conduct/#support-resources-at-uw","title":"Support Resources at UW","text":"<ul> <li> <p>Compliance Office (title IX, ADA, Compliance)</p> </li> <li> <p>UW title IX coordinator (federal civil rights law)</p> </li> <li> <p>UW Safe Campus</p> </li> <li> <p>UW Q Center (Advocacy, mentoring, and support for queer students)</p> </li> <li> <p>Disability Resources</p> </li> <li> <p>UW Counseling Center</p> </li> <li> <p>UW Health and Wellness </p> </li> <li> <p>UW Livewell Site (wellness training site)</p> </li> </ul> <p>Modified from Titus Brown's Code of Conduct. Original source and credit: http://2012.jsconf.us/#/about &amp; The Ada Initiative. Please help by translating or improving: http://github.com/leftlogic/confcodeofconduct.com. This work is licensed under a Creative Commons Attribution 3.0 Unported License</p>"},{"location":"Computing-Best-Practices/","title":"Best Practices","text":"<p>There are a variety of hardware and software options and combinations available to you. While there are few concrete rules, here is an attempt to guide your success.</p> <p>Resources for thinking about open and reproducible scientific computing.</p>"},{"location":"Computing-Best-Practices/#practical-aspects","title":"Practical Aspects","text":"<p>Foremost, code should be written so someone else could easily run. This means they have access and can understand.</p> <p>1) Code should be in a Github repository </p> <p>2) Organize your data and code. </p> <p>Here's an example of how repos should be organized. Note that each directory contains a <code>README.md</code>, which describes the contents of each directory (and, sometimes even describes each file in that directory).</p> <p>Create a directory called <code>gitrepos</code> and then keep all subsequent repositories within it.</p> <pre><code>gitrepos$ tree\n\n.\n\u251c\u2500\u2500 &lt;GitHub username&gt;\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Project-01\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 code\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 01-FastQ-QC.Rmd\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 02-DESeq2\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 genome-features\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 raw\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 outputs\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 01-FastQ-QC\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 figures\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 02-DESeq2\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 figures\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 RobertsLab\n    \u251c\u2500\u2500 lab-website\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 resources\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n    \u2514\u2500\u2500 tusk\n        \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"Computing-Best-Practices/#working-with-git-and-rstudio-on-raven","title":"Working with Git and RStudio on Raven","text":"Your browser does not support the video tag.  <p>related - getting a Personal Access token - https://d.pr/i/lS8UAr</p>"},{"location":"Computing-Best-Practices/#papers","title":"Papers","text":"<ul> <li> <p>Good enough practices in scientific computing</p> </li> <li> <p>Packaging data analytical work reproducibly using R (and friends)</p> </li> </ul>"},{"location":"Computing-Best-Practices/#workshops","title":"Workshops","text":"<ul> <li>A crash-course in using a project-oriented workflow with Git + GitHub in scientific research</li> </ul>"},{"location":"Computing-Best-Practices/#courses","title":"Courses","text":"<ul> <li> <p>FISH546 - Bioinformatics for Environmental Sciences</p> </li> <li> <p>FISH274 - Introduction to Data Analysis for Aquatic Sciences</p> </li> <li> <p>Data Carpentry for Biologists</p> </li> </ul>"},{"location":"Computing-Hardware/","title":"Roberts Lab Computing","text":"<p>Using computers is an integral part of Roberts Lab activities. The majority of our projects take on some form of bioinformatics analysis and manipulation of large data sets. Although we don't perform any high level programming, you will need to become familiar with basic command line syntax.</p> <p>Below is a list of computing resources we have available, as well as some links to help you begin learning.</p>"},{"location":"Computing-Hardware/#accounts","title":"Accounts","text":"<p>You will need accounts with the following services in order to minimally function in the Roberts Lab:</p> <ul> <li> <p>GitHub: Needed for posting/responding to RobertsLab/resources Issues</p> </li> <li> <p>Slack: Needed for participation in the Roberts Lab Slack channels</p> </li> </ul>"},{"location":"Computing-Hardware/#computers","title":"Computers","text":"<p>You're free to use your own computer for any computing task that you wish. However, some of the computing work that you will perform will require lengthy run times. As such, we have computers available for you to use. Plus, Roberts Lab computers have better processors and much more RAM, which will allow you to keep your computer free for doing fun stuff, like reading Facebook (or scientific papers).</p>"},{"location":"Computing-Hardware/#local-computers","title":"Local Computers","text":"<p>Here is a table of computers we have in the lab that are available for use:</p> Name Operating System Location CPU Cores Memory Storage Primary Use External Drives genefish macOS Sierra (10.12), Windows 7 230 2.3 GHz Intel Core i7 Quad Core 16GB 1TB Windows 7 Enterprise (64-bit) 228 qPCR woodpecker Windows 7 Enterprise (64-bit) 209 16 64GB 2TB Bioanalyzer;NanoDrop;NanoPore;proteomics swoose Ubuntu 16.04.1/Windows 10 Pro (64-bit) 209 24 72GB 1.5TB Sam 8TB swan Windows 7 Enterprise (64-bit) Brinnon 24 72GB 500GB titrator raven Ubuntu (18.04LTS) 213 48 256GB 1TB 2 x 1TB <p>A more detailed spreadsheet, including IP addresses is below (Google Sheet). You'll need to request access from Steven or Sam.</p> <ul> <li>Roberts Lab Computers</li> </ul>"},{"location":"Computing-Hardware/#remote-services","title":"Remote Services","text":""},{"location":"Computing-Hardware/#printers","title":"Printers","text":"<p>You can send print jobs wirelessly to the Brother HL-L2395DW395DW printer in rm 209.</p> <p>Windows computers:</p> <ol> <li> <p>Download the printer driver software to your computer.</p> </li> <li> <p>Add the printer via: Settings-&gt; Devices -&gt; Printers and Scanners. You'll need to enter the IP address of the printer which is listed on the Roberts Lab Computers spreadsheet.</p> </li> </ol> <p>For Macs:</p> <ol> <li> <p>Add the printer via: System preferences-&gt; Printers and scanners. You'll need to enter the IP address of the printer which is listed on the Roberts Lab Computers spreadsheet.</p> </li> <li> <p>You may need to change the 'Use' drop down menu:</p> <ul> <li> <p>Choose 'select software'</p> </li> <li> <p>Select 'Brother HL-L2395DW CUPS'.</p> </li> </ul> </li> <li> <p>You will need to change the Protocol to 'HP Jetdirect-Socket'.</p> </li> </ol>"},{"location":"Computing-Hardware/#software","title":"Software","text":"<p>To limit clutter on this page, we've assembled a list of software currently installed on each lab computer (including our Mox node):</p> <ul> <li>Lab Software</li> </ul> <p>If you need/want any particular software installed that isn't on the list, please submit a GitHub Issue. Please consider that we prefer to use free, open-source software.</p>"},{"location":"Computing-Hardware/#reproducibility","title":"Reproducibility","text":"<p>Reproducibility is of the utmost importance to your, and the Roberts Lab, success! This means that someone (ironically, usually yourself) should be able to look at your notebook and get the same results you did by executing the same commands with the same files you used.</p> <p>The easiest and most robust means that we've found to aid in this goal is through the use of a Jupyter Notebook. A Jupyter Notebook serves as a substitute for your Terminal (i.e. the place where you normally run your commands) and documents all commands that you run in a given session.</p> <ul> <li>Review our guide for using Jupyter Notebooks</li> </ul>"},{"location":"Computing-Hardware/#learning-other-resources","title":"Learning &amp; Other Resources","text":""},{"location":"Computing-Hardware/#data-management-reproducibility-and-collaboration","title":"Data Management, Reproducibility, and Collaboration","text":"<p>Please be sure to read the article linked below. It is a great starting point on understanding how to properly manage and manipulate data.</p> <ul> <li>Good Enough Practices in Scientific Computing (Wilson et al, 2017)</li> </ul>"},{"location":"Computing-Hardware/#learning-the-basics","title":"Learning the Basics","text":"<p>If you are new to using the command line (and/or other languages like R and Python), don't worry! We all were (and still are), so we know how you feel! The links below are lessons that take you through the basics - no prior experience needed!</p> <ul> <li> <p>Software Carpentry Introduction to The Shell (command line)</p> </li> <li> <p>Software Carpentry Introduction to Python</p> </li> <li> <p>Software Carpentry Introduction to R</p> </li> </ul>"},{"location":"DEI-Resources/","title":"DEI Resources","text":""},{"location":"DEI-Resources/#support-resources-at-uw","title":"Support Resources at UW","text":"<ul> <li> <p>Title IX office (federal gender equity law)</p> </li> <li> <p>UW Safe Campus</p> </li> <li> <p>UW Q Center (Advocacy, mentoring, and support for queer students)</p> </li> <li> <p>Disability Resources</p> </li> <li> <p>UW Counseling Center</p> </li> <li> <p>UW Health and Wellness</p> </li> </ul>"},{"location":"DEI-Resources/#groups-and-committees","title":"Groups and Committees","text":"<ul> <li> <p>GO-MAP: Supporting Graduate Students of Color at the University of Washington https://grad.uw.edu/equity-inclusion-and-diversity/go-map/</p> </li> <li> <p>SAFS DEI Committee: https://fish.uw.edu/about/diversity-equity-and-inclusion/safs-equity-inclusion-committee/</p> <ul> <li>SAFS DEI Committee GitHub for suggested action items: https://github.com/OARS-SAFS/DEI/issues</li> </ul> </li> <li> <p>SAFS DEI Slack channel: https://join.slack.com/t/safs-community/shared_invite/zt-uzytnche-1JagEpn8NxUEm6~tTi2izg (navigate to DEI page) </p> </li> <li> <p>SAFS 360: https://fish.uw.edu/about/diversity-equity-and-inclusion/safs-360/</p> </li> <li> <p>College of the Environment Community Equity Initiative: Organizational information here </p> </li> <li> <p>College of the Environment DEI Task Force: https://environment.uw.edu/about/diversity-equity-inclusion/diversity-equity-and-inclusion-task-force/</p> </li> <li> <p>UW Postdoc Diversity Alliance: https://sites.uw.edu/uwpda</p> </li> <li> <p>Peaks and professors club: hike with UW faculty members to network while enjoying the outdoors.</p> <ul> <li>Facebook page: https://www.facebook.com/peaksandprofessorsuw/</li> <li>Send a request to join the mailing list: peaksandprofessorsuw@gmail.com</li> </ul> </li> <li> <p>List of organizations that are striving to bring more diversity to the outdoors. https://web.archive.org/web/20220523105055/https://www.adventure-journal.com/2020/06/these-orgs-could-use-your-help-to-bring-more-diversity-to-the-outdoors/</p> </li> <li> <p>The College of the Environment communities often consist of people who enjoy and spend time in nature. Gatekeeping \u201coutdoorsy-ness\u201d is a serious issue that often excludes women, people of color, lower income individuals, and more. This can often make it difficult to participate in casual conversations at work/school or after-work/weekend activities, which can create a feeling of exclusion from the community as a whole.</p> </li> </ul>"},{"location":"DEI-Resources/#uw-centers","title":"UW Centers","text":"<ul> <li> <p>Kelly Ethnic Cultural Center. ECC frequently has talks, film showings, and more that are centered around DEI issues or celebrating different cultures. See there website for upcoming events: https://depts.washington.edu/ecc/event/</p> </li> <li> <p>Center for International Relations &amp; Cultural Leadership Exchange (CIRCLE) https://www.washington.edu/circle/</p> <ul> <li>Events calendar: https://www.washington.edu/circle/calendar/</li> </ul> </li> </ul>"},{"location":"DEI-Resources/#indigenous-resources-and-land-acknowledgement","title":"Indigenous Resources and Land Acknowledgement","text":"<ul> <li>Text your zip code or your city and state (separated by a comma) to (907) 312-5085 and a bot will respond with the names of the Native lands that correspond to that region</li> <li>Duwamish Tribe Land Acknowledgement</li> <li>\u00e2pihtawikosis\u00e2n Beyond Territorial Acknowledgements</li> <li>U.S. Department of Arts and Culture - Honor Native Land:  A Guide and Call to Acknowledgement</li> </ul>"},{"location":"DEI-Resources/#training-continuing-education","title":"Training &amp; Continuing Education","text":"<ul> <li> <p>Various DEI trainings available offered by UW:  https://hr.uw.edu/diversity/dei-related-trainings/pod-trainings/</p> <ul> <li>These do cost money, but department budget codes are available to offset that cost. If you're interested contact the SAFS administrator Jonas Louie at jinl@uw.edu for budget code and sign up information.</li> </ul> </li> <li> <p>\"Strategies to address unconscious bias\" https://diversity.ucsf.edu/resources/strategies-address-unconscious-bias</p> </li> <li> <p>\"Eight tactics to identify and reduce your implicit biases\" https://www.aafp.org/journals/fpm/blogs/inpractice/entry/implicit_bias.html</p> </li> <li> <p>Implicit bias test from Harvard: https://implicit.harvard.edu/implicit/takeatest.html</p> </li> </ul>"},{"location":"DEI-Resources/#articles-and-reading","title":"Articles and Reading","text":"<ul> <li> <p>Interrupting Bias in Academic Settings Feb 2017. From the National Center for Women &amp; Information Technology. \u201cUse this resource to help you practice ways to interrupt bias in real-life situations.\"</p> </li> <li> <p>Black Scientists Call Out Racism in Their Institutions June 2020. \u201cBlack scientists and students are sharing their experiences on Twitter of being dismissed and discriminated against in academia using the hashtag #BlackintheIvory.\u201d</p> </li> <li> <p>The science divide: Why do Latino and black students leave STEM majors at higher rates? May 2019. \u201cIf there\u2019s demonstrated, strong interest in STEM among black and Latino youth, why would you see higher departure rates for these students?\u201d the professor said. \u201cIt\u2019s not about interest or academic ability. So what causes this?\u201d</p> </li> <li> <p>Facilitating Critical Conversations With Students [PDF] December 2019. \u201c It\u2019s a conversation that explores the relationships between identity and power, that traces the structures that privilege some at the expense of others, that helps students think through the actions they can take to create a more just, more equitable, world.\u201d</p> </li> </ul>"},{"location":"DEI-Resources/#bimonthly-diversity-equity-and-inclusion-meetings","title":"Bimonthly Diversity, Equity and Inclusion Meetings","text":"<p>Biweekly DEI meetings (~1 hour) provide a space to learn, discuss, and engage in initiatives that further lab members' understanding about the institutionalized oppression present in academia. Example activities include discussing articles read prior to the meeting, tackling action items to improve DEI in the lab and/or department, and more. See log of topics.</p> <p>Code of Conduct for DEI Meetings</p> <p>We are dedicated to providing a welcoming and supportive environment for all people, regardless of background, identity, physical appearance, or manner of communication. Any form of language or behavior used to exclude, intimidate, or cause discomfort will not be tolerated. This applies to all course participants (instructor, students, guests). In order to foster a positive and professional learning environment, we will be using progressive stack discussion methods and these discussion rules:</p> <p>Discussion Rules</p> <ol> <li>We will listen with the intent to understand.</li> <li>We will monitor our own air time, aiming to share the space and time so others may participate as well.</li> <li>We will respect those who do not wish to speak.</li> <li>We will use \u201cI\u201d statements as opposed to generalizations.</li> <li>We will not ask anyone to speak on behalf of any group we perceive them to identify with, or that they self-identify with.</li> <li>We will expect discomfort.</li> <li>We will resist the urge to \u201cfix\u201d others\u2019 discomfort.</li> <li>We will elevate impact above intent, and we will apologize when necessary.</li> <li>We will expect and accept non-closure. We acknowledge that these conversations may not be resolved in a single meeting.</li> <li>We will take lessons learned, but not others\u2019 stories, out of this space. </li> <li>We will not participate in ad hominem attacks.</li> </ol>"},{"location":"Data-Management/","title":"Data Management","text":"<p>This page is intended to document all aspects of data management, from the day-to-day, formal NGS and proteomics plans, and general archiving options. Inspiration for this has been provided by Tim Essington and Gordon Holtgrieve who have developed similar documentation.</p> <p>Data must be:</p> <ol> <li> <p>Adequately described via metadata.</p> </li> <li> <p>Managed for data quality.</p> </li> <li> <p>Backed up in a secure manner.</p> </li> <li> <p>Archived in an easily reproducible format.</p> </li> </ol>"},{"location":"Data-Management/#metadata","title":"Metadata","text":"<p>All research data must be accompanied with a thorough description of that data from the beginning of the work. Metadata describes information about a dataset, such that a dataset can be understood, reused, and integrated with other datasets. Information described in a metadata record includes where the data were collected, who is responsible for the dataset, why the dataset was created, and how the data are organized.   </p>"},{"location":"Data-Management/#data-quality-standards","title":"Data Quality Standards","text":"<p>Students must take care that protocols and methods are employed to ensure that data are properly collected, handled, processed, used, and maintained, and that this process is documented in the metadata.</p>"},{"location":"Data-Management/#backup-and-storage","title":"Backup and Storage","text":"<p>Primary should be stored in several locations with canonical versions on Gannet (see below).</p> <p>Data, including intermediate analysis, needs to have a url. This most often means it will live on a Network Attached Storage Device (NAS; aka a server).</p>"},{"location":"Data-Management/#gannet","title":"Gannet","text":"<p>Gannet is a Synology RS3618xs NAS :</p> <ul> <li>RS3618xs uses 16TB HDDs (n = 36)</li> </ul> <p>Data on Gannet is backed up in the following ways:</p> <ul> <li> <p>Synology Hybrid RAID</p> <ul> <li>Mirrors data across HDDs, which reduces total storage capacity by 50%</li> <li>Allows for up to two concurrent HDD failures before data loss occurs</li> </ul> </li> </ul>"},{"location":"Data-Management/#gannet-data-structure","title":"Gannet Data Structure","text":"<ul> <li> <p>Each user has a dedicated, publicly accessible folder on Gannet. This is where you will store your data.</p> </li> <li> <p>Gannet has two storage volumes:</p> </li> <li> <p>Volume 2 (<code>/volume2/web/</code>) Main storage volume. This is where you will store your data.</p> </li> <li>Volume 1 (<code>/volume2/web/v1_web -&gt; /volume1/v1_web/</code>): Symlinked to the main storage volume.</li> </ul>"},{"location":"Data-Management/#daily-data-on-gannet","title":"Daily Data on Gannet","text":"<p>Using the Gannet NAS to store your data (web interface):</p> <ol> <li>Ask Steven or Sam to generate a user account for you. A folder will be created for you in: <code>gannet/web/</code> Ask Steven/Sam for the name of the folder, as well as your username and password.</li> <li>Upload data to your Gannet web folder:<ol> <li>Navigate to http://gannet.fish.washington.edu/</li> <li>Click on <code>Web Browser login</code>.<ol> <li>If it's your first time visiting this page, your browser will present you with a warning about an insecure site or bad certificate. That's OK. Click on the option to add an exception for this site.</li> </ol> </li> <li>Enter username and password. (NOTE: If it's your first time accessing your account, please change your password by clicking on the silhouette in the upper right corner, then \"Personal\" in the dropdown menu).</li> <li>Navigate to File Station &gt; web &gt; your_folder (If you don't see the File Station icon, click on the icon of four squares in the upper left corner and select File Station from the subsequent menu).</li> <li>Click-and-drag files from your computer to your <code>gannet/web</code> folder.</li> </ol> </li> </ol> <p>Using the Gannet NAS to store your data (command line): 1. Open a terminal window. 2. Use the following command to connect to Gannet: <pre><code>ssh &lt;username&gt;@gannet.fish.washington.edu\n</code></pre> 3. Enter your password when prompted. 4. Navigate to your folder: <pre><code>cd /volume2/web/&lt;your_folder&gt;\n</code></pre> 5. Use the following command to upload files: <pre><code>rsync -avP &lt;local_file&gt; &lt;username&gt;@gannet.fish.washington.edu:/volume2/web/&lt;your_folder&gt;\n</code></pre></p> <p>Files that you have uploaded to your_folder are publicly viewable: http://gannet.fish.washington.edu/your_folder</p> <p>You can use the URLs for your files for linking in your notebook.</p> <p>IMPORTANT!</p> <p>All folders need to contain a readme file.</p> <p>The readme files should be plain text (i.e. do not create/edit the file with a word processor like Microsoft Word or LibreOffice Writer) and should describe the contents of the folder. If there are directories in the same folder as your readme file, the directory names should be listed and a brief description of their contents should be provided.</p> <p>Please refrain from using any non alpha-numeric (including spaces) in file and folder names.</p>"},{"location":"Data-Management/#ngs-data-management-plan","title":"NGS Data Management Plan","text":"<p>Raw Data</p> <ol> <li> <p>As sequencing facility provides data, files are downloaded to our local NAS (owl), in the correct species subdirectory within <code>nightingales</code>.  http://owl.fish.washington.edu/nightingales/</p> </li> <li> <p>MD5 checksums are generated and compared to those supplied by the sequencing facility.</p> <ol> <li>Append the generated MD5 checksums to the <code>checksums.md5</code> file. If that file does not yet exist, create it, and add the generated checksums to the new <code>checksums.md5</code> file.</li> </ol> </li> <li> <p>The Nightingales Google Spreadsheet is updated.</p> <ol> <li>Each library (i.e. each sample with a unique sequencing barcode) is entered in its own row.</li> <li><code>SeqID</code> is the base name of the sequencing file (i.e. no file extensions like \".fq.gz\" or \".gz\")</li> <li>Each library receives a unique, incremented <code>Library_ID</code> number.</li> <li>Each library receives a <code>Library_name</code>; this may or may not be unique.</li> <li><code>SeqSubmissionDate</code> and <code>SeqReceiptDate</code> should be entered in yyyymmdd format. </li> </ol> </li> </ol> <p>Taxa Representation in Nightingales </p> <p></p> <p>Backup </p> <ul> <li> <p>The Google Docs spreadsheet Nightingales Google Spreadsheet is backed up on a regular basis by downloading tab-delimited file and pushing to LabDocs Repository, with the file name <code>Nightingales.tsv</code></p> </li> <li> <p><code>owl/nightingales</code> is automatically backed up to two locations, both managed by Synology apps:</p> </li> <li> <p>Amazon Glacier: Backup task occurs weekly on Mondays at 00:00.</p> </li> <li> <p>CloudSync to UW Google Drive: Backup occurs in real-time any time new files, or changes to existing files, are detected.</p> </li> </ul> <p>SRA Upload</p> <ul> <li>Sam will upload all high-throughput sequencing data to the NCBI Sequence Read Archive (SRA). Once submitted, the BioProject accession and a link to the NCBI BioProject will be added to the <code>SRA</code> column in the Nightingales Google Spreadsheet.</li> </ul>"},{"location":"Data-Management/#proteomics-data-management-plan","title":"Proteomics Data Management Plan","text":"<p>Raw Data</p> <ol> <li> <p>As sequencing facility provides data, files are downloaded to our local NAS (owl), in the root <code>phainopepla</code> directory.  http://owl.fish.washington.edu/phainopepla/ These data are organized by species, then by mass spectrometer run date (e.g. YYYY-MM-DD). For each run date, all <code>RAW</code> files (including blanks, sample, and QC files) should be included in the directory with their original names. Inside of the YYYY-MM-DD directory there should be a Readme file with the following information: Description of each file (eg. treatment, blank, etc), experimental design, link to more information.</p> </li> <li> <p>The Spreadsheet is then updated. Each \"mass spectrometer run date\" will be a new row in the sheet.</p> </li> </ol>"},{"location":"Data-Management/#histology-data-management-plan","title":"Histology Data Management Plan","text":"<p>1) Before histology cassettes are sent off for processing, fill out the Histology-databank with all relevant information at the sample(tissue) level. Reserve space for blocks and slides by adding block-location and slide-location information. Each sample should have a <code>unique-sample-ID</code> which is:</p> <ul> <li><code>experiment-date_organism-label_tissue</code></li> </ul> <p>2) After histology blocks are returned, photograph blocks and slides and label such that the location of each sample(tissue) can be readily understood.</p> <p>3) Image each sample(tissue). Use the following convention for saving images:</p> <ul> <li> <p>`[FULLTIMESTAMP]-[unique-sample-ID]-[magnification].jpeg</p> </li> <li> <p>e.g. <code>20180924-angasi013-10x.tif</code></p> </li> </ul> <p>All images should be stored in the proper species directory at http://owl.fish.washington.edu/hesperornis/</p>"},{"location":"Data-Management/#data-archiving","title":"Data Archiving","text":"<p>The goal for data archiving is to make your research easily understandable and reproducible in the future. It is therefore incumbent upon the researcher that, by the end of a project, care and effort is given to providing a highly organized and traceable accounting of the research that is archived in perpetuity.  At a minimum, this archive should include: raw and full processed data, complete metadata, all computer code, and any research products (manuscripts, published articles, figures, etc.). You will find that creating a usable data archive is much easier to do as you go, rather than waiting until the end of your project!</p>"},{"location":"Data-Management/#options-include","title":"Options include","text":"<ul> <li>GitHub -&gt; Zenodo.     </li> <li>Figshare</li> <li>UW ResearchWorks</li> <li>Open Science Framework</li> </ul>"},{"location":"Data-Management/#easy-file-upload-for-collaborators","title":"Easy file upload for Collaborators","text":"<p>Finally, data will be most usable if it is as flexible as possible.  So an excel spreadsheet with different information on different tabs is not very flexible.  Much better to have a text file, with the data in \u201clong form\u201d.  This means rather than have a ton of columns, have a ton of rows.</p> <p>see   Broman KW, Woo KH. (2017) Data organization in spreadsheets. PeerJ Preprints 5:e3183v1 https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989</p>"},{"location":"Digital-Media/","title":"Digital Media","text":"<p>Media including photos, videos and audio can really fall into two categories. In some instances they might fall under data. In that case treat them as such and follow Data Management guidelines. Another category might be considered candids.</p> <p>Candid media should be place in this Team Drive. If you need access please submit an issue. This has been developed in order to populate social media platforms, grant reports, and otherwise share in the adventures in science.</p>"},{"location":"Digital-Media/#videos","title":"Videos","text":""},{"location":"Digital-Media/#hatchery-and-field-work","title":"Hatchery and Field Work","text":"<p>Laura takes us through the process of screening Olympia oyster larvae.</p> <p>Tour of the Chew hatchery and Laura's research given by Beyer.</p> <p>Research Summary video highlighting our work with Geoduck clams and environmental conditioning.</p> <p>Release of sablefish with a satellite tag.</p>"},{"location":"Digital-Media/#how-to","title":"How-to","text":""},{"location":"Digital-Media/#defenses","title":"Defenses","text":""},{"location":"Digital-Media/#miscellany","title":"Miscellany","text":""},{"location":"Environment-and-Expectations/","title":"Environment and Expectations","text":""},{"location":"Environment-and-Expectations/#lab-environment","title":"Lab Environment","text":"<p>The purpose of the lab group is to grow as scientists and as people. Our intent is to maintain an open, welcoming, and communicative environment among all lab members. You are encouraged to approach any member of the lab with questions or issues related to science or otherwise. As the old idiom goes, \"there are no stupid questions\". It is okay to make mistakes, but it is not okay to hide your mistakes from others - addressing them and learning from them is how we grow as scientists. Similarly, if you disagree with lab members on any issue you are encouraged to engage with them directly.</p> <p>To foster the intended lab environment, everyone must follow the code of conduct. Lab members are also expected and encouraged to participate in trainings, committees, and self or group education to strive towards a more equitable, inclusive, and just lab and departmental community. Here is a non-exhaustive list of DEI resources available to you at UW and beyond: DEI-Resources. Additionally, all members of the lab meet to discuss project progress, diversity, equity, and inclusion issues, and to get help from others. Here is an example of our meeting schedule.</p> <p>NOTE: You are expected to attend all lab meetings, within reason. Science hour is optional, but highly encouraged!</p> <ul> <li> <p>Biweekly Project Progress Lab Meetings (1.5 hour): All members discuss their activities since the last meeting, planned activities for the next two weeks, and to get help from lab members on project-related issues. GOALS are set each meeting and reported upon.</p> </li> <li> <p>Weekly Science Hour (Fridays): A casual meeting to hang out, and sometimes tackle science issues/questions with the \"hive mind\" - e.g. we spend time debugging a script, interpreting a statistical analysis, interpreting/providing feedback on figures, or discuss science concepts that require more time than is available during the biweekly lab meetings.</p> </li> <li> <p>Practice presentation meetings (occasionally): When members prepare a presentation for a conference or symposium (etc.), they are expected to give a practice presentation to the lab group. For a 15 minute presentation, we schedule at least 1hr to deliver it, then receive lots of feedback. This exercise is invaluable, and greatly improves presentations.</p> </li> <li> <p>Targeted Topics (occasionally): When members determine a topic where is makes sense to meet as a group the initiate the meeting.</p> </li> </ul>"},{"location":"Environment-and-Expectations/#roberts-mentoring-approach","title":"Roberts Mentoring Approach","text":"<p>My mentoring approach will be somewhat specific per person, however generally I view my role as providing you the resources to succeed in your educational experience. There will be regular lab meetings where we primarily address any challenges members might be having while reaching their goals. Goals are important and I will working with you in developing long-term goals, however you will need to develop monthly goals. You might not always achieve them, but this helps you stay focused. Beyond lab meetings we have established a number means of communication.</p> <p>Utmostly important as you get into research, is to communicate issues and challenges. I will work with you to address these, though often we might find that the most effective solutions are resources outside of the lab.</p> <p>I will provide honest feedback in an effort to push you to be your best. This will include pushing you to consistently be stepping back to re-evaluate your work in a larger context, and consider areas of improvement.</p> <p>The predominantly white and cis/het, amongst other factors, community at SAFS may not meet everyone's needs. For this reason, you are encouraged to seek mentorship and community in the way that is best for you.</p>"},{"location":"Environment-and-Expectations/#personnel-expectations","title":"Personnel Expectations","text":""},{"location":"Environment-and-Expectations/#research-methods","title":"Research Methods","text":"<p>A lot of our research involves computational analysis of large, novel datasets. You will need to be competent in computing skills including basics of bash and R. A common task you should be able to accomplish is installing and running Blast on your own computer. You should also be familiar with Jupyter Notebooks. As might be evident, we using GitHub extensively and you will be using this to document code and data (and everything else).</p> <p>Electronic Open Lab Notebooks are also central to the lab. You are required to document your activity in real time. This will include not only benchwork and computational work, but also reflections, questions, and monthly goals.</p> <p>Writing. Always be doing it. Do not wait until you have completed a project but rather write the methods as you carry them out (or preferably before). This goes hand in hand with the lab notebook. Document your work in a detail that you and a stranger can completely reproduce it in 5 years.</p>"},{"location":"Environment-and-Expectations/#graduate-students","title":"Graduate Students","text":"<p>Graduate school is not easy, and not for everyone. Graduate school will be very challenging, and for most, very rewarding. Graduate school is not a job where you check-in and check-out each day, but rather an educational endevour where you gain a deep understanding of a scientific area and complete your tenure by contributing a valuable research product, that substantially advances knowledge. Understanding this fact might help you deal with the challenges and frustrations you will face.</p> <p>There is a lot going on during your graduate education. Staying organized and not overwhelmed is key. In the same vein, time-management is key. There are several strategies for this. I suggest reading \"Getting Things Done\". Finding time outside of lab to recharge your mind and body is essential.</p> <p>Graduate students are expected to meet every two weeks with Steven, having a clear agenda and goals for the meeting. This should include your action items for the next two weeks, as well as self-assessment on performance for the prior two weeks. All of this information should be published in your lab notebook no less than 24 hours prior to the meeting.</p>"},{"location":"Environment-and-Expectations/#expectations-on-performance","title":"Expectations on Performance","text":"<p>Graduate students will complete a Graduate Research Plan that will be revisited on a quarterly basis.</p> <p>This document is in part meant to delineate expected progress on thesis research. If there is inadequate progress made on thesis research (determined in part by entire committee when in place), action will be taken at the department level (commonly a written warning with specific expectations outlined). If targets are not reached, the situation will be reported to the UW Graduate School where a formal probation period could be initiated.</p> <p>Research Credit Hours: The following information regarding research credit hours should be confirmed with SAFS Graduate Program Advisor, but typically a graduate student will need to be signed up for at least 10 credit hours during the academic year. If these are not graded courses they should be research credit hours. Note, with the exception of summer, students are limited to a maximum of 10 credits per quarter of any combination of courses numbered 600, 700, or 800. Unsatisfactory progress on thesis research will result in no credit (NC) or possibly and/or a low grade for research credit hours. This will result in a student being placed on academic probation.</p> <p>Graduate Student stipends are paid in a variety of manners. There are often specific responsibilities associated with this. If you are a TA you are expected to perform duties set forth for the position no more than 20 hours a week. If you are asked to perform duties that exceed 20 hours a week you need to inform Professor Roberts ASAP.</p> <p>Another common form of stipend payment is a RA. A RA can be associated with a faculty grant or certain funds from SAFS are distributed as an RA. Responsibilities as set forth as part of a RA require 20 hours of effort per week. If you are unclear of responsibilities of a RA for any given quarter please contact Professor Roberts ASAP.</p> <p>To simplify efficient documentation of progress (useful for grant reporting) students on RAs will need summarize activity every two weeks when funded on an RA. Please use this form: https://forms.gle/ePCTJvBo2XnazGf47</p> <p>Prospective graduate students interested in graduate school and joining the lab, please submit this form. Please feel free to contact current graduate students for more information.</p>"},{"location":"Environment-and-Expectations/#undergraduate-students","title":"Undergraduate students","text":"<p>I enjoy having the opportunity to provide motivated undergraduate students with a chance to gain hands-on lab experience and get a better understanding of an array of approaches that can be used to study aquatic organisms. I feel this is an important component of your education. Depending on your status (i.e. intern, work-study, course credit, capstone etc.) there will likely be specific details that will need to be discussed.</p> <p>Undergraduates must review and sign the Undergraduate Commitment Contract prior to starting in the lab.</p>"},{"location":"Environment-and-Expectations/#postdocs","title":"Postdocs","text":"<p>Postdocs should complete an Individual Development Plan (e.g. https://myidp.sciencecareers.org/) that should be reviewed and updated on a quarterly basis.</p>"},{"location":"Experiment-Database/","title":"Experiment Database","text":"<p>Holding place for a database / link to database of all Roberts Lab experiments </p> <p>Proposed fields for database:  - Experiment Dates  - Species  - Very short description  - Project lead / contact person  - Samples collected &amp; status of samples - Type of data produced with links to where it's stored  - Status of experiment / project  - Products (i.e. papers, presentations, other write-ups)  </p> <p>Preliminary database is located in a Google Spreadsheet in the Roberts Lab Google Drive </p>"},{"location":"External-Communication-and-Funding/","title":"External Communication","text":"<p>This is a living document that lists conferences, community outreach, and funding sources that past and present lab members recommend.  </p>"},{"location":"External-Communication-and-Funding/#conferences-pertinent-travel-grants","title":"Conferences &amp; pertinent travel grants","text":"<ol> <li> <p>National Shellfisheries Association (NSA) annual meeting. March, USA, location changes annually.  Travel grant: NSA Student Endowment Fund </p> </li> <li> <p>Pacific Shellfish Growers' Association / Pacific Coast NSA chapter annual meeting. September, PNW. Travel grant: Apply for travel award upon submitting poster/presentation abstract. </p> </li> <li> <p>Aquaculture America February, USA, location changes annually. </p> </li> <li> <p>Salish Sea Ecosystem Conference. April, Washington or British Columbia. </p> </li> <li> <p>Western Society of Naturalists. October/November, U.S. west coast. </p> </li> <li> <p>Association for the Sciences of Limnology and Oceanography (ASLO) Aquatic Sciences. February/March, international. </p> </li> <li> <p>Ecological Society of America. August, USA, location changes annually. </p> </li> <li> <p>American Fisheries Society. Various subchapter meetings. </p> </li> <li> <p>WA Sea Grant Conference for Shellfish Growers. March, Puget Sound (usually Alderbrook Resort).  </p> </li> <li> <p>Plant and Animal Genome Conference. January, San Diego. </p> </li> </ol>"},{"location":"External-Communication-and-Funding/#general-conference-funding-for-uw-students","title":"General conference funding for UW Students:","text":"<ul> <li>College of the Environment Student Travel Award: $750 for North America, $1,000 for international. Can only receive once during degree. Post-docs are eligible.</li> <li>UW Graduate School: $300 for domestic, $500 for international.  SAFS provides matching funds.</li> <li>Fisheries Interdisciplinary Network of Students: Funding for SAFS-affiliated graduate students for travel and/or poster printing and publication costs. Awards preferentially given to individuals who have not received it previously and those that are involved in the department.</li> </ul>"},{"location":"External-Communication-and-Funding/#posters","title":"Posters","text":"<ul> <li>How to print a poster</li> <li>Traditional poster example</li> <li>Poster 2.0 example</li> </ul>"},{"location":"External-Communication-and-Funding/#community-outreach-education","title":"Community Outreach &amp; Education","text":"<ul> <li>Students Explore Aquatic Sciences: SEAS is an outreach program at UW. The program provides project-based learning activities, free of charge, for K-12 students in the Seattle area.</li> <li>Ocean Inquiry Project </li> </ul>"},{"location":"External-Communication-and-Funding/#fellowships-research-grants","title":"Fellowships &amp; Research Grants","text":"<p>The following are sources of funding, and people in the Roberts Lab who previously received them (with year)  </p>"},{"location":"External-Communication-and-Funding/#graduate-student-funding","title":"Graduate Student Funding","text":"<p>National Science Foundation Graduate Research Fellowship Program (NSF GRFP) - 3 years of stipend funding - Deadline: ~October annually  - Prospective grad students can apply  - Recipients: Laura Spencer (2016), Yaamini Venkataraman (2018) </p> <p>UW College of the Environment Hall Conservation Genetics Research Fund - $6,000 to be used towards within one year of award. - Deadline: ~March annually  - Recipients: James Dimond (2016), Laura Spencer (2017), Yaamini Venkataraman (2017)</p> <p>National Shellfisheries Association research grants:    - The Melbourne R. Carriker Student Research Grant, $1,250. Recipients: Laura Spencer (2017)   - Michael Castagna Student Grant for Applied Research, $1,250   - George R. Abbe Student Research Grant, $1,250 </p> <p>Libbie H. Hyman Memorial Scholarship for undergrads also  - $1,840 towards invertebrate coursework or research at a field station (e.g. Friday Harbor Labs). Laura Spencer (2017)</p> <p>Other Field Station Research Grants for undergrads also</p>"},{"location":"External-Communication-and-Funding/#postdoc-funding","title":"Postdoc Funding","text":""},{"location":"External-Communication-and-Funding/#grants-for-study-abroad-internships","title":"Grants for study abroad / internships","text":"<ul> <li>NSF Graduate Research Opportunity Worldwide (GROW); only available to NSF GRFP recipients. Recipients: Laura Spencer (2018) </li> <li>Australia-Americas PhD Research Internship program. Recipients: Laura Spencer (2018) </li> </ul>"},{"location":"Genomic-Resources/","title":"Genomic Resources","text":"<p>Here we try to compile genomic resources such that they are readily available and somewhat described. An effort will be made to keep respective index files alongside so these files can be directly used in IGV etc.</p> <p>Related Resources - Archived Versions of this page - 091319;</p> <ul> <li>Nightingales (Google Sheet) : Database of all raw high-throughput sequencing data</li> </ul>"},{"location":"Genomic-Resources/#acropora-pulchra","title":"Acropora pulchra","text":"<ul> <li> <p>Apulchra-genome.fa (504MB): <code>https://gannet.fish.washington.edu/gitrepos/urol-e5/timeseries_molecular/D-Apul/data/Apulchra-genome.fa</code></p> </li> <li> <p>MD5 = <code>1c500bff4aa07f8a097adf79260bf141</code></p> </li> <li> <p>FastA index (<code>samtoold faidx</code>)</p> <ul> <li>Apulchra-genome.fa.fai</li> </ul> </li> <li> <p>Origin of this genome comes from this GitHub Issue.</p> </li> </ul>"},{"location":"Genomic-Resources/#bisulfite-genome","title":"Bisulfite Genome","text":"<ul> <li> <p>Bisulfite_Genome.tar.gz (1.3GB): <code>https://gannet.fish.washington.edu/gitrepos/urol-e5/timeseries_molecular/D-Apul/data/Bisulfite_Genome.tar.gz</code></p> </li> <li> <p>MD5 = <code>399a196fc1dfc202a9f084a8fb342dd9</code></p> </li> <li>Gzipped tarball of bisulfite genome for use with Bismark.</li> <li>Creation details here.</li> </ul>"},{"location":"Genomic-Resources/#chionoecetes-bairdi","title":"Chionoecetes bairdi","text":"<ul> <li>cbai_genome_v1.01.fasta (18MB)<ul> <li>MD5 = <code>5a08d8b0651484e3ff75fcf032804596</code></li> <li>BUSCOs: <code>C:0.4%[S:0.3%,D:0.1%],F:0.2%,M:99.4%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_genome_v1.01.fasta.fai</li> </ul> </li> <li>Assembly from 20200923<ul> <li>Q7-filtered NanoPore data. Includes Hematodinium-infected sample.</li> <li>Subset of <code>cbai_genome_v1.0.fasta</code> with contigs &gt;1000bp</li> </ul> </li> </ul> </li> <li>cbai_genome_v1.0.fasta (19MB)<ul> <li>MD5 = <code>2f3b651bb0b875b0287e71e315cad59a</code></li> <li>BUSCOs: <code>C:0.4%[S:0.3%,D:0.1%],F:0.3%,M:99.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_genome_v1.0.fasta.fai</li> </ul> </li> <li>Assembly from 20200917<ul> <li>Q7-filtered NanoPore data. Includes Hematodinium-infected sample. Assembly Stats Table (Google Sheet) RNA-seq sample list</li> </ul> </li> </ul> </li> <li>cbai_transcriptome_v4.0.fasta<ul> <li>MD5 = <code>6450d6f5650bfb5f910a5f42eef94913</code></li> <li>BUSCOs: <code>C:73.8%[S:45.8%,D:28.0%],F:7.9%,M:18.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v4.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW BLASTx against NCBI C.opilio genome.</li> </ul> </li> <li>cbai_transcriptome_v3.1.fasta<ul> <li>MD5 = <code>aeec8ffbf8fa44fb1750caee6abaf68a</code></li> <li>BUSCOs: <code>C:96.5%[S:40.3%,D:56.2%],F:2.2%,M:1.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v3.1.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with non_Alveolata. Derived from <code>cbai_transcriptome_v3.0.fasta</code></li> </ul> </li> <li>cbai_transcriptome_v3.0.fasta<ul> <li>Assembly from 20200518</li> <li>MD5 = <code>5516789cbad5fa9009c3566003557875</code></li> <li>BUSCOs: <code>C:97.6%[S:39.1%,D:58.5%],F:1.6%,M:0.8%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v3.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with no taxonomic filter.</li> </ul> </li> <li>cbai_transcriptome_v2.1.fasta<ul> <li>MD5 = <code>1fb788175f9bb7cd5145370a399ae857</code></li> <li>BUSCOs: <code>C:98.3%[S:25.2%,D:73.1%],F:1.4%,M:0.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v2.1.fasta.fai</li> </ul> </li> <li>BLASTx annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with non_Alveolata. Derived from <code>cbai_transcriptome_v2.0.fasta</code></li> </ul> </li> <li>cbai_transcriptome_v2.0.fasta<ul> <li>Also referred to as <code>20200507.C_bairdi.Trinity.fasta</code>.</li> <li>MD5 = <code>01adbd54298495c147767b19ee5c0de9</code></li> <li>BUSCOs: <code>C:98.8%[S:24.9%,D:73.9%],F:0.9%,M:0.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v2.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with no taxonomic filter.</li> </ul> </li> <li>cbai_transcriptome_v1.7.fasta<ul> <li>MD5 = <code>032d1f81c7744736ebeefe7f63ed6d95</code></li> <li>Assembly from 20200527</li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.7.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.7.fasta.fai</code></li> </ul> </li> <li>BUSCOs: <code>C:86.7%[S:66.5%,D:20.2%],F:8.2%,M:5.1%,n:978</code></li> <li>BLASTx Annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.6.fasta<ul> <li>MD5 = <code>46d77ce86cdbbcac26bf1a6cb820651e</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.6.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.6.fasta.fai</code></li> </ul> </li> <li>BUSCOs: <code>C:91.7%[S:62.6%,D:29.1%],F:6.2%,M:2.1%,n:978</code></li> <li>BLASTx Annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.5.fasta<ul> <li>MD5 = <code>e61d68c45728ffbb91e3d34c087d9aa9</code></li> <li>BUSCOs: C:91.8%[S:64.0%,D:27.8%],F:5.9%,M:2.3%,n:978</li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.5.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.5.fasta.fai</code></li> </ul> </li> <li>Updated assembly from 20200330. Also referred to as <code>20200408.C_bairdi.megan.Trinity.fasta</code></li> <li>BLASTx Annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.0.fasta<ul> <li>MD5 = <code>fb28a203154b44b67ec2e2476d96d326</code></li> <li>BUSCOs: <code>C:85.5%[S:64.7%,D:20.8%],F:9.3%,M:5.2%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.0.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.0.fasta.fai</code></li> </ul> </li> <li>Initial Trinity assembly from 20200122</li> <li>BLASTx Annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019 with Arthropoda only reads. editor_options:    markdown:  wrap: 72</li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#cgoreaui","title":"C.goreaui","text":"<p>Genomes:</p> <ul> <li> <p><code>/volume1/web/halfshell/genomic-databank/Cladocopium_goreaui_genome_fa</code> (1.1GB)</p> <ul> <li> <p>MD5 checksum: <code>eb4a1a7ac2fc0cbc6f5c178240beb932</code></p> </li> <li> <p>Downloaded 20230216: https://espace.library.uq.edu.au/view/UQ:fba3259</p> </li> <li> <p>Access to the genome requires agreeing to some licensing provisions (primarily the requirement to cite the publication whenever the genome is used), so we will not be providing any public links to the file.</p> </li> <li> <p>Chen et. al, 2022</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p>`` (tarball gzip; 563MB)</p> <ul> <li> <p>MD5 checksum: ``</p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p><code>/volume1/web/halfshell/genomic-databank/Cladocopium_goreaui_genes_gff3</code> (225MB)</p> <ul> <li> <p>MD5 checksum: <code>ab47babf331507b9284e9d35406aefac</code></p> </li> <li> <p>Downloaded 20230216: https://espace.library.uq.edu.au/view/UQ:fba3259</p> </li> <li> <p>Access to the GFF requires agreeing to some licensing provisions (primarily the requirement to cite the publication whenever the genome is used), so we will not be providing any public links to the file.</p> </li> <li> <p>Chen et. al, 2022</p> </li> </ul> </li> <li> <p><code>Cladocopium_goreaui_genes_gff3.gtf</code> (197MB)</p> <ul> <li> <p>MD5 checksum: <code>97e69a850faf2e6d9b60df828ad02671</code></p> </li> <li> <p>Created 20230217: Data-Wrangling-C.goreaui-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-gigas-cgigas_uk_roslin_v1","title":"Crassostrea gigas - cgigas_uk_roslin_v1","text":"<ul> <li> <p>NCBI Assembly GCF_902806645.1</p> </li> <li> <p>A chromosome-level genome assembly for the Pacific oyster Crassostrea gigas</p> </li> <li> <p>NCBI Crassostrea gigas Annotation Release 102</p> </li> <li> <p>cgigas_uk_roslin_v1_fuzznuc_CGmotif.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_fuzznuc_CGmotif.gff</code> (CG motif track)</p> </li> </ul> <p>Genome assembly with mitochondrial DNA included: - cgigas_uk_roslin_v1_genomic-mito.fa: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/cgigas_uk_roslin_v1_genomic-mito.fa</code></p> <ul> <li>cgigas_uk_roslin_v1_genomic-mito.fa.fai: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/cgigas_uk_roslin_v1_genomic-mito.fa.fai</code></li> </ul> <p>Genome feature tracks generated from the NCBI RefSeq link in this Jupyter notebook</p> <ul> <li> <p>cgigas_uk_roslin_v1_gene.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_gene.gff</code></p> </li> <li> <p>GCF_902806645.1_cgigas_uk_roslin_v1_genomic-mito.gtf: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/GCF_902806645.1_cgigas_uk_roslin_v1_genomic-mito.gtf</code></p> </li> <li> <p>cgigas_uk_roslin_v1_mRNA.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_mRNA.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_CDS.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_CDS.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_nonCDS.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_nonCDS.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_exon.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_exon.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_exonUTR.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_exonUTR.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_intron.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_intron.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_intergenic.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_intergenic.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_flanks.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_flanks.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_upstream.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_upstream.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_downstream.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_downstream.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_lncRNA.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_lncRNA.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_rm.te.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_rm.te.bed</code></p> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-gigas-oyster_v9","title":"Crassostrea gigas - oyster_v9","text":"<p>Related Resources</p> <ul> <li> <p>NCBI Datasets</p> </li> <li> <p>Compilation of DNA Methylation Genome Feature Tracks (Crassostrea gigas) circa 2015</p> </li> <li> <p>Re-defining Cgigas Canonical features circa 2015</p> </li> <li> <p>Gigaton</p> </li> <li> <p>TJGR</p> </li> </ul> <p>Genome:</p> <ul> <li> <p>Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa</code></p> <ul> <li> <p>MD5 = 6de9d1239eb10ea0545bed6c4e746d6c</p> </li> <li> <p>FastA index (<code>samtools faidx</code>) : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa.fai</code></p> </li> </ul> </li> </ul> <p>Bisulfite Genome:</p> <ul> <li> <p>Crassostrea_gigas.oyster_v9.dna_sm.toplevel_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel_bisulfite.tar.gz</code></p> <ul> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Cgigas_v9_gene.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_gene.gff</code></p> </li> <li> <p>Cgigas_v9_exon.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_exon.gff</code></p> </li> <li> <p>Cgigas_v9_intron.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_intron.gff</code></p> </li> <li> <p>Cgigas_v9_TE.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_TE.gff</code></p> <ul> <li>Contains Tandem Repeats and wublastx features.</li> </ul> </li> <li> <p>Cgigas_v9_CG.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_CG.gff</code></p> <ul> <li>index: <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_CG.gff.idx</code></li> </ul> </li> <li> <p>Cgigas_v9_1k5p_gene_promoter.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_1k5p_gene_promoter.gff</code></p> </li> <li> <p>Cgigas_v9_COMP_gene_prom_TE.bed : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_COMP_gene_prom_TE.bed</code></p> </li> <li> <p>Crassostrea_gigas.oyster_v9.40.gff3 : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.40.gff3</code></p> <ul> <li>MD5 = 90a747fbc94a0a9225c43f75cc40b9db</li> </ul> </li> <li> <p>Crassostrea_gigas.oyster_v9.40.abinitio.gff3 : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.40.abinitio.gff3</code></p> <ul> <li>MD5 = c2a8c388f5a8afb22a115d61dee3dda0</li> </ul> </li> <li> <p>Crassostrea_gigas.oyster_v9.40_mRNA.gff3</p> <ul> <li><code>grep \"mRNA\" Crassostrea_gigas.oyster_v9.40.gff3 &gt; Crassostrea_gigas.oyster_v9.40_mRNA.gff3</code></li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-virginica","title":"Crassostrea virginica","text":"<p>NCBI FTP</p> <p>Genomes:</p> <ul> <li> <p>Cvirginica_v300.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300.fa</code></p> <ul> <li> <p>MD5 = f9135e323583dc77fc726e9df2677a32</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Cvirginica_v300.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300.fa.fai</code></li> </ul> </li> </ul> </li> <li> <p>GCF_002022765.2_C_virginica-3.0_genomic.fna.gz : <code>ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/022/765/GCF_002022765.2_C_virginica-3.0/GCF_002022765.2_C_virginica-3.0_genomic.fna.gz</code></p> <ul> <li>compressed version of <code>Cvirginica_v300.fa</code> (same files)</li> </ul> </li> </ul> <p>Annotations:</p> <ul> <li> <p>Coding sequences (CDS):</p> <ul> <li> <p><code>Cvir_cds-geneID-SPID.tab</code></p> <ul> <li> <p>MD5 = <code>0ee045d4e4702094798da26c2dd6fca3</code></p> </li> <li> <p>Gene with corresponsing SPID.</p> </li> <li> <p>17-Swiss-Prot-Annotation.Rmd</p> </li> </ul> </li> <li> <p><code>Cvir-CDS-GOslim.BP_per_gene.tab</code></p> <ul> <li> <p>MD5 = <code>73eac024baeedf06e28121f201525945</code></p> </li> <li> <p>Biological process GOslims/terms per gene</p> </li> <li> <p>17.1-GO-and-GOslim-CDS-Annotation.Rmd</p> </li> </ul> </li> <li> <p><code>Cvir-CDS-uniprot-full.tsv</code></p> <ul> <li> <p>MD5 = <code>80dd6338e42f21df120bf0cc22f95eab</code></p> </li> <li> <p>Tab-delimited output file from UniProt API retrieval. Columns:</p> <ul> <li><code>Entry</code></li> <li><code>Reviewed</code></li> <li><code>Entry Name</code></li> <li><code>Protein names</code></li> <li><code>Gene Names</code></li> <li><code>Organism</code></li> <li><code>Length</code></li> <li><code>Gene Ontology (biological process)</code></li> <li><code>Gene Ontology (cellular component)</code></li> <li><code>Gene Ontology (GO)</code></li> <li><code>Gene Ontology (molecular function)</code></li> <li><code>Gene Ontology IDs</code></li> </ul> </li> <li> <p>17.1-GO-and-GOslim-CDS-Annotation.Rmd</p> </li> </ul> </li> </ul> </li> </ul> <p>Bisulfite Genomes:</p> <ul> <li> <p>Cvirginica_v300_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300_bisulfite.tar.gz</code></p> <ul> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>C_virginica-3.0_Gnomon_mRNA.gff3 : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_mRNA.gff3</code></p> </li> <li> <p>C_virginica-3.0_Gnomon_genes.bed : <code>https://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_genes.bed</code></p> <ul> <li> <p>MD5 = <code>c8f203de591c0608b96f4299c0f847dc</code></p> </li> <li> <p>Notebook entry</p> </li> </ul> </li> <li> <p>C_virginica-3.0_Gnomon_exon.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_exon.bed</code></p> </li> <li> <p>C_virginica-3.0_intron.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_intron.bed</code></p> </li> <li> <p>C_virginica-3.0_CG-motif.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_CG-motif.bed</code></p> <ul> <li> <p>MD5 = <code>f88c171bccf45a6f3afcf455b6be810f</code></p> </li> <li> <p>Dead link in this Jupyter Notebook obscures details on how this was generated (via Galaxy):</p> <ul> <li>https://github.com/sr320/nb-2018/blob/master/C_virginica/22-CG-track.ipynb</li> </ul> </li> </ul> </li> <li> <p>C_virginica-3.0_TE-all.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/C_virginica-3.0_TE-all.gff</code></p> <ul> <li> <p>MD5 = d0d81fc6cf7525bc2c61984bee23521b</p> </li> <li> <p>Details</p> </li> </ul> </li> <li> <p>C_virginica-3.0_TE-Cg.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/C_virginica-3.0_TE-Cg.gff</code></p> <ul> <li> <p>MD5 = 83cd753c171076464fee1165b7e1c6ba</p> </li> <li> <p>Details</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#gadus-macrocephalus-pacific-cod","title":"Gadus macrocephalus (Pacific cod)","text":"<p>NCBI</p> <p>Genomes</p> <ul> <li> <p><code>GCF_031168955.1_ASM3116895v1_genomic.fna</code> (FastA; 537MB)</p> <ul> <li>MD5 = <code>5144890d4eceb0b258d92db3f35c681e</code></li> </ul> </li> <li> <p><code>GCF_031168955.1_ASM3116895v1_cds_from_genomic.fna</code> (FastA; 112MB)</p> <ul> <li>MD5 = <code>95ef994762e8e4d58c2ce15d312f0aaf</code></li> </ul> </li> <li> <p><code>GCF_031168955.1_ASM3116895v1.faa</code> (FastA; 35MB)</p> <ul> <li>MD5 = <code>cf58a1ec6408eb8c55aa23a6c06430d9</code></li> </ul> </li> <li> <p><code>GCF_031168955.1_ASM3116895v1_rna.fna</code> (FastA; 169MB)</p> <ul> <li>MD5 = <code>2a6c7c98982727e688f033a9b236725b</code></li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p><code>GCF_031168955.1_ASM3116895v1.gff</code> (GFF; 351MB)</p> </li> <li> <p>MD5 = <code>173fb3c159e474391c5c4aa1f7230024</code></p> </li> </ul>"},{"location":"Genomic-Resources/#hematodinium-sp-host-chionoecetes-bairdi","title":"Hematodinium sp. (Host: Chionoecetes bairdi)","text":"<p>Transcriptomes</p> <p>Assembly Stats Table (Google Sheet)</p> <ul> <li> <p>hemat_transcriptome_v1.7.fasta</p> <pre><code>- internal short-hand: includes 2018, 2019, 2020-UW with _Alveolata_ only reads.\n\n- MD5 = `f9c8f96a49506e1810ff4004426160d8`\n\n- FastA index (```samtools faidx```)\n\n    - [hemat_transcriptome_v1.7.fasta.fai](https://gannet.fish.washington.edu/Atumefaciens/20210308_hemat_trinity_v1.6_v1.7/hemat_transcriptome_v1.7.fasta_trinity_out_dir/hemat_transcriptome_v1.7.fasta.fai)\n\n- [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/08/Transcriptome-Assembly-Hematodinium-Transcriptomes-v1.6-and-v1.7-with-Trinity-on-Mox.html)\n\n- BUSCOs: `C:15.0%[S:12.2%,D:2.8%],F:12.3%,M:72.7%,n:978`\n\n    - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Assessment-BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox.html)\n\n- BLASTx Annotation\n\n  - [hemat_transcriptome_v1.7.fasta.blastx.outfmt6](https://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.7.fasta.blastx.outfmt6)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Annotation-Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox.html)\n\n- GO Terms Annotation\n\n  - [20210310.hemat_transcriptome_v1.7.fasta.trinotate.go_annotations.txt](https://gannet.fish.washington.edu/Atumefaciens/20210309_hemat_trinotate_transcriptome-v1.7/20210310.hemat_transcriptome_v1.7.fasta.trinotate.go_annotations.txt) (Trinotate)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/posts/2021/2021-03-09-Transcriptome-Annotation---Trinotate-Hematodinium-v1.7-on-Mox/index.html)\n</code></pre> </li> <li> <p>hemat_transcriptome_v1.6.fasta</p> <pre><code>- internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with _Alveolata_ only reads.\n\n- MD5 = `f9c8f96a49506e1810ff4004426160d8`\n\n- FastA index (```samtools faidx```)\n\n    - [hemat_transcriptome_v1.6.fasta.fai](https://gannet.fish.washington.edu/Atumefaciens/20210308_hemat_trinity_v1.6_v1.7/hemat_transcriptome_v1.6.fasta_trinity_out_dir/hemat_transcriptome_v1.6.fasta.fai)\n\n- [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/08/Transcriptome-Assembly-Hematodinium-Transcriptomes-v1.6-and-v1.7-with-Trinity-on-Mox.html)\n\n- BUSCOs: `C:26.5%[S:20.7%,D:5.8%],F:11.2%,M:62.3%,n:978`\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Assessment-BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox.html)\n\n- BLASTx Annotation\n\n  - [hemat_transcriptome_v1.6.fasta.blastx.outfmt6](https://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.6.fasta.blastx.outfmt6)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Annotation-Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox.html)\n\n- GO Terms Annotation\n\n  - [20210309.hemat_transcriptome_v1.6.fasta.trinotate.go_annotations.txt](https://gannet.fish.washington.edu/Atumefaciens/20210309_hemat_trinotate_transcriptome-v1.6/20210309.hemat_transcriptome_v1.6.fasta.trinotate.go_annotations.txt) (Trinotate)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/posts/2021/2021-03-09-Transcriptome-Annotation---Trinotate-Hematodinium-v1.6-on-Mox/index.html)\n</code></pre> </li> <li> <p>hemat_transcriptome_v1.5.fasta</p> <ul> <li> <p>MD5 = <code>b8d4a3c1bad2e07da8431bf70bdabfdd</code></p> </li> <li> <p>BUSCOs: <code>C:25.6%[S:20.7%,D:4.9%],F:11.7%,M:62.7%,n:978</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>hemat_transcriptome_v1.5.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/hemat_transcriptome_v1.5.fasta.fai</code></li> </ul> </li> <li> <p>Updated assembly from 20200330.</p> </li> <li> <p>BLASTx Annotation (txt; 355KB)</p> </li> <li> <p>Trinotate GO Terms Annotation (txt; 2.3MB)</p> </li> <li> <p>internal short-hand: includes 2018, 2019, 2020-GW with Alveolata only reads.</p> </li> </ul> </li> <li> <p>hemat_transcriptome_v1.0.fasta (3.9MB)</p> <ul> <li> <p>MD5 = <code>fa5eb74767d180af5265d2d1f80b6430</code></p> </li> <li> <p>BUSCOs: <code>C:25.1%[S:19.2%,D:5.9%],F:9.5%,M:65.4%,n:978</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>hemat_transcriptome_v1.0.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/hemat_transcriptome_v1.0.fasta.fai</code></li> </ul> </li> <li> <p>Initial Trinity assembly from 20200122</p> </li> <li> <p>BLASTx Annotation (txt; 308KB)</p> </li> <li> <p>Trinotate GO Terms Annotation (txt; 2.1MB)</p> </li> <li> <p>internal short-hand: includes 2018, 2019 with Alveolata only reads.</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#metacarcinus-magister-cancer-magister","title":"Metacarcinus magister (Cancer magister)","text":"<p>Genome:</p> <ul> <li> <p><code>mmag_pilon_scaffolds.fasta</code></p> <ul> <li> <p>MD5 = 5dfa2ba11edf0ff8191f112e0b1378d1</p> </li> <li> <p>Not shared publicly until permission received from NOAA.</p> </li> <li> <p>Roberts Lab members can access on Owl: <code>/web/halfshell/genomic-databank/mmag_pilon_scaffolds.fasta</code></p> </li> <li> <p>Original filename: <code>pilon_scaffolds.fasta</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li><code>mmag_pilon_scaffolds.fasta.fai</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#montipora-capitata","title":"Montipora capitata","text":"<p>Genomes:</p> <ul> <li> <p><code>GCA_006542545.1_Mcap_UHH_1.1_genomic.fna</code> (569MB)</p> <ul> <li> <p>MD5 checksum: <code>25efbc3110c0791b5eb2e5ac5c2a472f</code></p> </li> <li> <p>Downloaded 20230125: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_006542545.1/</p> </li> </ul> </li> <li> <p><code>Montipora_capitata_HIv3.assembly.fasta</code> (745MB)</p> <ul> <li> <p>MD5 checksum: <code>99819eadba1b13ed569bb902eef8da08</code></p> </li> <li> <p>Downloaded 2023017: http://cyanophora.rutgers.edu/montipora/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>)</p> <ul> <li> <p><code>Montipora_capitata_HIv3-hisat2-indices.tar.gz</code> (tarball gzip; 1.2GB)</p> <ul> <li> <p>MD5 checksum: <code>c8accb6c54e843198c776f0d6f0c603d</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p><code>Montipora_capitata_HIv3.genes.gff3</code> (67MB)</p> <ul> <li> <p>MD5 checksum: <code>5f6b80ba2885471c8c1534932ccb7e84</code></p> </li> <li> <p>Downloaded 2023017: http://cyanophora.rutgers.edu/montipora/</p> </li> </ul> </li> <li> <p><code>Montipora_capitata_HIv3.genes.gtf</code> (101MB)</p> <ul> <li> <p>MD5 checksum: <code>ceef8eca945199415b23d2f1f0dd2066</code></p> </li> <li> <p>Created 2023017: https://robertslab.github.io/sams-notebook/2023/01/27/Data-Wrangling-M.capitata-Genome-GFF-to-GTF-Using-gffread.html</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#mytilus-trossulus","title":"Mytilus trossulus","text":"<p>Genome:</p> <ul> <li> <p>NCBI Assembly GCF_021869535.1</p> </li> <li> <p>A chromosome-level reference genome of the bay mussel Mytilus trossulus</p> </li> <li> <p>NCBI Mytilus trossulus Annotation Release 100</p> </li> </ul> <p>Transcriptome:</p> <ul> <li> <p>Mtros-hq_transcripts.fasta</p> <ul> <li>MD5 = 381f7b6970fd20ff6b0e72006c80a</li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#ostrea-lurida","title":"Ostrea lurida","text":"<p>Genome:</p> <ul> <li> <p>Olurida_v081.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081.fa</code></p> <ul> <li> <p>MD5 = 3ac56372bd62038f264d27eef0883bd3</p> </li> <li> <p>This is <code>v080</code> with only contigs &gt; 1000bp. Details of how <code>v080</code> was reduced found here.</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Olurida_v081.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081.fa.fai</code></li> </ul> </li> </ul> </li> <li> <p>Olurida_v080.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080.fa</code></p> <ul> <li> <p>MD5 = 9258398f554493e08fdc30e9c1409864</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Olurida_v080.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080.fa.fai</code></li> </ul> </li> <li> <p>Also known as <code>pbjelly_sjw_01</code>. Details found here, though confirmation would be good.</p> </li> </ul> </li> </ul> <p>Bisulfite Genomes:</p> <ul> <li> <p>Olurida_v080_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080_bisulfite.tar.gz</code></p> </li> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> <p>Transcriptomes:</p> <ul> <li> <p>Olurida_transcriptome_v3.fasta</p> <ul> <li>MD5 = 9da3242af2be0463051ec7e1f39b2593</li> </ul> </li> </ul> <p>Tissue-specific transcriptomes generated by Katherine Silliman</p> <ul> <li> <p>Olurida_CA_adductor_Trinity.fasta.gz</p> </li> <li> <p>Olurida_CA_ctenidia_Trinity.fasta.gz</p> </li> <li> <p>Olurida_CA_mantle_Trinity.fasta.gz</p> </li> <li> <p>Olurida_gonad_Trinity.fasta.gz</p> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Olurida_v081_genome_snap02.all.renamed.putative_function.domain_added.gff (2.9GB) : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_genome_snap02.all.renamed.putative_function.domain_added.gff</code></p> <ul> <li>MD5 = <code>f54512bd964f45645c34b1e8e403a2b0</code></li> </ul> </li> <li> <p>Olurida_v081-20190709.CDS.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.CDS.gff</code></p> </li> <li> <p>Olurida_v081-20190709.exon.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.exon.gff</code></p> </li> <li> <p>Olurida_v081-20190709.gene.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.gene.gff</code></p> </li> <li> <p>Olurida_v081-20190709.mRNA.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.mRNA.gff</code></p> </li> <li> <p>Olurida_v081_TE-Cg.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_TE-Cg.gff</code></p> <ul> <li> <p>MD5 = 977fd7cdb460cd0b9df5e875e1e880ea</p> </li> <li> <p>Transposable Element track - more details in Sam's Notebook, including a summary table.</p> </li> </ul> </li> <li> <p>Olurida_v081_CG-motif.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_CG-motif.gff</code></p> </li> </ul>"},{"location":"Genomic-Resources/#ostrea-chil","title":"Ostrea chil","text":"<p>Genome:</p> <ul> <li> <p>[HapA]</p> </li> <li> <p>[HapB]</p> </li> </ul> <p>Protein:</p> <p>-</p> <p>Blast:</p>"},{"location":"Genomic-Resources/#panopea-generosa","title":"Panopea generosa","text":"<p>Genome:</p> <ul> <li> <p>Panopea-generosa-v1.0.fa : <code>https://gannet.fish.washington.edu/Atumefaciens/20191105_swoose_pgen_v074_renaming/Panopea-generosa-v1.0.fa</code></p> <ul> <li> <p>ENA Accession: GCA_902825435</p> </li> <li> <p>Version of 070 containing 18 largest scaffolds (details on subsetting)</p> </li> <li> <p>FastA file and scaffolds were renamed on 20191105 (notebook)</p> </li> <li> <p>MD5 = 32976550b9030126c07920d5f2db179c</p> </li> <li> <p>BUSCO scores:</p> <ul> <li> <p><code>C:71.6%[S:70.7%,D:0.9%],F:4.7%,M:23.7%,n:978</code></p> </li> <li> <p>Notebook entry</p> </li> </ul> </li> <li> <p>FastA index (<code>samtools faidx</code>):</p> <ul> <li><code>https://gannet.fish.washington.edu/Atumefaciens/20191105_swoose_pgen_v074_renaming/Panopea-generosa-v1.0.fa.fai</code></li> </ul> </li> <li> <p>Gene annotation file:</p> <ul> <li> <p>20220419-pgen-gene-accessions-gene_id-gene_name-gene_description-alt_gene_description-go_ids.tab</p> <ul> <li> <p><code>gene_ID</code>: Gene ID from our Panopea generosa (Pacific geoduck) genome.</p> </li> <li> <p><code>SPIDs</code>: Semicolon-delimited list of SPIDs from UniProt. One SPID in this list is a match corresponding to the our original BLAST annotations.</p> </li> <li> <p><code>UniProt_gene_ID</code>: Gene accession from UniProt.</p> </li> <li> <p><code>gene</code>: Abbreviated gene name from UniProt.</p> </li> <li> <p><code>gene_description</code>: Human-readable gene description from UniProt.</p> </li> <li> <p><code>alternate_gene_description</code>: Human-readable alternate gene description from UniProt.</p> </li> <li> <p><code>GO_IDs</code>: Semicolon-delimited GO IDs from UniProt.</p> </li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Bisulfite Genome:</p> <p>Genome Feature Tracks:</p> <ul> <li> <p>Panopea-generosa-vv0.74.a4</p> <p>These originate from GenSAS annotation on 20190928</p> <p>Individual feature GFFs were made with the following shell commands:</p> </li> </ul> <pre><code>```bash\n\nfeatures_array=(CDS exon gene mRNA repeat_region rRNA tRNA)\n\ninput=\"Panopea-generosa-vv0.74.a4-merged-2019-10-07-4-46-46.gff3\"\n\nfor feature in ${features_array[@]}\n  do\n  output=\"Panopea-generosa-vv0.74.a4.${feature}.gff3\"\n  head -n 3 ${input} \\\n  &gt;&gt; ${output}\n  awk -v feature=\"$feature\" '$3 == feature {print}' ${input} \\\n  &gt;&gt; ${output}\ndone\n```\n\n- [GFF files and scaffolds were renamed on 20191105](https://robertslab.github.io/sams-notebook/2019/11/05/Data-Wrangling-Rename-Pgenerosa_v074-Files-and-Scaffolds.html) (notebook)\n</code></pre> <ul> <li> <p>Panopea-generosa-v1.0.a4.gff3</p> <ul> <li>Primary GFF containing all features.</li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4_biotype-trna_strand_converted-no_RNAmmer.gtf</p> <ul> <li> <p>GTF file with formatting to avoid downstream parsing problems.</p> </li> <li> <p>GitHub Issue describing creation and problems</p> </li> </ul> </li> <li> <p>Panopea-generosa-v1.0.CpG.gff</p> </li> <li> <p>Panopea-generosa-v1.0.a4.CDS.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.exon.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.intergenic.bed</p> </li> <li> <p>Panopea-generosa-v1.0.a4.introns.bed</p> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.rRNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeat_region.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.DNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.LINE.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.LTR.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.RC.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.SINE.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.Simple_repeat.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.Unknown.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.tRNA.gff3</p> </li> </ul> <p>Fasta files:</p> <ul> <li> <p>Panopea-generosa-v1.0.a4.CDS.fasta (67M)</p> <ul> <li>MD5: <code>fb192eab0aefd5d3ba5bebef2a012f15</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.CDS.fasta.fai (26M)</p> <ul> <li>MD5: <code>f2266a449290ea0383d2eb98eb3ed426</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.fasta (362M)</p> <ul> <li>MD5: <code>7c956b1c27d14bd91959763403f81265 588d18f5fe0e4f2259a25586349fc244</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.fasta.fai (2.4M)</p> <ul> <li>MD5: <code>588d18f5fe0e4f2259a25586349fc244</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.fasta (475M)</p> <ul> <li>MD5: <code>1823be75694cf70f0ea6f1abc072ba16 e120b4c1d3bb0917868e72cd22507bbc</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.fasta.fai (3.4M)</p> <ul> <li>MD5: <code>e120b4c1d3bb0917868e72cd22507bbc</code></li> </ul> </li> </ul> <p>Jupyter notebook with creation deets (NB Viewer):</p> <ul> <li>20220324-pgen-gffs_to_fastas.ipynb</li> </ul> <p>CDS FastA description lines look like this:</p> <ul> <li><code>PGEN_.00g000010.m01.CDS01|PGEN_.00g000010.m01::Scaffold_01:2-125</code></li> </ul> <p>Explanation for CDS:</p> <ul> <li><code>PGEN_.00g000010.m01.CDS01</code>: Unique sequence ID.</li> <li><code>PGEN_.00g000010.m01</code>: \"Parent\" ID. Corresponds to unique mRNA ID.</li> <li><code>Scaffold_01</code>: Originating scaffold.</li> <li><code>2-125</code>: Sequence coordinates from scaffold mentioned above.</li> </ul> <p>mRNA FastA description looks like this:</p> <ul> <li><code>PGEN_.00g000030.m01|PGEN_.00g000030::Scaffold_01:49248-52578</code></li> </ul> <p>Explanation for mRNA:</p> <ul> <li><code>PGEN_.00g000030.m01</code>: Unique sequence ID.</li> <li><code>PGEN_.00g000030</code>: \"Parent\" ID. Corresponds to unique gene ID.</li> <li><code>Scaffold_01</code>: Originating scaffold.</li> <li><code>49248-52578</code>: Sequence coordinates from scaffold mentioned above.</li> </ul> <ul> <li> <p>Pgenerosa_transcriptome_v5.fasta : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Pgenerosa_transcriptome_v5.fasta</code></p> <ul> <li>MD5 = <code>5a21424ecbc88c3b01daefe56bed79da</code></li> </ul> </li> </ul> <p>Transcriptome generated from various libaries - details here.</p> <ul> <li> <p>Kallisto index for <code>Pgenerosa_transcriptome_v5.fasta</code> (8.2GB):</p> <ul> <li><code>https://gannet.fish.washington.edu/seashell/wd/062821/transcriptome_v5.idx</code></li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillipora-acuta","title":"Pocillipora acuta","text":"<p>Genome:</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2.assembly.fasta</code> (389MB)</p> <ul> <li> <p>MD5 checksum: <code>ce3b69ff3f5dafb8fb7416dc862ef4a0</code></p> </li> <li> <p>Downloaded 20230125: http://cyanophora.rutgers.edu/Pocillopora_acuta/</p> </li> </ul> </li> </ul> <p>Genome Index (<code>HISAT2</code>):</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2-hisat2-indices.tar.gz</code> (597MB)</p> <ul> <li> <p>MD5 checksum: <code>80dbf8ca589f569f43ef2a75ab57e17d</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks:</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2.genes.gff3</code> (54MB)</p> <ul> <li> <p>MD5 checksum: <code>fad5aa85afd7e3bec4400ca6da7d706d</code></p> </li> <li> <p>Downloaded 20230125: http://cyanophora.rutgers.edu/Pocillopora_acuta/</p> </li> </ul> </li> <li> <p><code>Pocillopora_acuta_HIv2.gtf</code> (82MB)</p> <ul> <li> <p>MD5 checksum: <code>34196bd945eb4965e665097648037132</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.acuta-Genome-GFF-to-GTF-Conversion-Using-gffread.html</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillopora-meandrina","title":"Pocillopora meandrina","text":"<p>Genome(s):</p> <ul> <li> <p><code>Pocillopora_meandrina_HIv1.assembly.fasta</code> (360MB)</p> <ul> <li> <p>MD5 checksum: <code>36eb9cdaf92db69906e6d1486a8406f5</code></p> </li> <li> <p>Downloaded 20230519: http://cyanophora.rutgers.edu/Pocillopora_meandrina/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p><code>Pocillopora_meandrina_HIv1.assembly-hisat2-indices.tar.gz</code> (tarball gzip; MB)</p> <ul> <li> <p>MD5 checksum: ``</p> </li> <li> <p>Needs to be unpacked before use!</p> </li> <li> <p>Notebook: </p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Genes</p> <ul> <li> <p>https://owl.fish.washington.edu/halfshell/genomic-databank/Pocillopora_meandrina_HIv1.genes-valid.gff3 (55MB)</p> </li> <li> <p>MD5 checksum: <code>5865589d1f2764b4b74df91ea78d5652</code></p> </li> <li> <p>A GFF3-compliant version of <code>Pocillopora_meandrina_HIv1.genes.gff3</code> (see below). Created GFF3 compliant version via the following command (replace <code>transcript</code> with <code>mRNA</code>):</p> <ul> <li><code>sed 's/transcript/mRNA/' Pocillopora_meandrina_HIv1.genes.gff3 &gt; Pocillopora_meandrina_HIv1.genes-valid.gff3</code></li> </ul> </li> <li> <p>Pocillopora_meandrina_HIv1.genes.gff3 (55MB)</p> <ul> <li> <p>MD5 checksum: <code>ace5c9a588321fada8e6771a1c758861</code></p> </li> <li> <p>Downloaded 20230519: http://cyanophora.rutgers.edu/Pocillopora_meandrina/</p> </li> <li> <p>NOTE: This is labelled as a GFF3, but in reality closer to a GTF file; as it only contains transcript/exon/CDS features. There are no gene features (e.g. 5'/3'UTR, mRNA, gene, etc). Additionally, the feature label of <code>transcript</code> is not GFF or GTF compliant.</p> </li> </ul> </li> </ul> </li> <li> <p>Repeats</p> <ul> <li> <p>Pocillopora_meandrina_HIv1.assembly.fasta.out.gff (13MB)</p> <ul> <li> <p>MD5 checksum: <code>6e7a25bf51a7c838b9659dd7ec37990f</code></p> </li> <li> <p>Notebook: Repeats-Identification-P.meandrina-Using-RepeatMasker-on-Mox.html</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillipora-verrucosa","title":"Pocillipora verrucosa","text":"<p>Genomes:</p> <ul> <li> <p><code>GCA_014529365.1_Pver_genome_assembly_v1.0_genomic.fna</code> (369MB)</p> <ul> <li> <p>MD5 checksum: <code>6ca98fae6a8b86183d75b23cf52a6651</code></p> </li> <li> <p>Downloaded 20230125: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_014529365.1/</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0.fasta</code> (363MB)</p> <ul> <li> <p>MD5 checksum: <code>cb1ed5a1b724d92456347a28bb25f228</code></p> </li> <li> <p>Downloaded 20230127: http://pver.reefgenomics.org/download/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p><code>pver-GCA_014529365.1-hisat2-indices.tar.gz</code> (tarball gzip; 563MB)</p> <ul> <li> <p>MD5 checksum: <code>f1669e7d88cf014fcfa10c6c06e03802</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-hisat2-indices.tar.gz</code> (tarball gzip; 594MB)</p> <ul> <li> <p>MD5 checksum: <code>57e193e101396fab67de04c851f63240</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> <li> <p>Notebook: Genome-Indexing-P.verrucosa-v1.0-Assembly-with-HiSat2-on-Mox.html</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>~~<code>Pver_genome_assembly_v1.0.gff3</code>~~ (70MB)</p> <ul> <li> <p>NOTE: DO NOT USE! NOT A VALID GFF3 FORMAT!</p> <ul> <li> <p>Retaining to maintain provenance of data.</p> </li> <li> <p>Use updated/validated <code>Pver_genome_assembly_v1.0-valid.gff3</code>.</p> </li> </ul> </li> <li> <p>MD5 checksum: <code>3f1d52afa2801f9aa126623aba3c149d</code></p> </li> <li> <p>Downloaded 20230127: http://pver.reefgenomics.org/download/</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.gff3</code> (70MB)</p> <ul> <li> <p>MD5 checksum: <code>5dd8f21a4faea1f46c48a5ab253749d7</code></p> </li> <li> <p>Modified/validated version of <code>Pver_genome_assembly_v1.0.gff3</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.verrucosa-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.gtf</code> (48MB)</p> <ul> <li> <p>MD5 checksum: <code>c3cc8fb576bcf39dd17b6d229100aa56</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.verrucosa-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.genes.bed</code> (1.2MB)</p> <ul> <li> <p>MD5 checksum: <code>f19672f65c4e376f96c6ab23c202c2e0</code></p> </li> <li> <p>Created 20230227 by Sam White:</p> <pre><code>bedops_linux_x86_64-v2.4.40/gff2bed \\\n&lt; Pver_genome_assembly_v1.0-valid.genes.gff3 \\\n| awk -F\"\\t\" 'BEGIN {OFS=\"\\t\"} {print $1, $2, $3, $4, $5, $6}' \\\n&gt; Pver_genome_assembly_v1.0-valid.genes.bed\n</code></pre> </li> </ul> </li> <li> <p>Pver_CGmotif.gff: <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Pver_CGmotif.gff</code> (1.3G)</p> </li> </ul>"},{"location":"Genomic-Resources/#pycnopodia-helianthodes","title":"Pycnopodia helianthodes","text":"<p>Genome</p> <ul> <li> <p>GCA_032158295.1_ASM3215829v1_genomic.fna</p> </li> <li> <p>MD5: <code>c6eb5b44d2bc14c37c852688a39009ad</code></p> </li> <li> <p>Downloaded from NCBI 20231025 by SJW.</p> </li> </ul>"},{"location":"Genomic-Resources/#qpx","title":"QPX","text":"<p>Genome:</p> <ul> <li>QPX_v017.fasta : <code>http://eagle.fish.washington.edu/QPX_genome/QPX_v017.fasta</code></li> </ul> <p>CLC v5.1 Mismatch cost = 2; Perform scaffolding = Yes; Mapping mode = Map reads back to contigs (slow); Deletion cost = 3; Similarity fraction = 0.9; Length fraction = 0.8; Insertion cost = 3; Update contigs = Yes; Automatic word size = Yes; Minimum contig length = 10000; Automatic bubble size = Yes; input: filtered_QPX_DNA_GTGAAA_L001_R1 trimmed.</p> <ul> <li>QPX_v017.fasta : <code>https://ndownloader.figshare.com/files/3085550</code></li> </ul> <p>CLC v5.1 Mismatch cost = 2; Perform scaffolding = Yes; Mapping mode = Map reads back to contigs (slow); Deletion cost = 3; Similarity fraction = 0.9; Length fraction = 0.8; Insertion cost = 3; Update contigs = Yes; Automatic word size = Yes; Minimum contig length = 10000; Automatic bubble size = Yes; input: filtered_QPX_DNA_GTGAAA_L001_R1 trimmed.</p> <ul> <li>QPX_v015.fasta : <code>https://doi.org/10.1371/journal.pone.0074196.s001</code></li> </ul> <p>De novo assembly was performed with Genomics Workbench v. 5.0 (CLC Bio, Germany) on quality trimmed sequences with the following parameters: mismatch cost = 2, deletion cost = 3, similarity fraction = 0.9, insertion cost = 3, length fraction = 0.8 and minimum contig size of 100 bp for genomic data and 200 bp for transcriptomic data. In order to remove ribosomal RNA sequences from the transcriptome data, consensus sequences were compared to the NCBI nt database using the BLASTn algorithm [59]. Sequences with significant matches (9) were removed and not considered in subsequent analyses.</p> <p>Manuscript: https://doi.org/10.1371/journal.pone.0074196</p> <p>Transcriptome:</p> <ul> <li>QPX_transcriptome_v1_clean.fasta</li> </ul> <p>QPX_Transcriptome v2.1</p> <p>Subset of version 1 (v1) that only includes sequences with e-value \\&lt; 1E-20. Based on Swiss-Prot blastx output, all sequences are oriented 5' - 3'. nucleotides between stop codons; minimum size 200.</p>"},{"location":"Genomic-Resources/#salvelinus-namaycush-lake-trout","title":"Salvelinus namaycush (lake trout)","text":"<p>Genome:</p> <ul> <li>SaNama_1.0_genomic.fna: <code>https://owl.fish.washington.edu/halfshell/genomic-databank/SaNama_1.0_genomic.fna</code></li> </ul> <p>Genome Feature Tracks:</p> <ul> <li> <p>20220818-snam-GCF_016432855.1_SaNama_1.0_genes.bed</p> <ul> <li>Notebook entry</li> </ul> </li> </ul>"},{"location":"How-to-Grad-School-Slides/","title":"How to Grad School: A Guide for High Schoolers and Undergrads","text":"<p>Thinking about graduate school? This guide covers everything you need to know about preparing for and succeeding in graduate studies in aquatic and environmental sciences.</p>"},{"location":"How-to-Grad-School-Slides/#slide-1-welcome","title":"Slide 1: Welcome! \ud83c\udf93","text":""},{"location":"How-to-Grad-School-Slides/#so-youre-thinking-about-grad-school","title":"So You're Thinking About Grad School?","text":"<p>Graduate school can be an amazing journey that: - Deepens your expertise in a field you're passionate about - Opens doors to research and leadership opportunities - Prepares you for careers in science, academia, industry, and policy - Connects you with a community of researchers and mentors</p> <p>But it's also a big commitment! Let's explore what you need to know.</p>"},{"location":"How-to-Grad-School-Slides/#slide-2-what-classes-should-you-take","title":"Slide 2: What Classes Should You Take? \ud83d\udcda","text":""},{"location":"How-to-Grad-School-Slides/#building-your-foundation","title":"Building Your Foundation","text":"<p>Core Science Classes: - Biology: Ecology, marine biology, molecular biology, genetics - Chemistry: General chemistry, organic chemistry, biochemistry - Math &amp; Statistics: Calculus, statistics, quantitative methods - Physics: At least one year for understanding physical processes</p> <p>Specialized Courses for Aquatic Sciences: - Oceanography or limnology - Fisheries biology - Environmental science - Hydrology or water chemistry</p> <p>Don't Forget: - Writing-intensive courses - Communication is crucial in science! - Computer science or bioinformatics - Data analysis skills are essential - Research methods courses - Foreign language (helpful for international research)</p>"},{"location":"How-to-Grad-School-Slides/#pro-tips","title":"Pro Tips:","text":"<p>\u2705 Take challenging courses - grad schools want to see you can handle rigorous academics \u2705 Maintain a strong GPA (aim for 3.5+ for competitive programs) \u2705 Don't just take required courses - explore topics that excite you!</p>"},{"location":"How-to-Grad-School-Slides/#slide-3-what-degree-programs-should-you-apply-to","title":"Slide 3: What Degree Programs Should You Apply To? \ud83c\udfeb","text":""},{"location":"How-to-Grad-School-Slides/#types-of-graduate-degrees","title":"Types of Graduate Degrees","text":"<p>Master's Degree (MS/MA) - 2-3 years - Good for: Career advancement, research experience, stepping stone to PhD - Options: Thesis-based (research-focused) or coursework-based</p> <p>Doctoral Degree (PhD) - 4-7 years - Good for: Research careers, academia, leadership roles in science - Intensive research focus with original contribution to knowledge</p>"},{"location":"How-to-Grad-School-Slides/#research-areas-in-aquatic-environmental-sciences","title":"Research Areas in Aquatic &amp; Environmental Sciences:","text":"<ul> <li>Marine Biology &amp; Oceanography</li> <li>Fisheries Science </li> <li>Aquaculture</li> <li>Conservation Biology</li> <li>Environmental Toxicology</li> <li>Climate Change &amp; Ocean Acidification</li> <li>Bioinformatics &amp; Computational Biology</li> <li>Environmental Policy &amp; Management</li> </ul>"},{"location":"How-to-Grad-School-Slides/#finding-the-right-program","title":"Finding the Right Program:","text":"<ol> <li>Research first, program second - Find faculty doing work you find exciting</li> <li>Consider location - Field work opportunities, climate, cost of living</li> <li>Look at funding - Teaching assistantships, research assistantships, fellowships</li> <li>Program culture - Visit labs, talk to current students</li> <li>Career outcomes - Where do graduates end up?</li> </ol>"},{"location":"How-to-Grad-School-Slides/#slide-4-what-are-useful-research-skills","title":"Slide 4: What Are Useful Research Skills? \ud83d\udd2c","text":""},{"location":"How-to-Grad-School-Slides/#laboratory-skills","title":"Laboratory Skills","text":"<ul> <li>Molecular techniques: DNA/RNA extraction, PCR, sequencing</li> <li>Microscopy: Identifying organisms, histology</li> <li>Chemical analysis: Water chemistry, pH, nutrients</li> <li>Field sampling: Proper collection and preservation techniques</li> </ul>"},{"location":"How-to-Grad-School-Slides/#computational-skills","title":"Computational Skills","text":"<ul> <li>Programming languages: R (statistics), Python (data analysis), bash (command line)</li> <li>Data management: Organizing, backing up, and sharing data properly</li> <li>Bioinformatics: Analyzing genomic data, phylogenetics</li> <li>Statistical analysis: Experimental design, hypothesis testing</li> </ul>"},{"location":"How-to-Grad-School-Slides/#field-work-skills","title":"Field Work Skills","text":"<ul> <li>Safety protocols: First aid, boat safety, SCUBA certification</li> <li>Equipment operation: Water quality meters, nets, underwater cameras</li> <li>Navigation: GPS, charts, tide tables</li> <li>Species identification: Local flora and fauna</li> </ul>"},{"location":"How-to-Grad-School-Slides/#communication-skills","title":"Communication Skills","text":"<ul> <li>Scientific writing: Papers, grants, reports</li> <li>Presentations: Conferences, lab meetings, public outreach</li> <li>Data visualization: Creating clear, compelling figures</li> <li>Collaboration: Working effectively in teams</li> </ul>"},{"location":"How-to-Grad-School-Slides/#how-to-develop-these-skills","title":"How to Develop These Skills:","text":"<p>\u2705 Undergraduate research - Most important! \u2705 Summer internships (REU programs, field stations) \u2705 Volunteer in labs during the academic year \u2705 Take relevant coursework \u2705 Attend workshops and training programs \u2705 Join student research groups</p>"},{"location":"How-to-Grad-School-Slides/#slide-5-how-do-you-apply-to-graduate-school","title":"Slide 5: How Do You Apply to Graduate School? \ud83d\udcdd","text":""},{"location":"How-to-Grad-School-Slides/#timeline-starting-junior-year","title":"Timeline (Starting Junior Year)","text":"<p>Junior Year: - Spring: Start researching programs and faculty - Summer: Gain research experience, attend conferences</p> <p>Senior Year: - Fall: Take GRE (if required), request transcripts, submit applications - Winter/Spring: Interview season, make final decisions</p>"},{"location":"How-to-Grad-School-Slides/#application-components","title":"Application Components","text":"<p>1. Research Experience \u2b50 Most Important! - Publications (even as co-author) - Conference presentations - Research projects with clear outcomes</p> <p>2. Letters of Recommendation (Usually 3) - Research supervisors who know your work well - Professors from relevant courses - Professional mentors</p> <p>3. Personal Statement/Statement of Purpose - Why this field? Why this program? - Your research interests and career goals - How your experience has prepared you</p> <p>4. Academic Records - Transcripts from all institutions - Strong GPA in relevant courses</p> <p>5. Standardized Tests (Check requirements!) - GRE (Graduate Record Examination) - Some programs dropping this requirement - Subject GRE (if required for your field)</p> <p>6. CV/Resume - Research experience, publications, presentations - Relevant coursework, skills, awards - Teaching or outreach experience</p>"},{"location":"How-to-Grad-School-Slides/#application-tips","title":"Application Tips:","text":"<p>\u2705 Apply broadly - 6-12 programs is typical \u2705 Contact faculty ahead of time - Email potential advisors \u2705 Visit programs if possible - Meet students and faculty \u2705 Apply for fellowships - NSF GRFP, EPA STAR, etc. \u2705 Start early - Applications often due in December/January</p>"},{"location":"How-to-Grad-School-Slides/#slide-6-the-graduate-school-experience","title":"Slide 6: The Graduate School Experience \ud83c\udfaf","text":""},{"location":"How-to-Grad-School-Slides/#what-to-expect","title":"What to Expect","text":"<p>First Year: - Coursework (usually 2-3 classes per semester) - Lab rotations (try different research groups) - Teaching assistant duties - Developing research proposal</p> <p>Years 2-3 (Master's) / 2-5 (PhD): - Focus shifts to research - Comprehensive exams (PhD) - Thesis/dissertation research - Conference presentations - Possible publications</p> <p>Final Year: - Writing thesis/dissertation - Job market preparation - Defense of research</p>"},{"location":"How-to-Grad-School-Slides/#funding-your-education","title":"Funding Your Education","text":"<ul> <li>Teaching Assistantships: Teach labs or lead discussion sections</li> <li>Research Assistantships: Work on funded research projects  </li> <li>Fellowships: Competitive awards (NSF GRFP, EPA STAR)</li> <li>Grants: Apply for research funding for your projects</li> </ul>"},{"location":"How-to-Grad-School-Slides/#challenges-and-rewards","title":"Challenges and Rewards","text":"<p>Challenges: - Long hours, uncertain outcomes - Steep learning curve - Balancing coursework and research - Mental health and work-life balance</p> <p>Rewards: - Contributing new knowledge to science - Developing expertise in your passion - Mentoring relationships - Travel opportunities for fieldwork and conferences - Job satisfaction and career flexibility</p>"},{"location":"How-to-Grad-School-Slides/#slide-7-career-opportunities-after-grad-school","title":"Slide 7: Career Opportunities After Grad School \ud83d\udcbc","text":""},{"location":"How-to-Grad-School-Slides/#academic-careers","title":"Academic Careers","text":"<p>Professor/Faculty (PhD required) - Research universities (R1): Focus on research + some teaching - Teaching universities: Focus on teaching + some research - Community colleges: Teaching-focused</p> <p>Postdoctoral Researcher (PhD required) - 2-5 years additional training after PhD - Develop independence, publish papers, apply for faculty jobs</p>"},{"location":"How-to-Grad-School-Slides/#government-careers","title":"Government Careers","text":"<p>Federal Agencies: - NOAA (National Oceanic and Atmospheric Administration) - EPA (Environmental Protection Agency) - USGS (US Geological Survey) - National Park Service - Fish and Wildlife Service</p> <p>State and Local: - Departments of Natural Resources - Environmental consulting - Water management districts</p>"},{"location":"How-to-Grad-School-Slides/#industry-careers","title":"Industry Careers","text":"<p>Environmental Consulting - Impact assessments, restoration projects - Regulatory compliance</p> <p>Aquaculture - Fish/shellfish farming operations - Feed development, breeding programs</p> <p>Biotechnology - Environmental monitoring tools - Pharmaceutical development from marine organisms</p> <p>Data Science - Environmental modeling - Climate analysis - Fisheries stock assessments</p>"},{"location":"How-to-Grad-School-Slides/#non-profit-sector","title":"Non-Profit Sector","text":"<ul> <li>Conservation organizations</li> <li>Environmental advocacy</li> <li>Science communication and education</li> <li>Policy think tanks</li> </ul>"},{"location":"How-to-Grad-School-Slides/#science-communication","title":"Science Communication","text":"<ul> <li>Science writing and journalism</li> <li>Museum education</li> <li>Science policy</li> <li>Outreach and public engagement</li> </ul>"},{"location":"How-to-Grad-School-Slides/#salary-expectations","title":"Salary Expectations","text":"<p>Entry Level (Master's): $40,000-70,000 Mid-Career (PhD): $60,000-120,000 Senior Level: $80,000-200,000+</p> <p>Varies significantly by sector, location, and specialization</p>"},{"location":"How-to-Grad-School-Slides/#slide-8-getting-started-action-steps","title":"Slide 8: Getting Started - Action Steps \ud83d\ude80","text":""},{"location":"How-to-Grad-School-Slides/#for-high-school-students","title":"For High School Students:","text":"<ol> <li>Take challenging science and math courses</li> <li>Look for local research opportunities (museums, field stations, universities)</li> <li>Participate in science fairs and competitions</li> <li>Consider marine science summer programs</li> <li>Volunteer with environmental organizations</li> </ol>"},{"location":"How-to-Grad-School-Slides/#for-undergraduates","title":"For Undergraduates:","text":"<ol> <li>Connect with faculty - Visit office hours, express interest in research</li> <li>Apply for summer research programs (REU sites, field stations)</li> <li>Join professional societies (student memberships are cheap!)</li> <li>Attend conferences - Great for networking and seeing cutting-edge research</li> <li>Start building your CV - Document all your experiences</li> </ol>"},{"location":"How-to-Grad-School-Slides/#questions-to-ask-yourself","title":"Questions to Ask Yourself:","text":"<ul> <li>Am I passionate enough about this field to dedicate 2-7 years to intensive study?</li> <li>Do I enjoy problem-solving and working with uncertainty?</li> <li>Am I comfortable with the lifestyle and career prospects?</li> <li>Do I have the academic preparation needed?</li> </ul>"},{"location":"How-to-Grad-School-Slides/#resources-at-university-of-washington","title":"Resources at University of Washington:","text":"<ul> <li>Undergraduate research opportunities: SAFS Research and Internships</li> <li>Graduate program information: SAFS Graduate Program</li> <li>Funding opportunities: Scholarships and Funding</li> <li>Research symposium: Undergraduate Research Symposium</li> </ul>"},{"location":"How-to-Grad-School-Slides/#slide-9-final-thoughts","title":"Slide 9: Final Thoughts \ud83d\udcad","text":""},{"location":"How-to-Grad-School-Slides/#graduate-school-is-not-for-everyone-and-thats-ok","title":"Graduate School Is Not for Everyone - And That's OK!","text":"<p>Consider grad school if you: - Love learning and asking research questions - Want to become an expert in a specific area - Enjoy working independently - Are passionate about contributing new knowledge - See yourself in a career that requires advanced training</p> <p>Alternative paths: - Industry positions with Bachelor's degree - Professional certifications - Technical training programs - Gaining experience first, then returning to school later</p>"},{"location":"How-to-Grad-School-Slides/#remember","title":"Remember:","text":"<ul> <li>There's no single \"right\" path to a successful career in science</li> <li>You can always change directions - many successful scientists have non-linear career paths</li> <li>Your undergraduate years are for exploring - try different research areas!</li> <li>Seek mentorship - Find faculty, graduate students, or professionals who can guide you</li> </ul>"},{"location":"How-to-Grad-School-Slides/#slide-10-questions-discussion","title":"Slide 10: Questions &amp; Discussion \ud83e\udd14","text":""},{"location":"How-to-Grad-School-Slides/#common-questions","title":"Common Questions:","text":"<p>Q: Do I need research experience to get into grad school? A: For research-focused programs, yes! Start as early as possible.</p> <p>Q: What if I don't know exactly what I want to study? A: That's normal! Use undergrad to explore different areas through courses and research.</p> <p>Q: How important is the GRE? A: Many programs are moving away from requiring it. Check specific program requirements.</p> <p>Q: Should I take time off between undergrad and grad school? A: Can be valuable for gaining experience, but maintain connections to academic community.</p> <p>Q: How do I know if a graduate program is a good fit? A: Visit if possible, talk to current students, and research the faculty and their work.</p>"},{"location":"How-to-Grad-School-Slides/#connect-with-us","title":"Connect With Us:","text":"<ul> <li>Roberts Lab Resources: github.com/RobertsLab/resources</li> <li>UW SAFS: fish.uw.edu</li> <li>Questions? Reach out to current graduate students or faculty!</li> </ul> <p>This presentation is part of the Roberts Lab outreach efforts. For more information about graduate school opportunities in aquatic and fishery sciences at the University of Washington, visit our lab resources.</p>"},{"location":"Lab-Communication/","title":"Lab Communication","text":"<p>An overarching philosophy on lab communication is inclusivity and leveraging the common wisdom. Further, the intent is that prior conversations and issues (hopefully resolved) can be found by others (and future you). To that end, email is often considered a last resort. A side benefit is this should reduce email anxiety and overload. </p>"},{"location":"Lab-Communication/#slack","title":"Slack","text":"<p>Our means of general communication in the lab is through Slack. This is in lieu of email, providing a simple means of archiving, searching, and easy user management. IMPORTANT: This is considered to be ethereal in nature. Anything worth coming back to needs to live somewhere else.</p>"},{"location":"Lab-Communication/#github-issues","title":"GitHub Issues","text":"<p>A critical form of lab communication is via RobertsLab/resources GitHub Issues. This serves as a catch-all for problems, concerns, troubleshooting, purchasing, wish list, lab meeting topics, and other miscellaneous things that you might need help with (also for which the ideas/resolutions might be useful for the rest of the lab).</p>"},{"location":"Lab-Communication/#lab-meetings","title":"Lab Meetings","text":"<p>We generally have weekly lab meetings. These can be attended in person or remotely via video/audio chat. Steven will post link(s) for joining the chats in Slack and/or in the event on the Roberts Lab Google Calendar.</p> <p>We alternate between a DEI focus and academic discovery. Themes can be found below. In general we will use DEI slots for a book club focused discussion and academic discovery will be a mix of modules including but not limited to...</p> <ul> <li>coding mini lectures    </li> <li>list of knowledge gaps    </li> <li>journal club (potential model - foundational paper coupled with new paper)    </li> <li>formal presentations (including practice talks)   </li> <li>revisit common tasks (eg writing, ref managing, notebooks)   </li> <li>round robin code show and tell   </li> <li>handbook focus (update / highlight)</li> <li>peer feedback   </li> <li>data workshop   </li> <li>issue triage</li> <li>website update</li> <li>specific Q &amp; A</li> </ul> <p>A traditional update with be rolled into new format that might include presentation or simply recent notebook posts.</p> <p>If you have any suggestions for topics, papers, demos (or anything for lab meeting) please submit here.</p> <p>go here to edit sheet</p>"},{"location":"Lab-Inventory/","title":"Lab Inventory","text":""},{"location":"Lab-Inventory/#general","title":"General","text":"<ul> <li> <p>Roberts Lab Inventory (includes refrigerators and -20C freezers)   See also Purchase Log to confirm existence and location</p> <ol> <li> <p>After receipt of new item(s), review the Roberts Lab Inventory and the Purchase Log to see if there's an established location for the item(s).</p> </li> <li> <p>If the item(s) have an existing storage location, put the new item(s) in the same location.</p> </li> <li> <p>If the item(s) do not have an existing storage location, select a storage location, and update both the Roberts Lab Inventory and the Purchase Log with the storage location info.</p> </li> </ol> </li> </ul>"},{"location":"Lab-Inventory/#-80-freezer","title":"-80 Freezer","text":"<ul> <li> <p>-80C Freezer Inventory Map</p> <ol> <li> <p>Review the -80C Freezer Inventory Map and find and empty slot in any freezer rack.</p> </li> <li> <p>Put the box (or boxes) in any empty rack slots.</p> </li> <li> <p>Fill in the appropriate info on the -80C Freezer Inventory Map</p> </li> </ol> </li> </ul>"},{"location":"Lab-Inventory/#histology","title":"Histology","text":"<ul> <li>Histology database includes information on blocks and slides</li> </ul>"},{"location":"Lab-Inventory/#primer-databases","title":"Primer Databases","text":"<ul> <li> <p>PrimerDatabase: Descriptive Google Sheet of primers.</p> </li> <li> <p>Primer Stocks: Google Sheets workbook of primer stock tube storage locations within FTR 213 -20<sup>o</sup>C freezer.</p> </li> </ul>"},{"location":"Lab-Notebooks/","title":"Lab Notebooks","text":"<p>We have been using online lab notebooks since 2007 and the platforms and workflows have certainly changed over the years. Below is a compendium of best practices based on our experience and the particular research we do. This is intended for those in our lab group, however comments and suggestions are welcome.</p> <p>An online lab notebook is required of all lab members. Entries need to be organized by date and in reverse chronological order, and Updated daily.</p>"},{"location":"Lab-Notebooks/#notebooks","title":"Notebooks","text":"Person Notebook Commitment Steven Roberts sr320.github.io Sam White robertslab.github.io Matt George mattgeorgephd.github.io Aspen Coyle aspencoyle.github.io Olivia Cattau ocattau.github.io Delaney Lawson drlawson.github.io Ariana Huffmyer ahuffmyer.github.io Chris Mantegna chrismantegna.github.io Zach Bengtsson zbengt.github.io Celeste Valdivia valeste.github.io Larken Root larkenr.github.io Laura Spencer laurahspencer.github.io Yaamini Venkataraman yaaminiv.github.io Grace Crandall grace-ac.github.io Shelly Trigg shellytrigg.github.io/notebook Kathleen Durkin shedurkin.github.io Megan Ewing meganewing.github.io/mewing-notebook"},{"location":"Lab-Notebooks/#platforms","title":"Platforms","text":"<p>The current recommendation is Quarto in Rstudio. </p> <p>See this page for a tutorial on how to set up. </p>"},{"location":"Lab-Notebooks/#make-sure-it-is-reproducible","title":"Make sure it is reproducible","text":"<p>Document in a fashion where someone could replicate your work.</p>"},{"location":"Lab-Notebooks/#document-daily","title":"Document daily","text":"<p>A record of your work should be published the day of activity. Yep, daily! Even if you feel like you did nothing, post something to describe what you did that day. Did you read some papers? Great! Make a post that lists the papers you read. Did you spend all day searching the web? Also great! Make a post about what you were searching for and how successful you were in finding what you wanted.</p>"},{"location":"Lab-Notebooks/#maintain-backup","title":"Maintain backup","text":"<p>Have a copy of your notebook in another location. This could be done in several ways. - composing in text editor and hosting on GitHub - using IFTTT to post/save entries elsewhere - run script (i.e. wget) to archive contents</p> <p>Periodically, you will be asked to show where your backup is and demonstrate that it is functional.</p> <p>All GitHub-based notebooks are also backed up to Gannet: https://gannet.fish.washington.edu/github_backups/notebooks/</p>"},{"location":"Lab-Protocols/","title":"Lab Protocols","text":""},{"location":"Lab-Protocols/#resazurin-metabolic-assay","title":"Resazurin metabolic assay","text":"<p>Resazurin metabolic assays are used to measure the metabolic rate of marine organisms. This protocol has been developed for use in oysters, but can be adapted for other organisms.   </p> <p>Contact: ashuff (at) uw (dot) edu</p>"},{"location":"Lab-Protocols/#standard-operating-protocol-sop","title":"Standard Operating Protocol (SOP)","text":"<p>Updated 20250813 by Ariana Huffmyer.  </p>"},{"location":"Lab-Protocols/#repository","title":"Repository","text":"<p>Example data sets, scripts, and resources can be found at our GitHub repository here. </p>"},{"location":"Lab-Protocols/#overview","title":"Overview","text":"<p>This protocol details general approaches for resazurin metabolic rate measurements in oysters. The protocol can be adapted for various sizes, temperature profiles, or different stress exposures following this base protocol.  </p>"},{"location":"Lab-Protocols/#materials-and-preparing-solutions","title":"Materials and preparing solutions","text":""},{"location":"Lab-Protocols/#stock-resazurin-solution","title":"Stock resazurin solution","text":"<p>To make the resazurin stock solution (10 mL) mix the following. We will use this solution for multiple trials.  </p> <ul> <li>0.5 g resazurin salt</li> <li>10 mL DI water</li> <li>10 \u00b5L DMSO</li> </ul> <p>Store in a dark fridge or freezer.  </p>"},{"location":"Lab-Protocols/#containers","title":"Containers","text":"<p>Here are some suggested vessels for conducting trials. The animals should be fully submerged. </p> <ul> <li>Small seed (&lt;7mm length): trials conducted in 48 or 96 well plates </li> <li>Medium seed (15-40 mm length): trials conducted in 12 or 24 well plates or small plastic cups </li> <li>Large seed/adults (&gt;40 mm length): trials can be conducted in tripour cups, beakers, or plastic cups. Scale volume appropriately. </li> </ul> <p>We recommend performing preliminary trials to ensure that a change in resazurin fluorescence can be detected over the time scale desired. </p>"},{"location":"Lab-Protocols/#sample-sizes","title":"Sample sizes","text":"<p>Plan your sample sizes appropriately depending on your research question. Metabolic rates are variable, so we recommend at least n=20 per experimental group as a minimum (higher replication is best). </p> <p>When selecting containers and volume of solutions, remember to account for blanks. We recommend if you use plates that you include n=3-8 blanks per plate and if using cups, we recommend n=5-10 blanks per temperature/stress/experimental treatment. </p>"},{"location":"Lab-Protocols/#working-resazurin-solution","title":"Working resazurin solution","text":"<p>First, determine the volume of resazurin required depending on the size of your organism, the number of blanks and samples, and the container size as described above. </p> <p>To prepare the working solution of resazurin, prepare the following.\u00a0</p> <ul> <li> <p>Desired working volume x 0.98666 = ___ mL filtered seawater (DI water with Instant Ocean adjusted to 23-25 ppt     or filtered (\\&lt;1um) seawater)\u00a0</p> </li> <li> <p>Desired working volume x 0.00222 = ___ mL resazurin stock solution as made above in step 1\u00a0</p> </li> <li> <p>Desired working volume x 0.001 = ___ mL DMSO</p> </li> <li> <p>Desired working volume x 0.01 = ___ mL  antibiotic solution\u00a0100x Penn/Strep &amp; 100x Fungizone. This should be kept frozen in a dark freezer and thawed before use (thaw in the dark or cover with aluminum foil)</p> </li> </ul> <p>Store at 4\u00b0C in dark fridge until use. We recommend making a fresh batch of working stock within 7 days of use.  </p> <p>For example, here is a recipe for 150 mL of working stock. </p> <ul> <li>148 mL seawater </li> <li>333 \u00b5L resazurin stock solution </li> <li>150 \u00b5L DMSO</li> <li> <p>1.5 mL antibiotic solution  </p> </li> <li> <p>Supplies </p> </li> <li> <p>Bench top incubators </p> </li> <li>Temperature loggers to be placed in incubators at treatment conditions </li> <li>Paper towels and bench paper/pads </li> <li>Tweezers, transfer pipettes, and forceps </li> <li>Dissecting microscope </li> <li>Spectrophotometer plate reader that detects fluorescence and associated software</li> <li>Plate reader filters (if required) with excitation wavelength of 530 and emission wavelength of 590 (we are currently using an excitation 528 wavelength filter with a bandpass of 20 and an emission 590 wavelength filter with a bandpass of 20)  </li> <li>Pipettes and tips </li> <li>Scale bar/ruler</li> <li>Camera/phone camera</li> <li>Plastic cups, beakers, plates, or other vessel for incubations</li> <li>Plates, cups, or beakers </li> </ul> <p>Label plates with identifying number (e.g. \"Plate 1\", \"Plate 2\") or label cups with unique numbers/identifiers.    </p>"},{"location":"Lab-Protocols/#protocol","title":"Protocol","text":"<p>Conduct measurements at treatments desired. We typically conduct measurements at a control temperature and a high temperature. If multiple treatments are desired over multiple days, be sure to run a control treatment each day as reference. Ensure you account for tank effects or other batch effects by randomizing loading order, position in incubators, etc. </p> <p>For oysters, we have used the following treatments to detect metabolic responses to stress: </p> <ul> <li>For acute stress and survival testing: control temperature (10-20\u00b0C) and acute high temperature (36-42\u00b0C)</li> <li>For thermal performance testing: control temperature (10-20\u00b0C), and a gradient of temperatures from 25\u00b0C-45\u00b0C. </li> <li>Acute stress (40\u00b0C) for 2 hours followed by cooling/stabilizing temperatures (counter top or fridge for 2 hours) </li> <li>Static measurements at non stressful temperatures to characterize metabolic rate variability between groups (e.g., 28\u00b0C) </li> </ul> <p>We strongly recommend preliminary testing to determine appropriate temperature treatments for your study system and research question.  </p>"},{"location":"Lab-Protocols/#time-points","title":"Time points","text":"<p>Resazurin measurements should be collected on a timescale appropriate for your research question. Typically, we run assays over a 3-6 hour period with measurements collected every 30-60 minutes. For example, here is a typical schedule for a day in which we are conducting 5 hour incubations at a control and high temperature. </p> <p>08:00-09:00: Load plates with oysters, take size images, and load resazurin solution  09:00: Time 0 measurement  10:00: Time 1 measurement  11:00: Time 2 measurement 12:00: Time 3 measurement 13:00: Time 4 measurement  14:00: Time 5 measurement  14:00-16:00: Clean up and assess survival (if needed)  </p>"},{"location":"Lab-Protocols/#load-and-prepare-samples","title":"Load and prepare samples","text":"<p>Before starting, set the incubator at the desired temperature or set up your treatments.  </p> <ol> <li>Prepare animals for assays. Track the source tank, treatment, or other identifying information. </li> <li>Add animals into labeled plates or containers and placing them into the empty container.</li> <li>Add blanks (see recommendations above). </li> <li>Write the location of wells on a plate map if using plates. </li> <li>Allocate the animals either into their designated cup or onto the lid of the plate. </li> <li>Take images of each animal with a scale bar with their identifying information in the photograph. See an example below.  </li> <li>Move the animals into their respective wells in the plate if you placed them on the lid for a photograph. </li> <li>Fill each well with the desired amount of resazurin working stock at ambient temperature using a microchannel pipette or graduated cylinder. </li> </ol> <p>An example of photograph for size measurements:  </p> <p> </p> <p>Measure size using ImageJ or other imaging software. We typically use maximum shell length (mm) for size normalization.  </p>"},{"location":"Lab-Protocols/#measurements","title":"Measurements","text":"<ol> <li>Turn on the computer and plate reader. Open the plate reader software.</li> <li>Create a new protocol that conducts end point measurements from the top of the plate using an excitation wavelength of 530 and emission wavelength of 590 nm. </li> <li>Name the protocol and save. This process may vary depending on your instrument.</li> <li>Take a T0 initial measurement - this is critical! If using a plate, you can place the plate with the animals directly on the plate reader (do not have the lid on the plate). If you have animals in cups, take a small sample (250uL) of the resazurin liquid from each container, place into a 96-well plate, and then conduct the measurements. If you use this method, be sure to make a plate map of the location of the samples and identifying information. Conduct measurements for blanks and samples.  </li> <li>Collect and export readings as directed in the plate software. </li> <li>Save the file with a descriptive name. For example,  <code>YYYYMMDD_TemperatureTreatment_Plate#_T0.xlsx</code>. </li> <li>Save the data to a flash drive and add to GitHub or data repository. </li> <li>Record the time of the measurement.</li> <li>Repeat for any remaining plates or treatments. </li> <li>Take temperature measurements in wells or cups if relevant. </li> <li>Move the animals to the incubator at their respective temperatures and record the temperature in the incubators. </li> <li>Repeat at 1, 2, 3, 4, and 5 hours of incubation as necessary for your experiment.  </li> </ol>"},{"location":"Lab-Protocols/#survival-measurements","title":"Survival measurements","text":"<ol> <li>Either each hour (if you can easily see the animals in larger cups) or at the end of the incubation (for animals in 96 well plates), conduct survival assessments. Note that it is critical to perform survival assessments so that you can analyze resazurin metabolic response for those that survive and those that die during the trials. If performing trials in 96 well plates or other small containers, we recommend performing survival assessment at the end of the incubation. If you are conducting trials in larger cups where you can see the animals without removing the resazurin solution, you can assess survival at each time point.  </li> <li>If using plates, prepare a plate map for recording the assessments - this is an easy method to keep track of the assessments. If you are not using plates, make a list of all samples with columns for recording survival at each time point.  </li> <li>If working with shellfish, use tweezers/forceps to take each animal out and examine in a petri dish filled with DI water under a dissecting scope. Determine if the oyster is dead by placing the cup side of the oyster down and gently taping/moving the shell. If the shell is open and remains open after tapping, the oyster is dead. If the shell is closed tight or closes after tapping, the oyster is alive. Use other determination methods for other organisms. </li> <li>Record any notes of oysters that were damaged by the tweezers or record any other notes of interest. </li> <li>After examining each oyster, move it to a beaker. Discard oysters after the measurements are done. </li> <li>Generate a data frame that has columns for sample ID, treatments, date, and other relevant information. Add a column designated \"mortality\" and add a 0 for alive and 1 for dead animals. Edit as required for your specific analysis. </li> </ol>"},{"location":"Lab-Protocols/#waste-disposal","title":"Waste disposal","text":"<p>Resazurin solution can be washed down the sink and flushed with plenty of water. Rinse containers thoroughly.   </p>"},{"location":"Lab-Protocols/#data-preparation-and-analysis","title":"Data preparation and analysis","text":"<p>Prepare the following data frames (see examples at our repository): </p> <ul> <li>Size measurements: columns for sample ID, date, treatment, and size measurement (e.g., length in mm)</li> <li>Mortality assessment: columns for sample ID, date, treatment, and mortality assessment (e.g., 0 for alive and 1 for dead)</li> <li>Metadata: columns for sample ID, date, treatment, tank or batch effects, species, well/cup ID, and sample type (i.e., \"blank\" or \"sample\") </li> <li>Resazurin files: files exported from plate reader software that contain fluorescence readings for each well of the plate</li> </ul> <p>Conduct the following analysis steps (see R scripts available for use in our repository):  </p> <ul> <li>Read in data</li> <li>Normalize all fluorescence values to the initial time point (fluorescence at time X divided by fluorescence at time 0) - do this for samples and blanks</li> <li>Calculate the mean value for normalized blanks within each unit (e.g., mean of all blanks in each plate at each time point)</li> <li>Subtract the mean blank value from the fluorescence value of each sample from the respective unit and time point</li> <li>Size normalize the data by dividing fluorescence values by size of each sample</li> <li>Proceed with visualization and statistical analyses, including testing for effects of treatment or other effects of interest and examining metabolic differences between animals that lived and animals that died during the trials. See examples in our GitHub repository. </li> </ul>"},{"location":"Lab-Protocols/#aquarium-nitrogen-testing-kit-protocols-aqi-test-kit","title":"Aquarium nitrogen testing kit protocols (AQI test kit)","text":"<p>Written by Noah Ozguner and Madeliene Baird 20250401.  </p> <p>This protocol is written based on the manufacturer's instructions. </p> <p>Test kit was ordered here</p>"},{"location":"Lab-Protocols/#standard-operating-protocol-sop_1","title":"Standard Operating Protocol (SOP)","text":"<p>After testing, do not pour contents back into the tank. Make sure to rinse test tubes after use. </p>"},{"location":"Lab-Protocols/#ph-kit-minimum-74-maximum-88","title":"pH (kit minimum 7.4, maximum 8.8)","text":"<ul> <li>Fill a clean test tube with 5 ml of water </li> <li>Add 5 drops of High range pH Test Solution</li> <li>Cap the test tube and invert it multiple times to mix the solution</li> <li>Read results by comparing the color of the solution to the provided pH color chart (in a relatively well lit area). The closest color match indicates the pH value of the water sample. </li> <li>Thoroughly wash test tube after use</li> </ul>"},{"location":"Lab-Protocols/#ammonia-ppm-or-mgl-two-bottles","title":"Ammonia (ppm or mg/L) [two bottles]","text":"<ul> <li>Fill a clean test tube with 5 ml of water </li> <li>Add 8 drops of Ammonia Test Solution 1</li> <li>Add 8 drops of Ammonia Test Solution 2</li> <li>Cap the test tube and shake vigorously for 5 seconds</li> <li>Wait 5 minutes for color to develop</li> <li>Read results by comparing the color of the solution to the provided Ammonia color chart. (in a relatively well lit area). The closest color match indicates the Ammonia value of the water sample. </li> <li>Thoroughly wash test tube after use</li> </ul>"},{"location":"Lab-Protocols/#nitrite-ppm-or-mgl","title":"Nitrite (ppm or mg/L)","text":"<ul> <li>Fill a clean test tube with 5mL of water</li> <li>Add 5 drops of Nitrite Test Solution</li> <li>Cap the test tube and shake for 5 seconds</li> <li>Wait 5 minutes for color to develop</li> <li>Compare the color of the solution to the Nitrite Color Chart in a well lit area. The closest match will indicate the ppm (mg/L) of the nitrite in the sample</li> <li>Thoroughly wash test tube after use</li> </ul>"},{"location":"Lab-Protocols/#nitrate-ppm-or-mgl-two-bottles","title":"Nitrate (ppm or mg/L) [two bottles]","text":"<ul> <li>Fill a clean test tube with 5mL of water</li> <li>Add 10 drops of Nitrate Test Solution #1</li> <li>Cap the test tube and invert several times to mix the solution</li> <li>Vigorously shake the Nitrate Test Solution #2 for at least 30 seconds</li> <li>Add 10 drops of Nitrate Test Solution #2</li> <li>Cap the test tube and shake vigorously for 1 minute</li> <li>Wait 5 minutes for the color to develop</li> <li>Compare the color of the solution to the Nitrate Color Chart in a well lit area. The closest match will indicate the ppm (mg/L) of the nitrite in the sample</li> <li>Thoroughly wash test tube after use</li> </ul>"},{"location":"Lab-Protocols/#reference-values","title":"Reference values","text":"<p>Ammonia (NH3): Ammonia is highly toxic to fish and should always be 0 ppm.  </p> <p>Nitrite (NO2): Nitrite is also toxic and should be 0 ppm.  </p> <p>Nitrate (NO3): While less toxic than ammonia and nitrite, nitrate can still be harmful to fish and corals at high levels. Aim to keep nitrate levels below 20 ppm, and ideally between 0-5 ppm.  </p>"},{"location":"Lab-Safety/","title":"Roberts Lab Safety","text":""},{"location":"Lab-Safety/#in-any-emergency-dial-911-from-any-laboratory-phone","title":"In any emergency, dial 911 from any laboratory phone.","text":""},{"location":"Lab-Safety/#before-beginning-any-work-in-the-laboratory-please-complete-the-following","title":"Before beginning any work in the laboratory, please complete the following:","text":"<ol> <li> <p>Read through the Personal Protective Equipment (PPE) Hazard Assessment for our lab:</p> <ul> <li>Personal Protective Equipment (PPE) Hazard Assessment</li> </ul> </li> <li> <p>Print the UW Lab PPE Assessment Completion form, fill in the fields, and return to Sam:</p> <ul> <li>UW Lab PPE Assessment Completion form</li> </ul> </li> <li> <p>Print the UW Roberts Lab-specific Training guide:</p> <ul> <li> <p>UW Lab Training guide</p> <ul> <li>NOTE: If you will be shipping hazardous goods (i.e. dry ice and/or ethanol), please print this form instead: UW Lab Training guide with shipping</li> </ul> </li> <li> <p>Complete all the trainings marked \"Yes\". Online training is available here:</p> <ul> <li>UW EH&amp;S Training</li> </ul> </li> <li>Fill out the date you completed each of the trainings</li> <li>Print/sign your name at the top of the form</li> <li>Return form to Sam</li> </ul> </li> <li> <p>Provide Sam with your UW NetID and he will add you as a user to the UW MyChem system for access to the Roberts Lab chemical inventory and Safety Data Sheets (SDS).</p> </li> <li> <p>Review our Standard Operating Protocols (SOPs) for chemical handling and disposal:</p> <ul> <li>Roberts Lab SOPs</li> </ul> </li> <li> <p>Schedule a time with Sam to tour the labs to learn the locations of phones, eye wash stations, fire extinguishers, first aid kits, emergency showers, other lab-specific points of emphasis.</p> </li> <li> <p>Download &amp; print the UW Roberts Lab-specific Training Checklist:</p> <ul> <li> <p>Lab-specific training checklist</p> </li> <li> <p>Check all boxes</p> </li> <li>Date/sign your name at the bottom of the form</li> <li>Return form to Sam</li> </ul> </li> </ol>"},{"location":"Lab-Safety/#roberts-lab-safety-resources","title":"Roberts Lab Safety Resources","text":"<ul> <li> <p>UW MyChem</p> </li> <li> <p>Roberts Lab SOPs</p> </li> </ul>"},{"location":"Lab-Safety/#official-university-of-washington-safety-resources","title":"Official University of Washington Safety Resources","text":"<p>UW Environmental Health &amp; Safety (EH&amp;S)</p> <p>UW Lab Safety Manual</p> <p>UW Online Accident Reporting System (OARS)</p> <p>Chemical Inventory &amp; Safety Data Sheets (MyChem)</p> <p>Hazardous Waste Online Collection Request</p>"},{"location":"Lab-Safety/#best-practices-for-lab-work","title":"Best Practices for Lab Work","text":"<ol> <li>Label all samples and reagents with contents, date, and name with clear and durable labels.</li> <li>Dispose of waste properly according to lab guidelines. Clearly label all waste and ensure it is stored properly. Clean up all materials used after you are finished with lab work, an experiment, etc.</li> <li>Keep the lab clean and organized by wiping down surfaces, decontaminating, throwing away trash, and maintaining equipment regularly.</li> <li>Report broken or malfunctioning lab equipment promptly and label the equipment with your name, date, and issue. Follow up to ensure equipment is repaired, discarded, or calibrated as needed.</li> <li>Maintain an up-to-date inventory of chemicals, reagents, and consumables. If you use the last of an item, please notify the lab so it can be reordered.</li> <li>Keep accurate records of experiments, protocols, and observations in physical lab notebooks and digital systems, with regular data backups. </li> <li>Follow all lab safety protocols. Wear appropriate PPE, be prepared for emergencies, and  follow safety and ethical guidelines.</li> <li>Take care of equipment and instruments in the lab. Many instruments are very expensive or difficult to repair. Ensure you know how to use an instrument and ask questions if you are unsure.</li> <li>Avoid contamination by cleaning areas before and after you conduct work in the lab and be mindful of where others are performing sensitive protocols.</li> <li>Do your part to keep the lab running smoothly. If you see that the lab needs some cleaning, picking up, or tips refilled please help! </li> </ol>"},{"location":"Lab-Software/","title":"Lab Software","text":""},{"location":"Lab-Software/#computer-raven","title":"Computer: raven","text":""},{"location":"Lab-Software/#os-ubuntu-1604","title":"OS: Ubuntu 16.04","text":""},{"location":"Lab-Software/#cpus-48","title":"CPU(s): 48","text":""},{"location":"Lab-Software/#memory-256gb","title":"Memory: 256GB","text":""},{"location":"Lab-Software/#hdd-capacity-10tb","title":"HDD Capacity: 1.0TB","text":""},{"location":"Lab-Software/#ext-hdd-1-capacity-mediaext_hdd01-10tb","title":"Ext. HDD 1 Capacity (<code>/media/ext_HDD01</code>): 1.0TB","text":""},{"location":"Lab-Software/#ext-hdd-2-capacity-mediaext_hdd01-10tb","title":"Ext. HDD 2 Capacity (<code>/media/ext_HDD01</code>): 1.0TB","text":""},{"location":"Lab-Software/#int-hdd-1-capacity-homeshared8tb_hdd_01-80tb","title":"Int. HDD 1 Capacity (<code>//home/shared/8TB_HDD_01</code>): 8.0TB","text":""},{"location":"Lab-Software/#int-hdd-2-capacity-homeshared8tb_hdd_02-80tb","title":"Int. HDD 2 Capacity (<code>/home/shared/8TB_HDD_02</code>): 8.0TB","text":"<pre><code>$/home/shared\nblast_dbs  blobtoolkit-v2.6.2  bowtie2-2.4.4-linux-x86_64  jellyfish-2.3.0  kallisto  ncbi-blast-2.11.0+  salmon-1.4.0_linux_x86_64  samtools-1.12  trinityrnaseq-v2.12.0\n</code></pre>"},{"location":"Lab-Software/#rstudio-server","title":"RStudio Server","text":"<ol> <li> <p>Activate Husky OnNet VPN service.</p> </li> <li> <p>Paste the following URL in your internet browser:</p> <ul> <li> <p><code>http://172.25.149.12:8787</code></p> </li> <li> <p>If you receive a notice from your browser regarding \"insecure connection\", you may safely ignore this and proceed.</p> </li> </ul> </li> <li> <p>Use login credentials provided by Steven or Sam.</p> </li> <li> <p>If you encounter any issues, please create a new Issue. Please post screenshots and paste text of any error messages you encounter.</p> </li> </ol>"},{"location":"Lab-Software/#computer-woodpecker","title":"Computer: woodpecker","text":""},{"location":"Lab-Software/#os-windows-7-enterprise-64-bit","title":"OS: Windows 7 Enterprise (64-bit)","text":"<p>Microsoft Office 2016 Pro Plus</p> <pre><code>      path = C:\\Program Files\\Microsoft Office\n</code></pre> <p>Protein Digest Simulator v2.2.6138.19320</p> <pre><code>      path = C:\\Program Files (x86)\\ProteinDigestionSimulator\n</code></pre> <p>Proteowizard v3.0.10577</p> <pre><code>      path = C:\\Program Files\\ProteoWizard\\ProteoWizard 3.0.10577\n</code></pre> <p>Skyline v3.6</p> <pre><code>      path =\n</code></pre>"},{"location":"Lab-Software/#computer-swan","title":"Computer: swan","text":""},{"location":"Lab-Software/#os-windows-7-enterprise-64-bit_1","title":"OS: Windows 7 Enterprise (64-bit)","text":"<p>Microsoft Office Professional 2016 64-bit - Access - Excel - Power Point - Word</p> <p>R v3.4.2</p> <p>R Studio 1.1383</p> <p>Skyline v3.7.0.11317</p> <p>Skyline Daily v3.7.1.11446</p> <p>Virtual Clonedrive v5.5.0.0</p> <p>ProteoWizard 3.0.11516 64-bit - MSConvert - SeeMS</p> <p>LabX v. 8.0.0 Build 3444</p> <p>Protein Digest Simulator v2.2.6471; September 19, 2017</p>"},{"location":"Onboarding/","title":"Onboarding","text":"<p>Onboarding to the Roberts Lab at the University of Washington.</p> <p>For newcomers, please read the following pages. Please read carefully, complete any required tasks (e.g. safety documentation).</p> <ol> <li> <p>Code of Conduct</p> </li> <li> <p>Lab Safety</p> </li> <li> <p>Lab Notebooks</p> </li> <li> <p>Data Management</p> </li> <li> <p>Lab Communication</p> </li> <li> <p>Computing</p> </li> </ol>"},{"location":"Onboarding/#lab-iaqs","title":"Lab IAQs","text":"<p>(Initially Asked Questions) or TLDR Handbook</p>"},{"location":"Onboarding/#what-things-do-i-need-to-do-to-get-connected","title":"What things do I need to do to get \"connected\"?","text":"<p>Get on lab Slack, added to the lab GitHub Organization, added to Lab Calendar, attend Lab Meetings, post regularly to your lab notebook.</p>"},{"location":"Onboarding/#what-do-i-need-to-have-on-my-devices-to-get-started","title":"What do I need to have on my device(s) to get started?","text":"<ul> <li>shell</li> <li>git    </li> <li>GitHub Desktop   </li> <li>RStudio   </li> </ul>"},{"location":"Onboarding/#what-do-you-recommend-for-learning-more-about-the-process-and-output-of-the-labss-scientific-endevours","title":"What do you recommend for learning more about the process and output of the labs's scientific endevours?","text":"<ul> <li>tusk</li> <li>FISH546</li> </ul>"},{"location":"Onboarding/#getting-connected-at-the-university-of-washington","title":"Getting connected at the University of Washington","text":"<p>At the University of Washington, there are a number of departments, schools, programs, institutes, and people that you may find beneficial to connect with. Below are some resources to help get you connected.</p>"},{"location":"Onboarding/#dei-groups-committees-centers-and-resources","title":"DEI Groups, Committees, Centers, and Resources","text":"<p>This is a list (non-exhaustive) of DEI groups, committees, centers, and resources available to you at UW and beyond: Our DEI page</p>"},{"location":"Onboarding/#listservs","title":"Listservs","text":"<p>If you experience any problems in joining these listservs, email SAFS computing administrator, Michael Parker (safshelp@uw.edu)</p> <ul> <li>SAFS social safssocial@uw.edu: click here to join</li> <li>SAFS job postings safsjobs@uw.edu: click here to join</li> <li>SAFS community Slack: click here to join. If you have trouble joining, email Steven Roberts (sr320@uw.edu)</li> </ul>"},{"location":"Onboarding/#undergraduate-students","title":"Undergraduate students","text":"<ul> <li>SAFS Undergraduate Resources: Research and Internships, Study Abroad</li> <li>SAFS Undergraduate funding</li> <li>Undergraduate Research Symposium</li> <li>College of the Environment's undergraduate research journal, FieldNotes</li> </ul>"},{"location":"Onboarding/#graduate-students","title":"Graduate students","text":"<ul> <li>UW Graduate School</li> <li>Graduate Opportunities and Minority Achievement Program (GO-MAP): Community for graduate students of color across the three UW campuses</li> <li> <p>Graduate and Professional Student Senate (GPSS)</p> </li> <li> <p>UW College of the Environment</p> </li> <li>Graduate student resources</li> <li>listserv environment_grads@uw.edu : Stay updated on graduate student opportunities and seminars. Click here to join</li> <li> <p>CoEnv travel funding</p> </li> <li> <p>SAFS Graduate Program</p> </li> <li>Assistant Director of Student Services and DEI: Samantha Scherer (iamsams@uw.edu)</li> <li>HR Mananger : Amy Fox (amyfox@uw.edu) </li> <li>Fisheries Interdisciplinary Network of Students (FINS): Graduate student organization within the School of Aquatic and Fishery Sciences. In addition to serving as an umbrella organization for several graduate student committees, FINS also raises funds to support student travel to conferences and organizes academic and social events throughout the year.<ul> <li>Student travel and conference awards</li> </ul> </li> <li>listserv safsgrads@uw.edu: click here to join</li> <li>SAFS Graduate Student Slack: click here to join</li> </ul>"},{"location":"Onboarding/#postdocs","title":"Postdocs","text":"<ul> <li> <p>UW Office of Postdoctoral Affairs</p> <ul> <li>UW Office of Postdoctoral Affairs listserv: to join, send an email request to uwopa@uw.edu</li> <li>UW Postdoc Association Twitter: @UWPostDocs</li> <li>UW Postdoc Association Slack channel: to join, send an email request to uwpa@uw.edu</li> <li>Postdoc Parenting Group</li> <li>Postdoc Diversity Alliance</li> </ul> </li> <li> <p>UW College of the Environment Postdocs</p> <ul> <li>more CoEnv Postdoc resources: https://environment.uw.edu/intranet/academics/postdoctoral-resources/</li> <li>listserv environment_postdocs@uw.edu : Stay in the loop on career preparation seminars, career panels, opportunities to give practice talks, etc. To join, email the CoEnv Graduate Student and Postdoctoral Services Specialist, Anthony Salazar (asalazar@uw.edu)</li> <li>CoEnv travel funding</li> </ul> </li> <li> <p>UW SAFS Postdocs</p> <ul> <li>join SAFS postdoc channel on Slack: click here to join</li> <li>join the SAFS Postdocs listserv safspostdocs@uw.edu: click here to join</li> </ul> </li> </ul>"},{"location":"Onboarding/#faculty","title":"Faculty","text":"<p>https://uwnetid.sharepoint.com/sites/safs/facultygovernance (Log in with UW net id)</p> <p>In particular under \"Policies\" 1. \"Salary recovery policy\" explains how if you have too many grants for your salary, you can use some to cover state salary, and then the state salary gets shifted to SAFS (benefits portion) and your RCR (the remainder).</p> <ol> <li> <p>\"Salary recovery policy\" teaching buyout. You can buy out from 1 quarter of teaching a small seminar course, for 1.5 mo of salary, or a large course for 2 mo of salary. Restrictions apply.</p> </li> <li> <p>\"Teaching release\", when substantially revamping a course or developing a new course, it is possible to get a one-quarter teaching release.</p> </li> </ol> <p>In addition, there are University-wide policies that some of us have signed up for: 1. A/B salary. For those who often have extra grant funding, it is possible to use the A/B salary. Your state income stays the same, but pays for only 80% or 90% of your time (basically an increase in monthly salary rate), and the extra time is covered by external grants. More details here: https://environment.uw.edu/intranet/personnel/academic-human-resources/salary-compensation/ab-salary-retention-adjustment-policy</p> <ol> <li>Personal mobile phone use for business. It is possible to cover a portion of your cell phone bill from RCR if you use your cell phone for UW business. More details here: https://www.washington.edu/admin/rules/policies/APS/55.01.html This one depends on departmental policy to some extent.</li> </ol>"},{"location":"Pubathon/","title":"Pubathon","text":"Loading\u2026"},{"location":"Pubathon/#2025-contenders","title":"2025 Contenders","text":"<p>Geoduck Env Memory Genome Paper - Hollie and Shelly et al   Working draft OSF GitHub </p> <p>Geoduck OA and reproductive development - Shelly et al Working draft Paper repo </p> <p>Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo </p> <p>CEABiGR lncRNA Zach, Yaamini et al    Working Draft Paper Repo </p> <p>Coral 3 species lncRNA Zach et al    Working Draft Paper Repo </p>"},{"location":"Pubathon/#2024-contenders","title":"2024 Contenders","text":"<p>1) CEABiGR Yaamini, Sam et al    Working Draft Paper Repo </p> <p>10) Single cell RNA-seq - Mac Working Draft GitHub </p> <p>41) Manila Clam Priming - Mac Working Draft GitHub </p> <p>10) Diploid and triploid Pacific oysters display different DNA methylation patterns following desiccation stress  - Matt Working Draft GitHub </p> <p>3) Ontogenetic shifts in metabolism and symbiotic nutritional exchange across a developmental time series in a vertically-transmitting species of reef-building coral - Ariana et al     Working draft Paper repo </p> <p>4) Thermal stress reduces photosynthate metabolism and disrupts carbon and nitrogen cycling in Montipora capitata coral larvae - Ariana Working draft Paper repo </p> <p>5) Seasonal environmental variation drives host and symbiont physiological state of three important reef-building coral species in Moorea, French Polynesia - Ariana Working draft Paper repo </p> <p>12) The impact of environmental stressors on the expression of byssal thread proteins  - Matt Working Draft GitHub </p> <p>13) Berdahl-sockeye-salmon manuscript  - Matt Working Draft GitHub </p> <p>13) Factors associated with Bitter Crab Syndrome in Southeast Alaskan Tanner crab  - Aspen Working Draft GitHub </p> <p>14) Geoduck OA and reproductive development - Shelly et al Working draft Paper repo </p> <p>14) Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo </p> <p>17) Effects of OA on Manila and Littleneck clams - Larken et al Working draft Paper repo </p> <p>18) Immune response of Pycnopodia helianthoides to Sea Star Wasting Disease - Grace C et al working draft paper repo </p> <p>19) Size class/age class Pycnopodia helianthoides exposed to sea star wasting - Grace C et al working draft project repo </p> <p>2) Geoduck Env Memory Genome Paper - Hollie and Shelly et al   Working draft OSF GitHub </p> <p>9) Mussel (Mytilus trossulus) heat stress response - Zach &amp; Chris et al  Working Draft Paper Repo </p> <p>6) Tanner crab and Hematodinium gene expression - Aspen et al Working draft Paper repo </p> <p>20) Pacific cod heat stress response - Kathleen Working Draft Project repo </p> <p>21) E5 deep dive ncRNA gene expression - Kathleen , Zach, et al. Working Draft Project repo </p> <p>22) Nature Opinion Chris    Working Draft Google Drive Folder </p> <p>23) Mussel Biomarkers Chris et al    Working Draft Paper Repo </p> <p>24) Yellow Island eDNA Chris et al   Working Draft Paper Repo </p> <p>25) Clam OA Differential Expression Megan  Working Draft Repo </p> <p>26) Ostrea lurida Sex-Determination Genes Megan  Working Draft Repo placeholder </p> <p>27) Botryllus schlosseri Nickel Genotoxciity Celeste Working Draft Repo placeholder </p> <p>28) Anthopleura elegantissima Multiple Stressors Sarah  Working Draft GitHub Project </p>"},{"location":"Pubathon/#pub-a-thon-2023","title":"Pub-a-thon 2023","text":"<p>15) CEABiGR Yaamini, Sam et al    Working Draft Paper Repo </p> <p>10) Single cell RNA-seq - Mac Working Draft GitHub </p> <p>9) Mussel (Mytilus trossulus) heat stress response - Zach &amp; Chris et al  Working Draft Paper Repo </p> <p>10) Diploid and triploid Pacific oysters display different DNA methylation patterns following desiccation stress  - Matt Working Draft GitHub </p> <p>11) The impact of ploidy on the physiological and genetic response of Pacific oysters following multiple stress exposure  - Matt Working Draft GitHub </p> <p>6) Tanner crab and Hematodinium gene expression - Aspen et al Working draft Paper repo </p> <p>7) Citrate Synthase Response and Multiple Stress in Pacific Oysters (C. gigas) - Olivia Working Draft Paper Repo </p> <p>3) Coral nutritional exchange across ontogeny - Ariana et al     Working draft Paper repo </p> <p>4) Coral nutritional exchange in larvae under thermal stress - Ariana et al     Working draft Paper repo </p> <p>5) Coral phenotypes shaped by host and symbiont physiological plasticity across environments in Moorea French Polynesia - Ariana et al     Working draft Paper repo </p> <p>8) Comparative Transcriptome Analysis of Geoduck Clam (P. generosa) - Olivia Working Draft Paper Repo 1 Paper Repo 2 </p> <p>12) The impact of environmental stressors on the expression of byssal thread proteins  - Matt Working Draft GitHub </p> <p>13) Berdahl-sockeye-salmon manuscript  - Matt Working Draft GitHub </p> <p>13) Factors associated with Bitter Crab Syndrome in Southeast Alaskan Tanner crab  - Aspen Working Draft GitHub </p> <p>14) Geoduck OA and reproductive development - Shelly et al Working draft Paper repo </p> <p>14) Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo </p> <p>15) Temp and Salinity effects on Salmon with sea lice - Shelly et al Working draft Paper repo </p> <p>17) Effects of OA on Manila and Littleneck clams - Larken et al Working draft Paper repo </p> <p>1) Proteomic response of early juvenile Pacific Oysters to temperature - Grac et al Working Draft GitHub  Journal: PeerJ     </p> <p>2) Geoduck Env Memory Genome Paper - Hollie and Shelly et al   Working draft OSF GitHub </p>"},{"location":"Pubathon/#pub-a-thon-2021","title":"Pub-a-thon 2021","text":"<p>Tier Red</p> <p>1) Geoduck Env Memory Genome Paper - Hollie et al   Working draft OSF GitHub </p> <p>4) Geoduck OA and reproductive development - Shelly et al Working draft Paper repo  Journal:</p> <p>5) Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo  Journal:</p> <p>11) Characterization of the gene repertoire and environmentally driven expression patterns in Tanner crab (Chionoecetes bairdi) - Grace Working Draft GitHub Reviews </p> <p>24) Tanner crab and Hematodinium gene expression - Aspen et al Working draft Paper repo  Journal:</p> <p>Tier Yellow</p> <p>6) Temp and Salinity effects on Salmon with sea lice - Shelly et al Working draft Paper repo  Journal:</p> <p>8) Oly epigenetics by population - Laura, Katherine, Steven Working Draft GitHub </p> <p>9) Oly pCO2 Carryover Gene Expression via QuantSeq - Laura Working Draft GitHub </p> <p>12) Proteomic response of early juvenile Pacific Oysters to temperature - Grace Working Draft GitHub </p> <p>13) Differential methylation in response to OA with diploid and triploid oysters - Yaamini Working Draft Github </p> <p>14) Differential gonad methylation in female oysters - Yaamini Working Draft Github </p> <p>15) Harnessing the Power of Single-cell RNA Sequencing to Control Reproductive Development in Bivalves - Mac Working Draft GitHub </p> <p>17) Oly WGBS - Steven Working Draft GitHub </p> <p>20) Differential gene expression in Hematodinium  - Aspen Working Draft GitHub </p> <p>22) Epigenetic response of diploidy and triploid Pacific Oysters to desiccation stress  - Matt Working Draft GitHub </p> <p>23) Cvirg Methylation and Gene Expression Working Draft Github </p> <p>Tier Blue</p> <p>2) Coupled Microbiome Analyses Highlights Relative Functional Roles of Bacteria in a Bivalve Hatchery - Emma et al   https://doi.org/10.1186/s40793-021-00376-z        Journal: Environmental Microbiome      </p> <p>3) Invertebrate methylomes provide insight into mechanisms of environmental tolerance and reveal methodological biases - Shelly and Yaamini et al Working draft Paper repo  Journal:  Molecular Ecology</p> <p>7) Latent effects of winter warming on Olympia oyster reproduction and larval viability - Laura  https://doi.org/10.1016/j.jembe.2021.151604    GitHub  Journal of Experimental Marine Biology and Ecology. doi:10.1016/j.jembe.2021.151604</p> <p>16) DNA methylation profiling of a cnidarian-algal symbiosis using nanopore sequencing - Jay  https://doi.org/10.1093/g3journal/jkab148  GitHub  Journal: G3</p> <p>21) OA impact on invertebrate reproduction - Laura and Yaamini Working Draft </p> <p>19) Chromosome-scale genome assembly of the sea louse Caligus rogercresseyi by SMRT sequencing and Hi-C analysis  https://doi.org/10.1038/s41597-021-00842-w    Journal: Scientific Data   Figshare</p>"},{"location":"Pubathon/#pub-a-thon-2020","title":"Pub-a-thon 2020","text":"<p>1) Oyster larval proteomics - 2015  -   Grace Working draft Rhonda's repo Paper repo (clean repo) </p> <p>2) Crab project - 2020  -  Grace First transcriptome working draft New transcriptome working draft Crab project repo </p> <p>3) Virginica gonad methylation - Yaamini Working draft Repo  Journal: Frontiers</p> <p>4) Gigas/Virginica gonad/offspring methylation - Yaamini Associated repo and draft coming soon</p> <p>5) Gigas/Virginica multiple tissue/method - Yaamini Associated repo and draft coming soon</p> <p>5) Oly larvae food and temp - Laura draft  Journal: Aquaculture  </p> <p>6) Oly epigenetics by population - Laura, Katherine, Steven Working Draft GitHub </p> <p>7) Geoduck Env Memory Genome Paper - Hollie et al   Working draft OSF GitHub  Journal:</p> <p>8)  Hatchery Microbiome   - Emma Working Draft WSG Final Report Megan Files Megan Publications </p> <p>9) Polydora risk to WA aquaculture - Laura Submitted Draft (pre-reviewer edits) </p> <p>10) Oly pCO2 Carryover Gene Expression via QuantSeq - Laura DRAFT LINK COMING SOON </p>"},{"location":"Pubathon/#pub-a-thon-2019","title":"Pub-a-thon 2019","text":""},{"location":"Pubathon/#wsg-bracket","title":"WSG Bracket","text":"<p>a) Hatchery Microbiome   - Emma Working Draft </p> <p>b) Geoduck pH proteomic   - Emma Working Draft </p> <p>c) Oyster larval proteomics - 2015  -   Grace Working draft Rhonda's repo Paper repo (clean repo) </p> <p>d) 2016 Temperature treated C.gigas larvae   - Shelly BioRxiv Clean Manuscript Repo Working Draft Shelly's Repo (ASCA on NSAF values, proportions test and fold change analysis on total num spectra, network analysis) Kaitlyn's Repo (with clustering analysis) Rhonda's Repo (with original survival and development data, and initial analyses) Rhonda's initial draft paper and Rhonda's other draft </p> <p>e) Winter temp/pH affect Oly reproduction &amp; larval viability (2017 exp.)  - Laura Working Draft Repo </p> <p>d) Oly larvae food and temp - Laura draft </p>"},{"location":"Pubathon/#pub-a-thon-2018","title":"Pub-a-thon 2018","text":"<p>list of papers</p> <p>1) Geoduck epigenetics and genome sequencing 1-Authorea  2-Draft - Genome Sequencing (G Docs) Repo (URL needed) </p> <p>2) Olympia Oyster WGBS Draft</p> <p>14) Oly DNA methylation and population structure.  Sam   Early Draft (Overleaf)  Repo URL Needed      </p> <p>2) Geoduck Outplant, pH/DNR Working Draft Repo </p> <p>4) 2018 Oly experiment Working Draft Repo </p> <p>6) Oil Exposure and DNA methylation in oysters  repo-URL: https://github.com/sr320/paper-Cvirg-oil  </p> <p>7) Effects of temperature change and Hematodinium sp. infection (Bitter Crab Disease) on Tanner crab (Chionoecetes bairdi) (Grace)     Working draft  repo-URL: https://github.com/grace-ac/paper-bitter-crab      </p> <p>10) Virginica gonad methylation Working draft Repo </p> <p>11) C.gigas methylation analysis Working draft Repo </p> <p>5) Response of DNA methylation to experimental transplantation in Porites astreoides Repo coming soon</p> <p>1) Adult low pH exposure influences larval abundance in Pacific oysters (Crassostrea gigas)  - Yaamini Working draft Repo reviews  Journal: JSR</p> <p>7) Gigas DNR Working draft Repo reviews  Journal: Marine Ecological Progress Series  </p> <p>3) Polydora risk to WA aquaculture Working Draft </p> <p>10) Geoduck Transcriptome  repo-URL: https://osf.io/3xf6m/    </p>"},{"location":"Pubathon/#pub-a-thon-2017","title":"Pub-a-thon 2017","text":"<p>list of papers</p> <p>17) Aquaculture and Epigenetics Repo-URL:        draft: on GoogleDocs  Journal 1: NOAA Technical Note     Journal 2: PeerJ    Response to Reviews: on GoogleDocs  PeerJ Revisions: on Google Docs</p> <p>19) Shellfish Functional Genomics  Repo-URL: https://github.com/sr320/fun-gen             draft: on GoogleDocs  Journal: JSR   </p> <p>6) Differential response to stress in Ostrea lurida (Carpenter 1864) as indicated by GENE EXPRESSION  repo-URL: https://github.com/RobertsLab/paper-Olurida-gene draft:  (see repo)     preprint:  https://peerj.com/preprints/1595/  Review Response: GoogleDocs </p> <p>21) Oyster Reproduction  / Genetics and Epigenetics  repo-URL:   draft: googledoc  Submission - Book Chapter    </p> <p>4) Puget Sound Oly Larval Performance repo-URL: https://github.com/ksil91/PS-Oly-Larvae-Growth draft: google-doc, Scientific Report version google-doc    - Paperpile     Journal: Scientific Reports    </p> <p>5) Juvenile Geoduck OA Exposure: Growth and Methylation (Hollie et al.)     repo-URL: https://github.com/hputnam/project_juvenile_geoduck_OA    draft: authorea </p> <p>10) Geoduck Transcriptome  repo-URL: https://osf.io/3xf6m/   </p> <p>13) Oly paper Megan (Megan)      repo-URL: https://github.com/MeganHintz/Paper---Oly-fingerprinting      draft: google-doc   - Paperpile</p> <p>15) Climate adaptability in Ostrea lurida (Laura)    Repo-URL: https://github.com/laurahspencer/O.lurida_Temp-OA_Gonad    draft: on GoogleDocs </p> <p>14)  C.gigas methylation analysis (Yaamini)   repo-URL: https://github.com/RobertsLab/paper-gigas-metaanalysis     draft: google-doc </p> <p>11) Oyster Hatchery 2015 Proteomics  repo-URL: https://github.com/RobertsLab/project-pacific.oyster-larvae draft: 2015 Google Doc </p> <p>23) Geoduck OA Larval Proteomics Jose    repo-URL:     draft: GoogleDoc </p> <p>20) Assessment of Toxicant Impact to Coho Salmon using a Novel Toxicogenetic Biomarker Assay  Repo-URL:        draft: on GoogleDocs </p> <p>22) Oyster Hatchery 2016 Proteomics  repo-URL: https://github.com/RobertsLab/project-pacific.oyster-larvae     draft: 2016 Google Doc </p> <p>12) Geoduck / Oyster DNR proteomics (Laura + Yaamini)     repo-URL:  https://github.com/RobertsLab/Paper-DNR-Proteomics   draft: google-doc   -  Paperpile</p> <p>18) Flounder Gene Expression  Repo-URL:        draft: on GoogleDocs </p> <p>8) Oly Pop Gen (2bRAD - BS)  repo-URL:   draft:   </p> <p>2) A non-lethal, field-based anesthesia protocol for sampling the mantle cavity of Olympia oysters (Megan)  repo-URL: draft:google doc  preprint: https://www.dropbox.com/s/dfwtw8e2s2ix6zf/AnesthesiaPaper_v87.docx?dl=0      Journal: Journal of Shellfish Research</p> <p>16) What goes up must come down: Diel vertical migration in the deepwater sablefish (Anoplopoma fimbria) revealed by satellite popup tags  Journal: Fisheries Oceanography</p> <p>9) Coral Epi RAD (Jay)    repo-URL: https://github.com/jldimond/Branching-Porites   preprint: http://biorxiv.org/content/early/2017/03/22/119156     Journal: Molecular Ecology</p> <p>1) Integrating discovery-driven proteomics and selected reaction monitoring to develop a non-invasive assay for geoduck reproductive maturation (Emma)   repo-URL:https://github.com/sr320/supp-geoduck-proteomics    draft:        preprint: https://doi.org/10.1101/094615   Journal: Journal of Proteome Research</p> <p>3) Evidence of Ostrea lurida (Carpenter 1864) population structure in Puget Sound, WA  repo-URL: https://github.com/RobertsLab/OluridaSurvey2014    draft:    preprint: https://peerj.com/preprints/704/    Journal: Marine Ecology</p> <p>7) Oly GBS (Sam)   data records repo-URL: https://osf.io/j8rc2/   draft repo-URL: https://github.com/kubu4/paper_oly_gbs    draft: https://www.authorea.com/users/4974/articles/149442  preprint (Overleaf): https://www.overleaf.com/read/mqbbvmwxhncg  preprint (PDF): https://osf.io/cdj7m/   Status Details  Review Response: on GoogleDocs  Journal: Scientific Data</p>"},{"location":"Purchasing-and-Reimbursement/","title":"SAFS Purchasing","text":""},{"location":"Purchasing-and-Reimbursement/#general-purchasing","title":"General Purchasing","text":"<p>Here is the procedure for purchases. Generally, we are shifting to have SAFS admin staff handling purchasing as default (SAFS Purchasing Form).</p> <ol> <li> <p>Submit initial request in <code>#purchasing</code> channel on Slack.</p> <p>a.  Provide link(s) to desired product(s)</p> <ul> <li>University of Washington preferred vendors should always be given priority (i.e. don't default to buying from Amazon.com)</li> </ul> <p>b.  Purchasing approval will be confirmed by Steven and he will provide the appropriate budget number &amp; name to use</p> </li> <li> <p>Sumbit Purchase</p> <p>There are three basic means by which to submit a purchase. They are listed in order (top to bottom) of preferred usage:</p> <ul> <li> <p>treq</p> </li> <li> <p>eProcurement (Ariba)</p> <ul> <li>Requires pre-authorization from Steven and the department to use. Instructions, training, and tutorials are available from UW Procurement Services.</li> </ul> </li> <li> <p>ProCard</p> <ul> <li> <p>ProCard is a credit card issued to specific users via the University of Washington.</p> </li> <li> <p>Graduate students are not elligible for ProCard use.</p> </li> <li> <p>Sam is the only current lab member who has a ProCard.</p> </li> <li> <p>Obtaining a ProCard requires completing a University of Washington training course.</p> </li> <li> <p>ProCards cannot be used for travel or meal expenses.</p> </li> </ul> </li> </ul> </li> <li> <p>Fill out Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul> </li> <li> <p>Receiving Orders</p> <ol> <li> <p>Compare contents of box(es) and compare to packing slips.</p> </li> <li> <p>Sign and date all packing slips.</p> </li> <li> <p>If no packing slip is provided, email Lisa Smith indicating the vendor and date the items were received.</p> </li> <li> <p>Put packing slips in designated main office inbox (FSH 116).</p> </li> <li> <p>Indicate date order was received in Roberts Lab Purchasing Log</p> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE: If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#biochem-stores-purchasing","title":"Biochem Stores Purchasing","text":"<ol> <li> <p>Search the store catalog or just head down to Room J-014 in the Health Sciences Building basement and ask for your product. If you are off-campus, you must use a VPN such as Husky OnNet to connect to the UW network.</p> </li> <li> <p>Order your product. They will need to know your lab, your name, and the budget number. They will give you a sales receipt for your purchase, but you don't need to submit this anywhere.</p> </li> <li> <p>Update the Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE: If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#primer-purchasing","title":"Primer Purchasing","text":"<ol> <li> <p>Enter primer details in Primer Database (Google Sheet).</p> </li> <li> <p>Minimum info needed for each primer:</p> <ul> <li>Unique primer name.</li> <li>Primer sequence.</li> <li>Initials.</li> <li>Species.</li> </ul> </li> <li> <p>Pickup primers from Biochem Stores after 24hrs. A budget number will be needed upon pickup.</p> </li> <li> <p>Update the Roberts Lab Purchasing Log with receipt date and budget number.</p> </li> <li> <p>After reconstitution, store primers in a box in the -20<sup>o</sup>C in FTR 213. Update the Primer Stocks database (Google Sheet) with storage locations of each primer.</p> </li> <li> <p>All primer stocks should be reconstituted to a concentration of 100uM in 1X Tris-EDTA (TE).</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#chem-store-purchasing","title":"Chem Store Purchasing","text":"<ol> <li>Search the store catalog or just go down to 036 Bagley Hall and ask for your product. If you are off-campus, you must use a VPN such as Husky OnNet to connect to the UW network.</li> <li>They will need to know your lab, your name, and the budget number. They will give you a sales receipt for your purchase, but you don't need to submit this anywhere.</li> <li> <p>Update the Roberts Lab Purchasing Log</p> </li> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE:If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#personal-purchases-reimbursed-by-safs-budget","title":"Personal Purchases (reimbursed by SAFS Budget)","text":"<p>Use https://treq.environment.uw.edu</p> <p>Fill out Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul>"},{"location":"Purchasing-and-Reimbursement/#travel-and-meeting-registration","title":"Travel and Meeting Registration","text":"<p>Note Steps 1 and 2 need to occur prior to travel</p> <p>Travel is handled via https://treq.environment.uw.edu or not</p> <p>Step 1) Need to identify and apply for any supplemental support. This includes at the School and College level. This also includes support offered by the conference itself. Many conferences have early-bird rates and discounted hotels. These should be considered. Note: - The College of the Environment travel fund is only for future travel so make sure you apply for this two quarters in advance if possible. - FINS travel funds are prioritized for those involved in FINS or some other type of service related to SAFS (CoEnv SAC, SEAS, GSS, etc.).</p> <p>Step 2) For any travel you need to complete Travel Pre-Authorization as soon as you know you would like to travel. (It is optional to complete for local transit to research sites)</p> <p></p> <p>During the Pre-Authorization step you can request a per diem Advance. But if your projected per diem for the length of travel is not \\$300 or more, you are not eligible for per diem advance.</p> <p>Note that there are options to have UW directly pay for conference registration, if you can get an invoice from the conference When this is the case you would simply submit this invoice for payment with the \"Pay an Invoice\" option in Treq and not include in Travel Authorization / Reimbursement. Make sure you upload your invoice to the OneDrive folder associated with your request.</p> <p>Step 3) Secure transit and lodging following all rules and regulations set forth by UW.</p> <p>In order to have UW pay directly for your flight and lodging, you must follow these steps. Once you have completed your travel pre-authorization, click on the \"+Task\" button on the main page of your travel request. Leave \"Assign To\" blank and fill in \"Task Title\" with something like \"UW direct payment\". Fill in the description with the parts of your travel request you would like to get UW to pay for directly. For example: \"Could I get UW to directly pay for airfare and lodging so I don't have to use personal card?\". Save the task. Someone from UW will be assigned to the task and will reach out with further instructions to reserve your flight and/or reserve lodging. For flights, you will be contacted via email by Tangerine Travel Agency. You'll need to provide them with the exact flight itinerary you want so they can book your flight.</p> <p>Step 4) When travel is complete, submit required documentation via Treq</p> <p>If you need technical assistance you can email efast\\@uw.edu.</p>"},{"location":"Purchasing-and-Reimbursement/#without-treq","title":"Without TREQ","text":"<p>Need to submit the request via eFAST@uw.edu.  They will need to copy Steven on this request so that you can provide your approval.  Here are the pertinent things that will be needed for a request example of mileage and ferry. Modify according to request.</p> <p>Name the SUBJECT of Request as:  Mileage and Ferry Reimbursement Request for NAME OF STUDENT.</p> <p>Contact information (Full name, email address, phone number)  of the Biology Student.</p> <p>Destination</p> <p>Dates of Travel</p> <p>Time of Travel</p> <p>Business Purpose.  UW defines business purpose as: \"Explanation of how the purchase or payment is used for UW business.\u201d  A good business purpose may be, \u201cTravel to the Point Whitney hatcher for field research to investigate stress related to oyster aquaculture. This travel was with two other students in Biology (name of student) and the School of Aquatic and Fishery Sciences (name of student).  I\u2019ve drove to the field and paid for all ferry tickets, and requesting reimbursement for this expense.\u201d</p> <p>Itemized the Amount       Mileage      ??    Must be from \u201cHome Duty Station\u201d to the Destination.  Mileage is $0.670 / mile     </p> <p>Ferry Ticket          ??           TOTAL REIMBURSEMENT REQUEST   ??           </p> <p>Budget Worktags and Name of Budget to be charged.</p>"},{"location":"Purchasing-and-Reimbursement/#budgets-uwft-system","title":"Budgets UWFT System","text":"<ul> <li>Worktags for Budgets (PDF)</li> </ul>"},{"location":"Undergraduate-contract/","title":"Undergraduate Contract","text":"<p>I enjoy having the opportunity to provide motivated undergraduate students with a chance to gain hands-on lab experience and get a better understanding of an array of approaches that can be used to study aquatic organisms. I feel this is an important component of your education. Depending on your status (i.e. intern, work-study, course credit, capstone etc.) there will likely be specific details that will need to be discussed, however all personnel need to agree to, and understand the following.</p> <p>If there are any issues (e.g. allergies) or assistance you might need/want that will help you succeed during your time in the lab, please record them on this page.</p> <p>Signing this document acknowledges the following:</p> <p>1)  I have read through all components of Onboarding:</p> <p>2)  I have completed all required Lab Safety training and provided the required documents to Sam White.</p> <p>3)  Research supplies (and equipment) are purchased through my grants and are very expensive.</p> <p>4)  You need to commit to at least 4-10 hours per week.</p> <p>5)  Always, Always ask Steven or someone else if you have any questions or are unsure about something. You are here to learn and you should take the initiative to make the most of your time here.</p> <p>6)  You need to maintain an e-lab notebook / journal that is updated on a daily basis. The platform for this will be genefish.wordpress.com.</p> <p>7)  If you are expected (or tell someone you are) to be in lab, and for some reason cannot make it -let us know ASAP</p> <p>8)  Your schedule of when you will be in the lab needs to be maintained on the lab calendar.</p> <p>9)  Make an effort to attend all lab meetings.</p>   Loading...   <p>Name:<code>______________________________</code></p> <p>Signature:<code>___________________________</code></p> <p>Date:<code>___________________________</code></p> <p>email used for Google Calendar: <code>_______________________________</code></p>"},{"location":"bio-Annotation/","title":"Annotation","text":""},{"location":"bio-Annotation/#intro-blast","title":"Intro (Blast)","text":"<p>Blast is a key component of working with lesser studied taxa. Here are some resources to help with this.</p> <p>First off, you should be familar with the command line interface and bash</p> <ul> <li>Introducing the Shell</li> <li>Introduction to the Command Line for Genomics</li> <li>https://explainshell.com/</li> </ul>"},{"location":"bio-Annotation/#blast-notebooks","title":"Blast Notebooks","text":"<ul> <li>https://robertslab.github.io/tusk/modules/04-blast.html - Blast and annotation on tusk.    </li> <li>https://rpubs.com/sr320/1026094 - Blast tutorial from FISH 546 (2023)</li> <li> <p>https://github.com/RobertsLab/code/blob/master/09-blast.ipynb - An example of how one might take a multi sequence fasta file and using NCBI Blast, compare the sequences with the Swiss-Prot Database on their own computer.</p> </li> <li> <p>https://github.com/RobertsLab/code/blob/master/10-blast-2-slim.ipynb - A notebook to seamlessly take blast output to GO Slim list</p> </li> <li> <p>https://github.com/RobertsLab/code/blob/master/script-box/complete_go_annotation_notebook.Rmd -</p> </li> <li> <p>https://github.com/sr320/ceabigr/blob/main/code/17-Swiss-Prot-Annotation.Rmd -  Blasting C virginica to Swiss-Prot. Author: Steven Roberts </p> </li> </ul>"},{"location":"bio-Annotation/#gene-ontology-go","title":"Gene Ontology (GO)","text":""},{"location":"bio-Annotation/#retrieve-go-terms-from-uniprot-using-swissprot-ids","title":"Retrieve GO terms from UniProt Using SwissProt IDs","text":"<p>The following steps will use the UniProt Python API to create a tab-delimited file of data retrieved from UniProt.</p> <ol> <li> <p>Create newline-delimited file of SwissProt IDs. (e.g. <code>SPIDS.txt</code>)</p> <pre><code>cat SPIDS.txt\n\nQ86IC9\nP04177\nQ8L840\nQ61043\nA1E2V0\nP34456\nP34457\nO00463\nQ00945\nQ5SWK7\n</code></pre> </li> <li> <p>Create Python file (e.g. <code>uniprot-retrieval.py</code>) with the following:</p> <pre><code>import re\nimport zlib\nimport gzip\nimport requests\nfrom requests.adapters import HTTPAdapter, Retry\nimport sys\nimport shutil\nimport os\n\nre_next_link = re.compile(r'&lt;(.+)&gt;; rel=\"next\"')\nretries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\nsession = requests.Session()\nsession.mount(\"https://\", HTTPAdapter(max_retries=retries))\n\ndef get_next_link(headers):\n    if \"Link\" in headers:\n        match = re_next_link.match(headers[\"Link\"])\n        if match:\n            return match.group(1)\n\ndef get_batch(batch_url):\n    while batch_url:\n        response = session.get(batch_url)\n        response.raise_for_status()\n        total = response.headers[\"x-total-results\"]\n        yield response, total\n        batch_url = get_next_link(response.headers)\n\ndef process_accessions(accessions):\n    accession_batches = [accessions[i:i+500] for i in range(0, len(accessions), 500)]\n    all_lines = []\n\n    for accession_batch in accession_batches:\n        accession_query = '%29%20OR%20%28accession%3A'.join(accession_batch)\n        url = f\"https://rest.uniprot.org/uniprotkb/search?compressed=true&amp;fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cgo_p%2Cgo_c%2Cgo%2Cgo_f%2Cgo_id&amp;format=tsv&amp;query=%28%28accession%3A{accession_query}%29%29&amp;size=500\"\n\n        progress = 0\n        lines = []\n        for batch, total in get_batch(url):\n            # Decompress each batch as we want to extract the header\n            decompressed = zlib.decompress(batch.content, 16 + zlib.MAX_WBITS)\n            batch_lines = [line for line in decompressed.decode(\"utf-8\").split(\"\\n\") if line]\n            if not progress:\n                # First line so print TSV header\n                lines = [batch_lines[0]]\n            lines += batch_lines[1:]\n            progress = len(lines) - 1\n            print(f\"{progress} / {total}\")\n\n        all_lines.extend(lines)\n\n    return all_lines\n\ndef main(accession_file, output_dir):\n    with open(accession_file, 'r') as f:\n        accessions = f.read().splitlines()\n\n    retrieved_data = process_accessions(accessions)\n\n    # Write to a temporary gzip file\n    temp_filename = \"uniprot-retrieval-temp.tsv.gz\"\n    with gzip.open(temp_filename, \"wt\", encoding=\"utf-8\") as f:\n        f.write('\\n'.join(retrieved_data))\n\n    # Determine the full output path\n    output_path = os.path.join(output_dir, \"uniprot-retrieval.tsv.gz\")\n\n    # Merge the temporary file with the existing output file (if it exists)\n    try:\n        with gzip.open(output_path, \"rb\") as f_existing, open(temp_filename, \"rb\") as f_temp:\n            with gzip.open(\"uniprot-retrieval-merged.tsv.gz\", \"wb\") as f_merged:\n                shutil.copyfileobj(f_existing, f_merged)\n                shutil.copyfileobj(f_temp, f_merged)\n\n        # Replace the original output file with the merged file\n        shutil.move(\"uniprot-retrieval-merged.tsv.gz\", output_path)\n    except FileNotFoundError:\n        # If the existing output file doesn't exist, rename the temporary file\n        shutil.move(temp_filename, output_path)\n\nif __name__ == '__main__':\n    if len(sys.argv) &lt; 3:\n        print(\"Usage: python uniprot-retrieval.py &lt;input_file&gt; &lt;output_directory&gt;\")\n        sys.exit(1)\n\n    accession_file = sys.argv[1]\n    output_dir = sys.argv[2]\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    main(accession_file, output_dir)\n</code></pre> </li> <li> <p>Run the Python script:</p> <p><pre><code>python3 uniprot-retrieval.py SPIDS.txt /path/to/desired/output/directory/\n</code></pre> - IMPORTANT: Requires Python &gt;= 3!</p> <ul> <li>If using R Markdown, run the above in a <code>bash</code> chunk:</li> </ul> </li> </ol> <p>The resulting output file (<code>uniprot-retrieval.tsv.gz</code>) will be in the specified directory.</p> <ol> <li> <p>Gunzip the output file:</p> <pre><code>gunzip uniprot-retrieval.tsv.gz\n</code></pre> </li> </ol> <p>The resulting file (<code>uniprot-retrieval.tsv</code>) will be formatted with the following columns:</p> Entry Reviewed Entry Name Protein names Gene Names Organism Length Gene Ontology (biological process) Gene Ontology (cellular component) Gene Ontology (molecular function) Gene Ontology (GO) Gene Ontology IDs <p>NOTES:</p> <ul> <li> <p>This requires Python &gt;= 3 to run. Simplest way to access Python 3 is via a conda environment.</p> </li> <li> <p>On the first attempt, you'll likely need to install the packages that are being imported at the very beginning of the script.</p> </li> <li> <p>Create an issue if you need help with any of the above.</p> </li> </ul>"},{"location":"bio-Annotation/#map-go-ids-to-goslims","title":"Map GO IDs to GOslims","text":"<p>Below are a series of R Markdown chunks to run.</p> <p>The expected input file has at least two columns. One each with:</p> <ul> <li>gene ID</li> <li>Gene Ontology (GO) ID</li> </ul> <p>NOTE: The GO IDs in the GO ID column should be separated with a semi-colon.</p> <p>The basic output from this process will be:</p> <ul> <li>GOslim IDs (as rownames)</li> <li>GOslim terms</li> <li>Counts of GO IDs matching to corresponding GOslim</li> <li>Percentage of GO IDs matching to corresponding GOslim</li> <li>GOIDs mapped to corresponding GOslim, in a semi-colon delimited format</li> </ul> <p>There are steps after this that perform different subsetting that you may/not be interested in. They've been left in to serve as examples.</p> <p>Load libraries</p> <pre><code>```{r setup, include=TRUE}\nlibrary(GSEABase)\nlibrary(GO.db)\nlibrary(knitr)\nlibrary(tidyverse)\nknitr::opts_chunk$set(\n  echo = TRUE,         # Display code chunks\n  eval = FALSE,        # Evaluate code chunks\n  warning = FALSE,     # Hide warnings\n  message = FALSE,     # Hide messages\n  comment = \"\"         # Prevents appending '##' to beginning of lines in code output\n)\n```\n</code></pre> <p>Variables</p> <p>IMPORTANT: The user needs to provide:</p> <ul> <li> <p>names of the columns containing the GO IDs and the gene IDs!</p> </li> <li> <p>Path or URL to input file.</p> </li> </ul> <p>After that, there's almost no need to modify any of the chunks which follow.</p> <pre><code>```{r set-variables, eval=TRUE}\n# Column names corresponding to gene name/ID and GO IDs\nGO.ID.column &lt;- \"Gene.Ontology.IDs\"\ngene.ID.column &lt;- \"gene_id\"\n\n# Relative path or URL to input file\ninput.file &lt;- \"https://raw.githubusercontent.com/grace-ac/paper-pycno-sswd-2021-2022/d1cdf13c36085868df4ef4b75d2b7de03ef08d1c/analyses/25-compare-2021-2022/DEGlist_same_2021-2022_forGOslim.tab\"\n\n\n##### Official GO info - no need to change #####\ngoslims_obo &lt;- \"goslim_generic.obo\"\ngoslims_url &lt;- \"http://current.geneontology.org/ontology/subsets/goslim_generic.obo\"\n```\n</code></pre> <p>Set GSEAbase location and download <code>goslim_generic.obo</code> <pre><code>```{r download-generic-goslim-obo, eval=TRUE}\n# Find GSEAbase installation location\ngseabase_location &lt;- find.package(\"GSEABase\")\n\n# Load path to GOslim OBO file\ngoslim_obo_destintation &lt;- file.path(gseabase_location, \"extdata\", goslims_obo, fsep = \"/\")\n\n# Download the GOslim OBO file\ndownload.file(url = goslims_url, destfile = goslim_obo_destintation)\n\n# Loads package files\ngseabase_files &lt;- system.file(\"extdata\", goslims_obo, package=\"GSEABase\")\n```\n</code></pre></p> <p>Read in gene/GO file <pre><code>```{r read-in-gene-file, eval=TRUE}\nfull.gene.df &lt;- read.csv(file = input.file, header = TRUE, sep = \"\\t\")\n\nstr(full.gene.df)\n```\n</code></pre></p> <p>Remove rows with NA, remove whitespace in GO IDs column and keep just gene/GO IDs columns <pre><code>```{r remove-NA-and-uniprotIDs, eval=TRUE}\n\n# Clean whitespace, filter NA/empty rows, select columns, and split GO terms using column name variables\ngene.GO.df &lt;- full.gene.df %&gt;%\n  mutate(!!GO.ID.column := str_replace_all(.data[[GO.ID.column]], \"\\\\s*;\\\\s*\", \";\")) %&gt;% # Clean up spaces around \";\"\n  filter(!is.na(.data[[gene.ID.column]]) &amp; !is.na(.data[[GO.ID.column]]) &amp; .data[[GO.ID.column]] != \"\") %&gt;% \n  select(all_of(c(gene.ID.column, GO.ID.column)))\n\n\nstr(gene.GO.df)\n```\n</code></pre></p> <p>This flattens the file so all of the GO IDs per gene are separated into one GO ID per gene per row. <pre><code>```{r flatten-gene-and-GO-IDs, eval=TRUE}\nflat.gene.GO.df &lt;- gene.GO.df %&gt;% separate_rows(!!sym(GO.ID.column), sep = \";\")\n\nstr(flat.gene.GO.df)\n```\n</code></pre></p> <p>Groups the genes by GO ID (i.e. lists all genes associated with each unique GO ID) <pre><code>```{r group-by-GO, eval=TRUE}\ngrouped.gene.GO.df &lt;- flat.gene.GO.df %&gt;%\n  group_by(!!sym(GO.ID.column)) %&gt;%\n  summarise(!!gene.ID.column := paste(.data[[gene.ID.column]], collapse = \",\"))\n\nstr(grouped.gene.GO.df)\n```\n</code></pre></p> <p>Map GO IDs to GOslims</p> <p>The mapping steps were derived from this bioconductor forum response <pre><code>```{r vectorize-GOIDs, eval=TRUE}\n# Vector of GO IDs\ngo_ids &lt;- grouped.gene.GO.df[[GO.ID.column]]\n\nstr(go_ids)\n```\n</code></pre></p> <p>Creates new OBO Collection object of just GOslims, based on provided GO IDs. <pre><code>```{r extract-GOslims-from-OBO, eval=TRUE}\n\n# Create GSEAbase GOCollection using `go_ids`\nmyCollection &lt;- GOCollection(go_ids)\n\n# Retrieve GOslims from GO OBO file set\nslim &lt;- getOBOCollection(gseabase_files)\n\nstr(slim)\n```\n</code></pre></p> <p>Get Biological Process (BP) GOslims associated with provided GO IDs. <pre><code>```{r retrieve-BP-GOslims, eval=TRUE}\n# Retrieve Biological Process (BP) GOslims\nslimdf &lt;- goSlim(myCollection, slim, \"BP\", verbose)\nstr(slimdf)\n```\n</code></pre></p> <p>Performs mapping of of GOIDs to GOslims</p> <p>Returns:</p> <ul> <li>GOslim IDs (as rownames)</li> <li>GOslim terms</li> <li>Counts of GO IDs matching to corresponding GOslim</li> <li>Percentage of GO IDs matching to corresponding GOslim</li> <li>GOIDs mapped to corresponding GOslim, in a semi-colon delimited format <pre><code>```{r map-GO-to-GOslims, eval=TRUE}\n# List of GOslims and all GO IDs from `go_ids`\ngomap &lt;- as.list(GOBPOFFSPRING[rownames(slimdf)])\n\n# Maps `go_ids` to matching GOslims\nmapped &lt;- lapply(gomap, intersect, ids(myCollection))\n\n# Append all mapped GO IDs to `slimdf`\n# `sapply` needed to apply paste() to create semi-colon delimited values\nslimdf$GO.IDs &lt;- sapply(lapply(gomap, intersect, ids(myCollection)), paste, collapse=\";\")\n\n# Remove \"character(0) string from \"GO.IDs\" column\nslimdf$GO.IDs[slimdf$GO.IDs == \"character(0)\"] &lt;- \"\"\n\n# Add self-matching GOIDs to \"GO.IDs\" column, if not present\nfor (go_id in go_ids) {\n  # Check if the go_id is present in the row names\n  if (go_id %in% rownames(slimdf)) {\n    # Check if the go_id is not present in the GO.IDs column\n    # Also removes white space \"trimws()\" and converts all to upper case to handle\n    # any weird, \"invisible\" formatting issues.\n    if (!go_id %in% trimws(toupper(strsplit(slimdf[go_id, \"GO.IDs\"], \";\")[[1]]))) {\n      # Append the go_id to the GO.IDs column with a semi-colon separator\n      if (length(slimdf$GO.IDs) &gt; 0 &amp;&amp; nchar(slimdf$GO.IDs[nrow(slimdf)]) &gt; 0) {\n        slimdf[go_id, \"GO.IDs\"] &lt;- paste0(slimdf[go_id, \"GO.IDs\"], \"; \", go_id)\n      } else {\n        slimdf[go_id, \"GO.IDs\"] &lt;- go_id\n      }\n    }\n  }\n}\n\nstr(slimdf)\n```\n</code></pre></li> </ul> <p>\"Flatten\" file so each row is single GO ID with corresponding GOslim rownames_to_column needed to retain row name info <pre><code>```{r flatten-GOslims-file, eval=TRUE}\n# \"Flatten\" file so each row is single GO ID with corresponding GOslim\n# rownames_to_column needed to retain row name info\nslimdf_separated &lt;- as.data.frame(slimdf %&gt;%\n  rownames_to_column('GOslim') %&gt;%\n  separate_rows(GO.IDs, sep = \";\"))\n\n# Group by unique GO ID\ngrouped_slimdf &lt;- slimdf_separated %&gt;%\n  filter(!is.na(GO.IDs) &amp; GO.IDs != \"\") %&gt;%\n  group_by(GO.IDs) %&gt;%\n  summarize(GOslim = paste(GOslim, collapse = \";\"),\n            Term = paste(Term, collapse = \";\"))\n\n\nstr(grouped_slimdf)\n```\n</code></pre></p> <p>Sorts GOslims by <code>Count</code>, in descending order and then selects just the <code>Term</code> and <code>Count</code> columns. <pre><code>```{r sort-and-select-slimdf-counts, eval=TRUE}\n\nslimdf.sorted &lt;- slimdf %&gt;% arrange(desc(Count))\n\nslim.count.df &lt;- slimdf.sorted %&gt;% \n  select(Term, Count)\n\nstr(slim.count.df)\n```\n</code></pre></p>"},{"location":"bio-Annotation/#enrichment-analysis-visualization-and-interpretation","title":"Enrichment Analysis Visualization and Interpretation","text":"<p>You've completed your enrichment analysis and have a list of significantly enriched GO terms, KEGG pathways, or other functional categories. Now what? Enrichment analysis often produces hundreds of significantly enriched terms, making it challenging to distill these results into a compelling narrative and impactful visualizations for your research story.</p>"},{"location":"bio-Annotation/#overview-from-results-to-story","title":"Overview: From Results to Story","text":"<p>After completing enrichment analysis, you typically face these challenges:</p> <ol> <li>Identify the most important physiological processes relevant to your biological question from hundreds of enriched terms</li> <li>Create visualizations that clearly communicate key findings without overwhelming readers</li> <li>Write a coherent discussion that tells a story rather than listing enriched terms</li> </ol> <p>This section provides strategies, code examples, and best practices for transforming your enrichment results into publication-ready figures and narratives. This guide assumes you already have enrichment results (e.g., from clusterProfiler, GOseq, DAVID, or similar tools).</p>"},{"location":"bio-Annotation/#best-practices-for-synthesizing-enrichment-results","title":"Best Practices for Synthesizing Enrichment Results","text":""},{"location":"bio-Annotation/#1-prioritize-and-filter-results","title":"1. Prioritize and Filter Results","text":"<p>Not all significantly enriched terms are equally informative. Consider:</p> <ul> <li>Biological relevance: Focus on processes directly related to your experimental design or biological question</li> <li>Term specificity: Prefer specific terms (e.g., \"lipid metabolic process\") over very broad terms (e.g., \"metabolic process\")</li> <li>Statistical significance: Use adjusted p-values (FDR/q-value &lt; 0.05) and consider effect size (fold enrichment)</li> <li>Redundancy reduction: Many GO terms are hierarchical and redundant; simplify by selecting representative terms</li> </ul> <p>Strategy: Start by filtering to the top 10-20 most significant terms, then manually curate to remove redundancy and retain biological meaning.</p>"},{"location":"bio-Annotation/#2-group-related-processes","title":"2. Group Related Processes","text":"<p>Organize enriched terms into higher-level biological themes:</p> <ul> <li>Metabolism: Energy production, biosynthesis, catabolism</li> <li>Stress response: Oxidative stress, heat shock, immune response</li> <li>Development: Cell differentiation, morphogenesis, growth</li> <li>Signaling: Cell communication, signal transduction</li> <li>Structural: Cytoskeleton, cell adhesion, extracellular matrix</li> </ul> <p>This grouping helps create a coherent narrative and simplifies visualization.</p>"},{"location":"bio-Annotation/#3-compare-across-conditions","title":"3. Compare Across Conditions","text":"<p>If you have multiple comparisons (e.g., multiple treatments or time points):</p> <ul> <li>Identify shared enriched processes (core response)</li> <li>Identify unique enriched processes (condition-specific responses)</li> <li>Look for temporal patterns (early vs. late response)</li> <li>Consider opposing processes (up-regulated vs. down-regulated genes)</li> </ul>"},{"location":"bio-Annotation/#r-packages-for-visualization","title":"R Packages for Visualization","text":""},{"location":"bio-Annotation/#essential-packages","title":"Essential Packages","text":"<pre><code># Install Bioconductor packages (if needed)\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(c(\"enrichplot\", \"GOSemSim\", \"DOSE\"))\n\n# Install CRAN packages\ninstall.packages(c(\"ggplot2\", \"dplyr\", \"tidyr\", \"forcats\", \"stringr\", \"RColorBrewer\"))\n</code></pre> <p>Key packages: - enrichplot: Advanced visualization functions for enrichment results - GOSemSim: Semantic similarity to reduce redundancy - ggplot2: Customizable plotting - dplyr/tidyr: Data manipulation</p>"},{"location":"bio-Annotation/#working-with-your-enrichment-results","title":"Working with Your Enrichment Results","text":"<p>This section assumes you have enrichment results in one of these formats:</p> <ol> <li>clusterProfiler object (e.g., from <code>enrichGO()</code>, <code>enrichKEGG()</code>)</li> <li>Data frame with columns for: term ID, description, p-value, adjusted p-value, gene count, etc.</li> <li>Table from web tools (DAVID, Enrichr, etc.) exported as CSV/TSV</li> </ol>"},{"location":"bio-Annotation/#loading-your-results","title":"Loading Your Results","text":"<pre><code>library(enrichplot)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# If you have a clusterProfiler object already:\n# ego_results &lt;- readRDS(\"my_enrichment_results.rds\")\n\n# If you have a table from another tool, read it:\n# enrichment_df &lt;- read.csv(\"enrichment_results.csv\")\n\n# For this guide, we'll assume you have a clusterProfiler enrichResult object\n# named 'ego_results' with your enrichment analysis results\n</code></pre>"},{"location":"bio-Annotation/#simplify-results-remove-redundancy","title":"Simplify Results (Remove Redundancy)","text":"<pre><code>library(GOSemSim)\n\n# Assuming you have enrichment results in 'ego_results'\n# Simplify GO terms based on semantic similarity\nego_simplified &lt;- simplify(ego_results, \n                          cutoff = 0.7,      # Similarity threshold (0-1)\n                          by = \"p.adjust\",   # Metric to select representative\n                          select_fun = min)\n\n# Further reduce to top N terms\ntop_n &lt;- 20\nego_top &lt;- ego_simplified[1:min(top_n, nrow(ego_simplified)), ]\n\n# Convert to dataframe for further manipulation\nego_df &lt;- as.data.frame(ego_simplified)\n</code></pre> <p>Note: If your enrichment results are from a non-clusterProfiler source (e.g., DAVID, Enrichr), you can manually filter redundant terms by: - Selecting the most specific term from hierarchical groups - Using REVIGO to cluster semantically similar terms - Prioritizing terms with the highest significance and gene counts</p>"},{"location":"bio-Annotation/#creating-impactful-figures","title":"Creating Impactful Figures","text":""},{"location":"bio-Annotation/#1-dot-plot-most-common-and-effective","title":"1. Dot Plot (Most Common and Effective)","text":"<p>Dot plots show enriched terms with: - X-axis: Gene ratio or fold enrichment - Y-axis: GO terms - Dot size: Number of genes - Dot color: Significance (p-value or q-value)</p> <pre><code># Basic dotplot\ndotplot(ego_top, \n        showCategory = 20,\n        font.size = 10,\n        title = \"GO Biological Process Enrichment\")\n\n# Enhanced dotplot with custom colors\ndotplot(ego_top, \n        showCategory = 20,\n        font.size = 10) + \n  scale_color_gradient(low = \"red\", high = \"blue\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 11)) +\n  ggtitle(\"Top Enriched Biological Processes in DEGs\")\n</code></pre> <p>Best for: Showing top 15-25 enriched terms with statistical significance and gene counts at a glance.</p>"},{"location":"bio-Annotation/#2-bar-plot-clear-and-simple","title":"2. Bar Plot (Clear and Simple)","text":"<pre><code># Bar plot showing count or gene ratio\nbarplot(ego_top, \n        showCategory = 15,\n        font.size = 10) + \n  ggtitle(\"GO Enrichment - Biological Process\")\n\n# Horizontal bar plot with custom aesthetics\nggplot(ego_df[1:15, ], aes(x = Count, y = reorder(Description, Count))) +\n  geom_bar(stat = \"identity\", aes(fill = p.adjust)) +\n  scale_fill_gradient(low = \"red\", high = \"blue\", name = \"Adjusted\\np-value\") +\n  labs(x = \"Gene Count\", y = \"\", title = \"Top 15 Enriched GO Terms\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 11))\n</code></pre> <p>Best for: Simple, publication-ready figures showing the most enriched processes.</p>"},{"location":"bio-Annotation/#3-networkenrichment-map-shows-relationships","title":"3. Network/Enrichment Map (Shows Relationships)","text":"<p>Network plots display relationships between enriched terms based on shared genes:</p> <pre><code># Pairwise term similarity\nego_pairwise &lt;- pairwise_termsim(ego_simplified)\n\n# Enrichment map (network plot)\nemapplot(ego_pairwise, \n         showCategory = 30,\n         cex_label_category = 0.7,\n         layout = \"nicely\") +\n  ggtitle(\"Enrichment Map of GO Terms\")\n\n# Alternative: use ggraph for more control\nlibrary(ggraph)\nemapplot(ego_pairwise, \n         showCategory = 30,\n         cex_label_category = 0.7,\n         layout = \"fr\")  # Fruchterman-Reingold layout\n</code></pre> <p>Best for: Showing how enriched processes relate to each other and identifying clusters of related functions.</p>"},{"location":"bio-Annotation/#4-upset-plot-for-multiple-gene-lists","title":"4. Upset Plot (For Multiple Gene Lists)","text":"<p>When comparing enrichment across multiple conditions:</p> <pre><code># Assuming you have multiple enrichment results\nego_list &lt;- list(Condition1 = ego_cond1,\n                Condition2 = ego_cond2,\n                Condition3 = ego_cond3)\n\n# Upset plot\nupsetplot(ego_list)\n</code></pre> <p>Best for: Comparing enriched terms across multiple experimental conditions or time points.</p>"},{"location":"bio-Annotation/#5-heatmap-of-enriched-terms","title":"5. Heatmap of Enriched Terms","text":"<pre><code># Heatplot showing gene-term relationships\nheatplot(ego_top, \n         showCategory = 15,\n         foldChange = gene_fc)  # Optional: include fold-change values\n\n# Custom heatmap with ggplot2\nlibrary(pheatmap)\n\n# Prepare matrix: rows = genes, columns = GO terms\n# (Requires some data wrangling)\n</code></pre> <p>Best for: Detailed view of which genes contribute to which enriched terms.</p>"},{"location":"bio-Annotation/#6-gene-concept-network","title":"6. Gene-Concept Network","text":"<pre><code># Show genes associated with top enriched terms\ncnetplot(ego_top, \n         showCategory = 5,\n         foldChange = gene_fc,  # Optional: show gene expression\n         circular = FALSE,\n         colorEdge = TRUE)\n\n# Circular layout\ncnetplot(ego_top, \n         showCategory = 5,\n         circular = TRUE,\n         colorEdge = TRUE)\n</code></pre> <p>Best for: Highlighting specific genes driving enrichment in key processes.</p>"},{"location":"bio-Annotation/#advanced-visualization-strategies","title":"Advanced Visualization Strategies","text":""},{"location":"bio-Annotation/#combining-multiple-plots","title":"Combining Multiple Plots","text":"<pre><code>library(cowplot)\nlibrary(patchwork)\n\n# Create multiple plots\np1 &lt;- dotplot(ego_bp, showCategory = 15) + ggtitle(\"Biological Process\")\np2 &lt;- dotplot(ego_mf, showCategory = 15) + ggtitle(\"Molecular Function\")\np3 &lt;- dotplot(ego_cc, showCategory = 15) + ggtitle(\"Cellular Component\")\n\n# Combine into one figure\ncombined_plot &lt;- p1 | p2 | p3\nggsave(\"combined_GO_enrichment.png\", combined_plot, width = 18, height = 6, dpi = 300)\n</code></pre>"},{"location":"bio-Annotation/#custom-ordering-and-grouping","title":"Custom Ordering and Grouping","text":"<pre><code># Manually select and order terms by biological theme\nselected_terms &lt;- c(\n  # Metabolism\n  \"lipid metabolic process\",\n  \"carbohydrate metabolic process\",\n\n  # Stress response\n  \"response to oxidative stress\",\n  \"response to heat\",\n\n  # Immune\n  \"innate immune response\",\n  \"inflammatory response\"\n)\n\n# Filter and plot in custom order\nego_custom &lt;- ego_df %&gt;%\n  filter(Description %in% selected_terms) %&gt;%\n  mutate(Description = factor(Description, levels = selected_terms))\n\nggplot(ego_custom, aes(x = GeneRatio, y = Description)) +\n  geom_point(aes(size = Count, color = p.adjust)) +\n  scale_color_gradient(low = \"red\", high = \"blue\") +\n  theme_minimal() +\n  labs(title = \"Key Physiological Processes in Response to Treatment\")\n</code></pre>"},{"location":"bio-Annotation/#adding-annotations-and-context","title":"Adding Annotations and Context","text":"<pre><code># Add biological context to plot\ndotplot(ego_top, showCategory = 15) +\n  annotate(\"rect\", xmin = 0.3, xmax = 0.5, ymin = 1, ymax = 5, \n           alpha = 0.2, fill = \"yellow\") +\n  annotate(\"text\", x = 0.4, y = 6, \n           label = \"Metabolic\\nreprogramming\", \n           size = 4, fontface = \"bold\")\n</code></pre>"},{"location":"bio-Annotation/#writing-a-compelling-discussion","title":"Writing a Compelling Discussion","text":""},{"location":"bio-Annotation/#structure-your-narrative","title":"Structure Your Narrative","text":"<ol> <li>Start with the big picture: What is the overall biological theme?</li> <li> <p>\"Enrichment analysis revealed a coordinated metabolic shift toward lipid catabolism...\"</p> </li> <li> <p>Present major themes, not individual terms: Group related processes</p> </li> <li> <p>\"Three major physiological responses emerged: (1) stress defense, (2) metabolic remodeling, and (3) immune activation\"</p> </li> <li> <p>Connect to your hypothesis: Link enrichment to your research question</p> </li> <li> <p>\"Consistent with our hypothesis that heat stress triggers energy reallocation...\"</p> </li> <li> <p>Highlight specific processes: Dive into 2-3 key enriched processes</p> </li> <li> <p>\"The enrichment of 'oxidative stress response' (q-value = 0.001, 45 genes) suggests...\"</p> </li> <li> <p>Integrate with gene expression patterns: Mention direction (up/down)</p> </li> <li> <p>\"Up-regulated genes were enriched in immune pathways, while down-regulated genes showed enrichment in growth processes\"</p> </li> <li> <p>Compare to literature: Reference similar findings or contrasts</p> </li> <li> <p>\"This aligns with previous transcriptomic studies in oysters exposed to thermal stress (Smith et al., 2020)\"</p> </li> <li> <p>Acknowledge limitations and complexity: Be transparent</p> </li> <li>\"While enrichment analysis provides functional insights, individual gene functions and pathway crosstalk require further investigation\"</li> </ol>"},{"location":"bio-Annotation/#example-discussion-paragraph","title":"Example Discussion Paragraph","text":"<pre><code>Gene ontology enrichment analysis of the 1,247 up-regulated genes revealed significant \noverrepresentation of biological processes related to stress response and metabolic \nremodeling (Figure 3A). Specifically, genes involved in 'response to oxidative stress' \n(GO:0006979, q &lt; 0.001, 68 genes), 'protein folding' (GO:0006457, q = 0.002, 45 genes), \nand 'lipid catabolic process' (GO:0016042, q = 0.003, 52 genes) were highly enriched. \nThis pattern suggests a coordinated cellular response to thermal stress characterized by \nboth protective mechanisms (heat shock proteins, antioxidant enzymes) and metabolic \nadaptation (shift from anabolic to catabolic processes). In contrast, down-regulated \ngenes (n = 892) showed enrichment in 'cell division' (GO:0051301, q &lt; 0.001) and \n'protein translation' (GO:0006412, q = 0.002), indicating suppression of energy-intensive \ngrowth processes during stress. These findings align with the concept of stress-induced \ngrowth-metabolism tradeoffs previously described in marine invertebrates (Jones et al., 2018).\n</code></pre>"},{"location":"bio-Annotation/#complete-workflow-example","title":"Complete Workflow Example","text":"<p>This example assumes you already have enrichment results from your analysis.</p> <pre><code># ===== Visualization Workflow Starting with Enrichment Results =====\n\nlibrary(enrichplot)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(GOSemSim)\n\n# STARTING POINT: You already have enrichment results\n# These could be from clusterProfiler, GOseq, or loaded from saved files\n# For this example, we assume you have two enrichResult objects:\n# - ego_up: enrichment results for up-regulated genes\n# - ego_down: enrichment results for down-regulated genes\n\n# If you saved your results previously, load them:\n# ego_up &lt;- readRDS(\"enrichment_results_up.rds\")\n# ego_down &lt;- readRDS(\"enrichment_results_down.rds\")\n\n# 1. Simplify results to remove redundancy\nego_up_simp &lt;- simplify(ego_up, cutoff = 0.7, by = \"p.adjust\", select_fun = min)\nego_down_simp &lt;- simplify(ego_down, cutoff = 0.7, by = \"p.adjust\", select_fun = min)\n\n# 2. Create publication-ready figure\np_up &lt;- dotplot(ego_up_simp, showCategory = 15, title = \"Up-regulated Genes\") +\n  scale_color_gradient(low = \"red\", high = \"blue\")\n\np_down &lt;- dotplot(ego_down_simp, showCategory = 15, title = \"Down-regulated Genes\") +\n  scale_color_gradient(low = \"red\", high = \"blue\")\n\n# Combine plots\nlibrary(patchwork)\ncombined &lt;- p_up / p_down\nggsave(\"Figure_GO_enrichment.png\", combined, width = 10, height = 12, dpi = 300)\n\n# 3. Export results table for supplementary materials\nwrite.csv(as.data.frame(ego_up_simp), \"Supplementary_Table_GO_up.csv\", row.names = FALSE)\nwrite.csv(as.data.frame(ego_down_simp), \"Supplementary_Table_GO_down.csv\", row.names = FALSE)\n\n# 4. Create enrichment map for manuscript\nego_up_pairwise &lt;- pairwise_termsim(ego_up_simp)\np_network &lt;- emapplot(ego_up_pairwise, showCategory = 30) +\n  ggtitle(\"Enrichment Network - Up-regulated Genes\")\nggsave(\"Figure_enrichment_network.png\", p_network, width = 10, height = 10, dpi = 300)\n</code></pre> <p>Alternative: Working with enrichment results from other tools</p> <p>If you have enrichment results from DAVID, Enrichr, or similar web tools:</p> <pre><code># Load your enrichment results table\nenrichment_df &lt;- read.csv(\"enrichment_results.csv\")\n\n# Assuming columns: Term, P.value, Adjusted.P.value, Genes, Count\n# Filter to significant terms\nsig_terms &lt;- enrichment_df %&gt;%\n  filter(Adjusted.P.value &lt; 0.05) %&gt;%\n  arrange(Adjusted.P.value) %&gt;%\n  head(20)\n\n# Create a custom bar plot\nggplot(sig_terms, aes(x = Count, y = reorder(Term, Count))) +\n  geom_bar(stat = \"identity\", aes(fill = Adjusted.P.value)) +\n  scale_fill_gradient(low = \"red\", high = \"blue\", name = \"Adjusted\\np-value\") +\n  labs(x = \"Gene Count\", y = \"\", title = \"Top 20 Enriched Terms\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10))\n\nggsave(\"enrichment_barplot.png\", width = 8, height = 10, dpi = 300)\n</code></pre>"},{"location":"bio-Annotation/#alternative-approaches-and-tools","title":"Alternative Approaches and Tools","text":""},{"location":"bio-Annotation/#using-goplot-for-circular-visualization","title":"Using GOplot for Circular Visualization","text":"<pre><code># Install GOplot\nif (!requireNamespace(\"GOplot\", quietly = TRUE))\n    install.packages(\"GOplot\")\n\nlibrary(GOplot)\n\n# Prepare data (requires specific format)\n# See: https://wencke.github.io/\n\n# Circular visualization\nGOCircle(GOplot_data, nsub = 10)\n</code></pre>"},{"location":"bio-Annotation/#revigo-for-semantic-clustering","title":"REVIGO for Semantic Clustering","text":"<p>For reducing GO term redundancy through semantic similarity:</p> <ol> <li>Export GO terms with p-values</li> <li>Upload to REVIGO</li> <li>Visualize clustered terms</li> <li>Export representative terms</li> </ol>"},{"location":"bio-Annotation/#shinygo-for-interactive-exploration","title":"ShinyGO for Interactive Exploration","text":"<p>ShinyGO provides a web interface for: - Enrichment analysis - Interactive visualizations - Pathway analysis - No coding required</p>"},{"location":"bio-Annotation/#tips-for-publication-quality-figures","title":"Tips for Publication-Quality Figures","text":"<ol> <li>Font sizes: Ensure labels are readable (minimum 8-10 pt)</li> <li>Color palettes: Use colorblind-friendly palettes (viridis, RColorBrewer)</li> <li>Resolution: Export at 300 DPI for publication</li> <li>File format: PDF for vector graphics, PNG for presentations</li> <li>Simplicity: Don't show more than 20-25 terms per figure</li> <li>Consistency: Use same color schemes across figures</li> <li>White space: Don't overcrowd; consider multi-panel figures</li> </ol> <pre><code># Colorblind-friendly palette\nlibrary(viridis)\n\ndotplot(ego_top, showCategory = 15) +\n  scale_color_viridis(option = \"plasma\", direction = -1) +\n  theme_minimal(base_size = 12)\n</code></pre>"},{"location":"bio-Annotation/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":"<ol> <li>Showing too many terms: More is not better; focus on top processes</li> <li>Ignoring redundancy: Simplify semantically similar terms</li> <li>Cherry-picking: Report systematic filtering criteria</li> <li>Over-interpretation: GO terms are predictions, not proof of function</li> <li>Ignoring background: Always use appropriate universe/background</li> <li>P-value only: Consider fold enrichment and gene counts too</li> <li>No biological context: Connect enrichment to your research question</li> </ol>"},{"location":"bio-Annotation/#use-cases-from-our-lab","title":"Use Cases from Our Lab","text":"<ul> <li> <p>Enrichment analysis examples - Tanner crab transcriptomics </p> </li> <li> <p>C. virginica GO enrichment - Eastern oyster functional genomics </p> </li> </ul>"},{"location":"bio-Annotation/#additional-resources","title":"Additional Resources","text":"<p>R Packages Documentation: - clusterProfiler book - enrichplot documentation</p> <p>Tutorials: - clusterProfiler tutorial - GO enrichment analysis workflow</p> <p>Theory: - Gene Ontology Handbook - Understanding enrichment analysis</p>"},{"location":"bio-Annotation/#genome-features","title":"Genome features","text":"<p>In addition to sequence database alignment, finding spatial relationship within a genome is also an import approach for annotation. Often this is done using software tools such as <code>bedtools</code>.</p>"},{"location":"bio-Annotation/#bedtoolsintersectbed","title":"<code>bedtools::intersectbed</code>","text":"<p>see also https://bedtools.readthedocs.io/en/latest/content/tools/intersect.html</p>"},{"location":"bio-Annotation/#transcriptome-trinity","title":"Transcriptome (Trinity)","text":"<p>After transcriptome assembly using Trinity, run the numbered steps below, in order.</p> <p>NOTE: The following info is long and requires the use of many programs. All of the code listed below are solely examples. Making the commands functional requires a fair amount of organization (i.e. listing paths to programs and input/output files, creating subdirectories for organizing outputs, etc.). See the Use Cases at the end of this section for a more complete picture of how to organize/run this pipeline.</p> <ol> <li> <p>Transdecoder</p> <ul> <li> <p>Identify longest open reading frames (ORFs).</p> </li> <li> <p>Use transcriptome assembly and gene-trans map from Trinity assembly.</p> <pre><code>TransDecoder.LongOrfs \\\n--gene_trans_map Trinity.fasta.gene_trans_map \\\n-t Trinity.fasta\"\n</code></pre> </li> </ul> </li> <li> <p>BLASTp</p> <ul> <li> <p>Run blastp on long ORFs from Step 1 above.</p> </li> <li> <p>Output format 6 produces a standard BLAST tab-delimited file.</p> </li> <li> <p>Settings are recommended in TransDecoder documentation.</p> </li> <li> <p>Peptide database (<code>-db uniprot_sprot.pep</code>) is supplied with Trinotate (e.g. <code>Trinotate-v3.1.1/admin/uniprot_sprot.pep</code>), but can be changed to use your own version.</p> <pre><code>blastp \\\n-query longest_orfs.pep \\\n-db uniprot_sprot.pep \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads ${threads} \\\n&gt; Trinity.fasta.blastp.outfmt6\n</code></pre> </li> </ul> </li> <li> <p>BLASTx (<code>DIAMOND</code>)</p> <ul> <li> <p>Run <code>DIAMOND</code> blastx on long ORFs from Step 1 above.</p> </li> <li> <p>Output format 6 produces a standard BLAST tab-delimited file.</p> </li> <li> <p>Settings (<code>--evalue</code> and <code>--max-target-seqs</code>) are recommended in TransDecoder documentation.</p> </li> <li> <p><code>--block-size</code> and <code>--index-chunks</code> are specific to running <code>DIAMOND</code> BLASTx.</p> </li> <li> <p><code>--db uniprot_sprot.dmnd</code> is a <code>DIAMOND</code>-formatted BLAST database. User can generate their own.</p> <pre><code>```\ndiamond blastx \\\n--db uniprot_sprot.dmnd \\\n--query Trinity.fasta \\\n--out Trinity.fasta.blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n```\n</code></pre> </li> </ul> </li> <li> <p>pFam</p> <ul> <li> <p>Run pfam search on long ORFs from Step 1 above.</p> </li> <li> <p>Protein hidden Markov model database (<code>Pfam-A.hmm</code>) is supplied with Trinotate (e.g. <code>Trinotate-v3.1.1/admin/Pfam-A.hmm</code>), but can be changed to use your own version.</p> <pre><code>hmmscan \\\n--cpu ${threads} \\\n--domtblout Trinity.fasta.pfam.domtblout \\\nPfam-A.hmm \\\nlongest_orfs.pep\n</code></pre> </li> </ul> </li> <li> <p>Transdecoder</p> <ul> <li>Run Transdecoder using transcriptome assembly FastA, <code>blastp</code> and <code>Pfam</code> results.</li> </ul> <pre><code>TransDecoder.Predict \\\n    -t Trinity.fasta \\\n    --retain_pfam_hits Trinity.fasta.pfam.domtblout \\\n    --retain_blastp_hits Trinity.fasta.blastp.outfmt6\n</code></pre> </li> <li> <p>Trinotate</p> <ul> <li> <p>Trinotate requires a large number of steps and programs!</p> <ul> <li> <p>Run <code>signalp</code></p> <pre><code>signalp \\\n-f short \\\n-n Trinity.fasta.trinotate.signalp.out \\\nlongest_orfs.pep\n</code></pre> </li> <li> <p>Run <code>tmHMM</code></p> <pre><code>tmhmm \\\n--short \\\n&lt; longest_orfs.pep \\\n&gt; Trinity.fasta.trinotate.tmhmm.out\n</code></pre> </li> <li> <p>Run <code>RNAmmer</code></p> <ul> <li>Uses a special Trinotate implementation of <code>rnammer</code> (e.g. <code>Trinotate/util/rnammer_support/RnammerTranscriptome.pl</code>)</li> </ul> <pre><code>RnammerTranscriptome.pl \\\n--transcriptome Trinity.fasta \\\n--path_to_rnammer rnammer\n</code></pre> </li> <li> <p>Load transcripts and coding regions into Trinotate SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\ninit \\\n--gene_trans_map Trinity.fasta.gene_trans_map \\\n--transcript_fasta Tinity.fasta \\\n--transdecoder_pep longest_orfs.pep\n</code></pre> </li> <li> <p>Load BLASTp/x homologies into SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_swissprot_blastp \\\nTrinity.fasta.blastp.outfmt6\n</code></pre> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_swissprot_blastx \\\nTrinity.fasta.blastx.outfmt6\n</code></pre> </li> <li> <p>Load Pfam into SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_pfam \\\nTrinity.fasta.pfam.domtblout\n</code></pre> </li> <li> <p>Load transmembrane domains</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_tmhmm \\\nTrinity.fasta.trinotate.tmhmm.out\n</code></pre> </li> <li> <p>Load signal peptides</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_signalp \\\nTrinity.fasta.trinotate.signalp.out\n</code></pre> </li> <li> <p>Load RNAmmer</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_rnammer \\\nTrinity.fasta.rnammer.gff\n</code></pre> </li> <li> <p>Create annotation report</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nreport \\\n&gt; Trinity.fasta.annotation_report.txt\n</code></pre> </li> <li> <p>Extract gene ontology (GO) terms from annotation report</p> <pre><code>extract_GO_assignments_from_Trinotate_xls.pl \\\n--Trinotate_xls Trinity.fasta.annotation_report.txt \\\n-G \\\n--include_ancestral_terms \\\n&gt; Trinity.fasta.go_annotations.txt\n</code></pre> <ul> <li>The output file is formatted like this (<code>&lt;trinity-id&gt;``&lt;tab&gt;``&lt;GO:NNNNNN,GO:NNNNN,...&gt;</code>):</li> </ul> <pre><code>TRINITY_DN0_c0_g1   GO:0003674,GO:0003824,GO:0003964,GO:0006139,GO:0006259,GO:0006310,GO:0006313,GO:0006725,GO:0006807,GO:0008150,GO:0008152,GO:0009987,GO:0016740,GO:0016772,GO:0016779,GO:0032196,GO:0034061,GO:0034641,GO:0043170,GO:0044237,GO:0044238,GO:0044260,GO:0044699,GO:0044710,GO:0044763,GO:0046483,GO:0071704,GO:0090304,GO:1901360\nTRINITY_DN0_c10_g1  GO:0003674,GO:0003824,GO:0004659,GO:0004660,GO:0005488,GO:0005575,GO:0005829,GO:0005875,GO:0005965,GO:0006464,GO:0006807,GO:0008150,GO:0008152,GO:0008270,GO:0008318,GO:0009987,GO:0016740,GO:0016765,GO:0018342,GO:0018343,GO:0019538,GO:0032991,GO:0036211,GO:0043167,GO:0043169,GO:0043170,GO:0043234,GO:0043412,GO:0044237,GO:0044238,GO:0044260,GO:0044267,GO:0044422,GO:0044424,GO:0044430,GO:0044444,GO:0044446,GO:0044464,GO:0046872,GO:0046914,GO:0071704,GO:0097354,GO:1901564,GO:1902494,GO:1990234\nTRINITY_DN0_c2_g4   GO:0000166,GO:0003674,GO:0005488,GO:0005524,GO:0005575,GO:0005737,GO:0005856,GO:0017076,GO:0030554,GO:0032553,GO:0032555,GO:0032559,GO:0035639,GO:0036094,GO:0043167,GO:0043168,GO:0043226,GO:0043228,GO:0043229,GO:0043232,GO:0044424,GO:0044464,GO:0097159,GO:0097367,GO:1901265,GO:1901363\n</code></pre> </li> </ul> </li> <li> <p>Make transcript features annotation map</p> <pre><code>```\nTrinotate_get_feature_name_encoding_attributes.pl \\\nTrinity.fasta.annotation_report.txt \\\n&gt; Trinity.fasta.annotation_feature_map.txt\n```\n</code></pre> </li> </ul> </li> </ol>"},{"location":"bio-Gene-expression/","title":"Gene Expression","text":"<p>This primarily refers to dealing with transcriptome wide analysis (eg RNA-seq, tag-seq). Please see also Roberts and Gavery (2018) Opportunities in Functional Genomics: A Primer on Lab and Computational Aspects There are several workflows out there, but here we outline common workflows in our lab.</p>"},{"location":"bio-Gene-expression/#qc","title":"QC","text":"<p>A normal starting point would be having raw sequence data provided by a core facility. When downloading said data you need to make sure you check the integrity by making sure the hash at the source is the same once you get it to where you want to analyse it.</p> <p>To begin with, you should run fastqc to assess quality. This might vary based on the details of your project but generally you can ID outliers and those samples with poor read quality. Presence of adapters can also be visualized.</p>"},{"location":"bio-Gene-expression/#trimming","title":"trimming","text":"<p>It is debatable how necessary how necessary trimming reads is, though if done correctly there is likely no reason it is detrimental.</p>"},{"location":"bio-Gene-expression/#reference-choice","title":"reference choice","text":"<p>The next step is to take the sequence reads, align, and compare counts. Alignent be done using either a transcriptome or genome. Distinct software that is genome-aware will be needed for the latter.</p>"},{"location":"bio-Gene-expression/#alignment-kallisto-pseudo-alignment","title":"alignment: kallisto (pseudo-alignment)","text":"<p>See the official documentation.</p> <p>User Guides</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<ul> <li> <p>https://github.com/RobertsLab/paper-tanner-crab/blob/master/notebooks/kallisto-4libraries.ipynb tanner crab </p> </li> <li> <p>Mytilus Tag-seq </p> </li> </ul>"},{"location":"bio-Gene-expression/#alignment-hisat2","title":"Alignment: HiSat2","text":"<p>See the official documentation (linked above).</p> <p>Benefits to using <code>HISAT2</code> for alignments:</p> <ul> <li> <p>Fast.</p> </li> <li> <p>Can detect exon/intron junctions (i.e. alternative isoform splice sites).</p> </li> </ul> <p>For RNA-Seq, <code>HISAT2</code> alignments are frequently followed up using <code>StringTie</code> for transcript assembly and quantitation of splice variants.</p> <p>General usage:</p> <ol> <li> <p>Build a <code>HISAT2</code> reference sequence index:</p> <pre><code># Create Hisat2 exons tab file\n\"${programs_array[hisat2_exons]}\" \\\n\"${transcripts_gtf}\" \\\n&gt; \"${exons}\"\n\n# Create Hisat2 splice sites tab file\n\"${programs_array[hisat2_splice_sites]}\" \\\n\"${transcripts_gtf}\" \\\n&gt; \"${splice_sites}\"\n\n# Build Hisat2 reference index using splice sites and exons\n\"${programs_array[hisat2_build]}\" \\\n\"${genome_fasta}\" \\\n\"${genome_index_name}\" \\\n--exon \"${exons}\" \\\n--ss \"${splice_sites}\" \\\n-p \"${threads}\" \\\n2&gt; hisat2-build_stats.txt\n</code></pre> </li> <li> <p>Perform alignment(s):</p> <pre><code># Hisat2 alignments\n\"${programs_array[hisat2]}\" \\\n-x \"${genome_index_name}\" \\\n-1 \"${fastq_list_R1}\" \\\n-2 \"${fastq_list_R2}\" \\\n-S \"${sample_name}\".sam \\\n--threads \"${threads}\" \\\n2&gt; \"${sample_name}\"-hisat2_stats.txt\n\n# Sort SAM files, convert to BAM, and index\n${programs_array[samtools_view]} \\\n-@ \"${threads}\" \\\n-Su \"${sample_name}\".sam \\\n| ${programs_array[samtools_sort]} - \\\n-@ \"${threads}\" \\\n-o \"${sample_name}\".sorted.bam\n${programs_array[samtools_index]} \"${sample_name}\".sorted.bam\n\n\n# Delete unneccessary index files\nrm \"${genome_index_name}\"*.ht2\n\n# Delete unneeded SAM files\nrm ./*.sam\n</code></pre> </li> </ol> <p>See links in the \"use cases\" section below for full-fledged scripts and advanced usage (e.g. assigning read groups to alignment files (SAM) for improved downstream handling/accessiblity).</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li> <p>RNAseq Alignments - P.generosa Alignments and Alternative Transcript Identification Using Hisat2 and StringTie on Mox</p> </li> <li> <p>Splice Site Identification - S.namaycush Liver Parasitized and Non-Parasitized SRA RNAseq Using Hisat2-Stingtie with Genome GCF_016432855.1</p> </li> <li> <p>project-pycno-sizeclass-2022 </p> </li> <li> <p>05.33-lncRNA-discovery-overview: lncRNA pipeline that involves HiSat of RNAseq data </p> </li> </ul>"},{"location":"bio-Gene-expression/#deseq2","title":"DESeq2","text":"<p>See also the official documentation.</p> <p>User Guides - Analyzing RNA-seq data with DESeq2</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab_2","title":"Use cases from our lab","text":"<ul> <li> <p>https://github.com/laurahspencer/O.lurida_QuantSeq-2020/blob/master/notebooks/02-Adult-data-analysis-QuantSeq2020.Rmd - draft code analyzing QuantSeq data from Olympia oyster gill tissue by two factors (population, pCO2 treatment). See 2020-QuantSeq-Processing_Raw-to-Counts.ipynb and 01-Importing-data-QuantSeq2020.Rmd for steps prior to DeSeq2. Author: Laura Spencer </p> </li> <li> <p>https://github.com/RobertsLab/paper-tanner-crab/blob/master/scripts/DESeq.Rmd </p> </li> </ul>"},{"location":"bio_Basics/","title":"Basics","text":"<p>A suite of core fundamental Bioinformatic workflows.</p>"},{"location":"bio_Basics/#shell","title":"Shell","text":"<ul> <li>Introducing the Shell</li> <li>Introduction to the Command Line for Genomics</li> </ul>"},{"location":"bio_Basics/#sequence-alignment-blast","title":"Sequence Alignment - BLAST","text":"<p>Tutorial from FISH546 - starting from a fasta and downloading blast.</p>"},{"location":"bio_Basics/#fastqc","title":"FastQC","text":"<p>Tutorial from FISH546 - running FastQC from Jupyter.</p>"},{"location":"bio_DNA-methylation/","title":"DNA Methylation Analysis","text":""},{"location":"bio_DNA-methylation/#bismark","title":"Bismark","text":"<p>See also the official documentation.</p> <p>User Guides</p> <p>1)  https://felixkrueger.github.io/Bismark/\\ 2)  https://www.bioinformatics.babraham.ac.uk/projects/bismark/</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<p>https://github.com/RobertsLab/code/blob/master/20-bismark.sh</p> <ul> <li> <p>https://github.com/sr320/paper-oly-mbdbs-gen/blob/master/code/00-Bismark.sh - used to processes BS-MBDSeq Data from Olympia oysters, run on Mox. Author: Steven Roberts </p> </li> <li> <p>https://raw.githubusercontent.com/laurahspencer/C.magister_methyl-oa/master/scripts/20201214_Cmag_bismark-align.sh - slurm script used to process MiSeq data from Dungeness crab, run on Mox. Here is a Jupyter Notebook with more details/narrative. Author: Laura Spencer, but derived from the MethCompare workflow. </p> </li> <li> <p>https://github.com/sr320/paper-oly-wgbs/blob/master/submission/Narrative.Rmd part of Rmd narrative, used for WGBS Olympia oyster data. Author: Steven Roberts </p> </li> <li> <p>https://github.com/hputnam/Geoduck_Meth/blob/master/code/03-bismark.sh geoduck environmental memory project. Run on Mox. Author: Steven Roberts </p> </li> <li> <p>https://raw.githubusercontent.com/epigeneticstoocean/paper-gonad-meth/master/code/02-bismark.sh eastern oyster data, run on Mox </p> </li> <li> <p>https://github.com/hputnam/Meth_Compare/blob/master/code/00.01-DNA-sequence-processing.md Complete DNA processing protocol from comparison of BS methods on corals. </p> </li> </ul>"},{"location":"bio_DNA-methylation/#diagram","title":"Diagram","text":""},{"location":"bio_DNA-methylation/#code-output-expectations","title":"Code Output Expectations","text":"<p>(Always default to the Manual/User Guide! - this is merely an attempt at explaining our workflow)</p>"},{"location":"bio_DNA-methylation/#bismark_1","title":"Bismark","text":"<p>Bismark User Guide</p> <p>(I) Running bismark_genome_preparation</p> <p>USAGE: bismark_genome_preparation [options]  <pre><code>${bismark_dir}/bismark_genome_preparation \\\n--verbose \\\n--parallel 28 \\\n--path_to_aligner ${bowtie2_dir} \\\n${genome_folder}\n</code></pre> <p>You should expect to prepared genome with directory structure similar to</p> <pre><code>./roslin_M/Bisulfite_Genome\n./roslin_M/Bisulfite_Genome/GA_conversion\n./roslin_M/Bisulfite_Genome/CT_conversion\n</code></pre> <p>(II) Running bismark</p> <p>USAGE: bismark [options] --genome  {-1  -2  | } <pre><code>find ${reads_dir}*_R1_001_val_1.fq.gz \\\n| xargs basename -s _R1_001_val_1.fq.gz | xargs -I{} ${bismark_dir}/bismark \\\n--path_to_bowtie ${bowtie2_dir} \\\n-genome ${genome_folder} \\\n-p 4 \\\n-score_min L,0,-0.6 \\\n--non_directional \\\n-1 ${reads_dir}{}_R1_001_val_1.fq.gz \\\n-2 ${reads_dir}{}_R2_001_val_2.fq.gz \\\n-o Mcap_tg\n</code></pre> <p>This will create bam files (sequence alignment files)</p> <p>(III) Running deduplicate_bismark</p> <p>deduplicate_bismark --bam [options]  <p>This command will deduplicate the Bismark alignment BAM file and remove all reads but one which align to the the very same position and in the same orientation. This step is recommended for whole-genome bisulfite samples, but should not be used for reduced representation libraries such as RRBS, amplicon or target enrichment libraries.</p> <pre><code>find *.bam | \\\nxargs basename -s .bam | \\\nxargs -I{} ${bismark_dir}/deduplicate_bismark \\\n--bam \\\n--paired \\\n{}.bam\n</code></pre> <p>This will create a deduplicated bam file.</p> <p>(IV) Running bismark_methylation_extractor</p> <p>USAGE: bismark_methylation_extractor [options]  <pre><code>${bismark_dir}/bismark_methylation_extractor \\\n--bedGraph --counts --scaffolds \\\n--multicore 14 \\\n--buffer_size 75% \\\n*deduplicated.bam\n</code></pre> <pre><code># ${bismark_dir}/bismark_methylation_extractor \\\n# --bedGraph \\\n# --counts \\\n# --comprehensive \\\n# --merge_non_CpG \\\n# --multicore 28 \\\n# --buffer_size 75% \\\n# *deduplicated.bam\n</code></pre> <p>This will create deduplicated.bismark.cov.gz, uncompressed is in this format. Not we are using <code>--bedGraph</code> output, this is not default.</p> <p>Alternatively, the output of the methylation extractor can be transformed into a bedGraph and coverage file using the option --bedGraph (see also --counts)... Optionally, the bedGraph counts output can be used to generate a genome-wide cytosine report which reports the number on every single CpG (optionally every single cytosine) in the genome, irrespective of whether it was covered by any reads or not. As this type of report is informative for cytosines on both strands the output may be fairly large.</p> <pre><code>NC_035784.1 141 141 37.5    3   5\nNC_035784.1 142 142 100 2   0\nNC_035784.1 155 155 70  7   3\nNC_035784.1 156 156 100 2   0\nNC_035784.1 291 291 0   0   2\nNC_035784.1 292 292 0   0   3\nNC_035784.1 313 313 0   0   1\nNC_035784.1 314 314 66.6666666666667    2   1\nNC_035784.1 470 470 66.6666666666667    4   2\nNC_035784.1 611 611 0   0   4\n</code></pre> <p><code>&lt;chromosome&gt; &lt;start position&gt; &lt;end position&gt; &lt;methylation percentage&gt; &lt;count methylated&gt; &lt;count unmethylated&gt;</code></p> <p>genome-wide cytosine report output</p> <p>Starting from the coverage output, the Bismark methylation extractor can optionally also output a genome-wide cytosine methylation report. The module coverage2cytosine (part of the Bismark package) may also be run individually. It is also sorted by chromosomal coordinates but also contains the sequence context and is in the following format:  <p>The main difference to the bedGraph or coverage output is that every cytosine on both the top and bottom strands will be considered irrespective of whether they were actually covered by any reads in the experiment or not. For this to work one has to also specify the genome that was used for the Bismark alignments using the option --genome_folder . As for the bedGraph mode, this will only consider cytosines in CpG context by default but can be extended to cytosines in any sequence context by using the option --CX (cf. Appendix (III)). Be aware though that this might mean an output with individual lines for more than 1.1 billion cytosines for any large mammalian genome... <pre><code>find *deduplicated.bismark.cov.gz \\\n| xargs basename -s _trimmed_bismark_bt2.deduplicated.bismark.cov.gz \\\n| xargs -I{} ${bismark_dir}/coverage2cytosine \\\n--genome_folder ${genome_folder} \\\n-o {} \\\n--merge_CpG \\\n--zero_based \\\n{}_trimmed_bismark_bt2.deduplicated.bismark.cov.gz\n</code></pre> <p>generates a file <code>.CpG_report.merged_CpG_evidence.cov</code></p> <pre><code>NC_035785.1 217 219 100.000000  17  0\nNC_035785.1 523 525 87.500000   7   1\nNC_035785.1 556 558 50.000000   5   5\nNC_035785.1 727 729 100.000000  16  0\nNC_035785.1 1330    1332    0.000000    0   2\nNC_035785.1 1403    1405    0.000000    0   2\nNC_035785.1 1494    1496    66.666667   2   1\nNC_035785.1 1747    1749    100.000000  8   0\nNC_035785.1 2024    2026    100.000000  24  0\nNC_035785.1 2054    2056    93.333333   14  1\n</code></pre> <p>(V) Running bismark2report</p> <p>USAGE: bismark2report [options]</p> <pre><code>${bismark_dir}/bismark2report\n</code></pre> <p>(VI) Running bismark2summary</p> <p>USAGE: bismark2summary [options]</p> <p>Produces report like this</p> <pre><code>${bismark_dir}/bismark2summary\n</code></pre> <p>Produces report like this</p>"},{"location":"bio_DNA-methylation/#bs-snpr","title":"BS-Snpr","text":"<p>See https://github.com/hellbelly/BS-Snper</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li>https://nbviewer.org/github/RobertsLab/project-gigas-oa-meth/blob/master/code/07-BS-SNPer.ipynb - Pacific oyster exposed to OA. Author: Yaamini Venkataraman </li> </ul>"},{"location":"bio_DNA-methylation/#epidiversesnp-nextflow-pipeline","title":"<code>EpiDiverse/snp</code> (Nextflow pipeline)","text":"<p>See https://github.com/EpiDiverse/snp</p>"},{"location":"bio_DNA-methylation/#instructions-for-running-on-mox","title":"Instructions for running on Mox","text":"<p>Add the following below your SBATCH script header. Replace <code>bams_dir</code> and <code>genome_fasta</code> locations with your own.</p> <p>NOTE: A FastA index file needs to be present in the same directory as your genome FastA file.</p> <pre><code># These variables need to be set by user\n\n## Directory with BAM(s)\nbams_dir=\"/gscratch/scrubbed/samwhite/data/C_virginica/BSseq/120321-cvBS\"\n\n## Location of EpiDiverse/snp pipeline directory\nepi_snp=\"/gscratch/srlab/programs/epidiverse-pipelines/snp\"\n\n## FastA file is required to end with .fa\n## Requires FastA index file to be present in same directory as FastA\ngenome_fasta=\"/gscratch/srlab/sam/data/C_virginica/genomes/GCF_002022765.2_C_virginica-3.0_genomic.fa\"\n\n## Location of Nextflow\nnextflow=\"/gscratch/srlab/programs/nextflow-21.10.6-all\"\n\n## Specify desired/needed version of Nextflow\nnextflow_version=\"20.07.1\"\n\n\n###################################################################################\n\n\n# Exit script if a command fails\nset -e\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n# Activate NF-core conda environment\nconda activate epidiverse-snp_env\n\n# Count BAMs\n# Needed to pass info to Epidiverse/spn\n# to avoid artificial file count limitation.\nbam_count=0\n\nfor bam in ${bams_dir}*.bam\ndo\n  # Increments counter by 1 for each BAM\n  ((bam_count++))\ndone\n\n## Run EpiDiverse/snp\nNXF_VER=${nextflow_version} \\\n${nextflow} run \\\n${epi_snp} \\\n--input ${bams_dir} \\\n--reference ${genome_fasta} \\\n--variants \\\n--clusters \\\n--take ${bam_count}\n</code></pre>"},{"location":"bio_DNA-methylation/#epidiversewgbs-nextflow-pipeline","title":"<code>EpiDiverse/wgbs</code> (Nextflow pipeline)","text":"<p>See https://github.com/EpiDiverse/wgbs.</p>"},{"location":"bio_DNA-methylation/#instructions-for-running-on-raven","title":"Instructions for running on Raven","text":""},{"location":"bio_DNA-methylation/#instructions-for-running-on-mox_1","title":"Instructions for running on Mox","text":"<p>NOTE: All code below should be added to your SLURM script.</p> <ol> <li>Add the following lines to the beginning (below the header) of your SLURM script:</li> </ol> <pre><code># Load Anaconda\n# Unknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the EpiDiverse/wbgs Anaconda environment\nconda activate epidiverse-wgbs_env\n</code></pre> <ol> <li> <p>Run the Nextflow pipeline. Read the comments in code below for important usage notes.</p> <p>NOTE: Replace items enclosed in <code>&lt;&gt;</code> (including the <code>&lt;&gt;</code> with your own path(s))</p> </li> </ol> <pre><code># Run Nextflow EpiDiverse/wgbs pipeline\n# Expects paired end, gzipped FastQ files named *.fastq.gz. Add --SE parameter to use single end instead.\n# Genome FastA must have a corresponding FastA index file.\n# Can perform trimming if desired. Add --trim parameter.\n# Can run FastQC after trimming. Add --fastqc parameter.\nNXF_VER=20.07.1 \\\n/gscratch/srlab/programs/nextflow \\\n/gscratch/srlab/programs/epidiverse-pipelines/wgbs \\\n--input &lt;path to directory with *.fastq.gz files&gt; \\\n--reference &lt;path to genome FastA&gt; \\\n--INDEX\n</code></pre>"},{"location":"bio_DNA-methylation/#methylkit","title":"Methylkit","text":"<p>See also the official documentation - MethylKit Vignette</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_2","title":"Use cases from our lab","text":"<ul> <li> <p>https://github.com/sr320/paper-oly-mbdbs-gen/blob/master/code/01-methylkit.Rmd - used to processes BS-MBDSeq Data from Olympia oysters, run on personal computer (not Mox). Author: Laura Spencer </p> </li> <li> <p>https://github.com/hputnam/Meth_Compare/blob/master/code/MethCompare_methylKit_analysis.R coral methylation comparison of methods. </p> </li> <li> <p>https://github.com/epigeneticstoocean/paper-gonad-meth/blob/master/code/04-methylkit.Rmd eastern oyster OA work </p> </li> </ul>"},{"location":"bio_DNA-methylation/#diagram_1","title":"Diagram","text":"<p> Flowchart of possible operations by methylKit. A summary of the most importantmethylKit features is shown in a flow chart. It depicts the main features of methylKitand the sequential relationship between them. The functions that could be used for thosefeatures are also printed in the boxes. - Figure and caption from Akalin et al. 2012</p>"},{"location":"bio_DNA-methylation/#characterizing-gene-level-methylation","title":"Characterizing Gene Level Methylation","text":""},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_3","title":"Use cases from our lab","text":"<p>https://sr320.github.io/gene-meth/</p>"},{"location":"bio_Transcriptome-assembly/","title":"Transcriptome Assembly","text":"<p>Introductory guide to transcriptome assembly using <code>Trinity</code> and short-read sequencing data.</p>"},{"location":"bio_Transcriptome-assembly/#qc","title":"QC","text":"<p>A normal starting point would be having raw sequence data provided by a core facility. When downloading said data you need to make sure you check the integrity of the files after transfer by confirming checksum hashes (usually <code>MD5</code> checksums) match those provided by the sequencing facility. </p> <p>You should run <code>FastQC</code> to assess sequencing quality. This might vary based on the details of your project but generally you can ID outliers and those samples with poor read quality. Presence of adapters can also be visualized.</p>"},{"location":"bio_Transcriptome-assembly/#trimming","title":"Trimming","text":"<p>Quality and adapter trimming is required prior to assembly. <code>fastp</code> is recommended due to its speed and FastQC-like report(s). Additionally, the output from <code>fastp</code> can also be analyzed by <code>MultiQC</code> (requires a \"plug-in\"). Trimmed files should be passed through <code>FastQC</code> and assessed. Although rare, some projects may require a second round of trimming.</p> <p>Alternatively, <code>Trinity</code> has trimming capabilities built in, using Trimmomatic. Although convenient, it limits the ability to assess post-trimming sequencing data prior to assembly.</p>"},{"location":"bio_Transcriptome-assembly/#assembly","title":"Assembly","text":"<p><code>Trinity</code> is the de facto standard. It is well-documented, well-supported, and actively updated. Additionally, the developer is very responsive, considerate, and helpful to all GitHub Issues.</p> <p><code>Trinity</code> is powerful and has complex, but useful options availalbe. Take time to consider how you will use your assembly for later analysis. <code>Trinity</code> has many options available for downstream analysis (e.g. gene expression) that can be simplified with careful planning prior to assembly.</p> <p>Due to the intensive processing required for assembly (high CPU and RAM usage), it is highly recommended to run all assemblies on a high-performance computing cluster such as UW's Klone or Raven systems.</p>"},{"location":"bio_Transcriptome-assembly/#sample-list-file","title":"Sample list file","text":"<p>It is recommended to create a sample list file for <code>Trinity</code> to use. One of the biggest benefits is that this sample file list can be used for other downstream operations in the <code>Trinity</code> pipeline. Additionally, it's an easy way to document which sequencing files were used for assembly. Here's the example from <code>Trinity</code>. Sample file list is tab-delimited like this:</p> <pre><code>cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq\ncond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq\ncond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq\ncond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq\n</code></pre>"},{"location":"bio_Transcriptome-assembly/#stranded-sequencing-reads","title":"Stranded sequencing reads","text":"<p><code>Trinity</code> has the option (<code>--SS_lib_type</code>) to specify whether or not the sequences you're assembly are \"stranded\". This is dependent upon the library construction. With that said, most paired-end RNA-seq project libraries are constructed using Illumina's stranded kit. As such, the user should specify this in the following fashion as on option in the <code>Trinity</code> command (example specifies typical stranded libraries): <code>--SS_lib_type RF</code></p> <p>If you do not know whether your libraries are stranded or not (for example, if you downloaded RNA-seq data from NCBI and the metadata doesn't indicate library construction methodology), <code>Trinity</code> has a built-in tool to help assess your sequencing reads, after assembly:</p> <p>Examine-Strand-Specificity</p>"},{"location":"bio_Transcriptome-assembly/#de-novo-assembly","title":"De novo assembly","text":"<p>A de novo assembly is an assembly that is done without the use of a reference genome. Here's an example command, using trimmed paired-end reads. This set of commands will assembly the reads into contigs, generate assembly statistics, a gene map file (maps isoforms to \"gene\" names), and a sequence length file (useful for downstream gene expression).</p> <pre><code># Perform assembly\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--SS_lib_type RF \\\n--max_memory 100G \\\n--CPU ${threads} \\\n--samples_file ${samples}\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".seq_lens\n</code></pre> <ul> <li><code>--max_memory 100G</code> should not be changed, per communications with the developer.</li> </ul> <p>Another example via SR <pre><code>export PATH=/home/shared/jellyfish-2.3.0/bin:$PATH\nexport PATH=/home/shared/bowtie2-2.4.4-linux-x86_64/:$PATH\nexport PATH=/home/shared/salmon-1.4.0_linux_x86_64/bin:$PATH\n/home/shared/trinityrnaseq-v2.12.0/Trinity \\\n--seqType fq \\\n--max_memory 50G \\\n--CPU 8 \\\n--left ../data/raw/der/PSC-0517_R1_001.fastq.gz \\\n--right ../data/raw/der/PSC-0517_R2_001.fastq.gz \\\n--output ../output/01-data-explore/trinity\n</code></pre></p>"},{"location":"bio_Transcriptome-assembly/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<ul> <li>Transcriptome-Assembly-C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox</li> </ul>"},{"location":"bio_Transcriptome-assembly/#genome-guided-assembly","title":"Genome-guided assembly","text":"<p>A genome-guided assembly is an assembly which utilizes a reference genome. This requires a sorted BAM as input, which means you have to have previously aligned your RNA-seq reads to a reference genome. See our Handbook entry on using Hisat2 for read alignment. Here's an example command, using trimmed paired-end reads. This set of commands will assembly the reads into contigs, generate assembly statistics, a gene map file (maps isoforms to \"gene\" names), and a sequence length file (useful for downstream gene expression).</p> <pre><code># Perform assembly\n${programs_array[trinity]} \\\n--genome_guided_bam ${sorted_bam} \\\n--genome_guided_max_intron ${max_intron} \\\n--seqType fq \\\n--SS_lib_type RF \\\n--max_memory 100GB \\\n--CPU ${threads} \\\n--samples_file ${samples}\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".seq_lens\n</code></pre> <ul> <li> <p><code>--genome_guided_max_intron ${max_intron}</code>: The value used in the <code>Trinity</code> examples is 10000.</p> </li> <li> <p><code>--max_memory 100G</code> should not be changed, per communications with the developer.</p> </li> </ul>"},{"location":"bio_Transcriptome-assembly/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li>Transcriptome-Assembly-Genome-guided-C.virginica-Adult-Gonad-OA-RNAseq-Using-Trinity-on-Mox</li> </ul>"},{"location":"bio_Transcriptome-assembly/#output-files","title":"Output files","text":"<p>Both types of assemblies listed above will generate your assembly as a FastA file:</p> <ul> <li><code>Trinity.fasta</code>: This is the default name.</li> </ul> <p>If you ran the commands above you will also get the following files:</p> <ul> <li> <p><code>assembly_stats.txt</code>: Statistics on your assembly. Will look something like this:</p> <pre><code>################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  887315\nTotal trinity transcripts:  1849486\nPercent GC: 36.26\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\nContig N10: 7967\nContig N20: 5284\nContig N30: 3814\nContig N40: 2801\nContig N50: 2062\n\nMedian contig length: 562\nAverage contig: 1117.46\nTotal assembled bases: 2066718534\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\nContig N10: 6904\nContig N20: 4398\nContig N30: 3003\nContig N40: 2120\nContig N50: 1501\n\nMedian contig length: 434\nAverage contig: 860.79\nTotal assembled bases: 763788564\n</code></pre> </li> <li> <p><code>Trinity.fasta.gene_trans_map</code>:</p> <pre><code>TRINITY_GG_1_c20044_g1  TRINITY_GG_1_c20044_g1_i2\nTRINITY_GG_1_c20044_g1  TRINITY_GG_1_c20044_g1_i4\nTRINITY_GG_1_c27757_g4  TRINITY_GG_1_c27757_g4_i1\nTRINITY_GG_1_c4646_g1   TRINITY_GG_1_c4646_g1_i1\nTRINITY_GG_1_c31636_g3  TRINITY_GG_1_c31636_g3_i1\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i2\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i7\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i5\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i6\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i4\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i1\n</code></pre> </li> <li> <p><code>Trinity.fasta.seq_lens</code>:</p> <pre><code>#fasta_entry    length\nTRINITY_GG_1_c20044_g1_i2   1058\nTRINITY_GG_1_c20044_g1_i4   1057\nTRINITY_GG_1_c27757_g4_i1   265\nTRINITY_GG_1_c4646_g1_i1    347\nTRINITY_GG_1_c31636_g3_i1   215\nTRINITY_GG_1_c5375_g1_i2    324\nTRINITY_GG_1_c5375_g1_i7    511\nTRINITY_GG_1_c5375_g1_i5    349\nTRINITY_GG_1_c5375_g1_i6    340\n</code></pre> </li> </ul>"},{"location":"bio_Transcriptome-assembly/#gene-expression","title":"Gene expression","text":""},{"location":"bio_Transcriptome-assembly/#annotation","title":"Annotation","text":""},{"location":"code_Snippets/","title":"Code Snippets","text":"<p>A few useful code chunks.</p>"},{"location":"code_Snippets/#shell-basics","title":"Shell Basics","text":"<p>Most commands are for bash (shell) scripts.</p> <p>Also, assumes usage of bash &gt;=4.0.</p>"},{"location":"code_Snippets/#r-markdown","title":"R Markdown","text":""},{"location":"code_Snippets/#use-bash-variables-across-chunks","title":"Use Bash variables across chunks","text":"<p>Variables are saved to a \u201cdot file\u201d and that file needs to be sourced in each Bash chunk to have access to the Bash variables across Bash chunks.</p> <p>The Bash variables set in the example below are:</p> <ul> <li> <p><code>${threads}</code></p> </li> <li> <p><code>${my_fasta}</code></p> </li> <li> <p><code>${samtools}</code></p> </li> </ul> <pre><code>{bash save-bash-variables-to-rvars-file}\n# Send text to export Bash variables to .rvars file\n{\necho \"# CPU threads\"\necho 'export threads=8'\necho \"\"\necho \"# Programs\"\necho 'export my_fasta=\"~/data/temporary.fasta\"'\necho 'export samtools=\"~/programs/samtools-1.12/samtools\"'\necho \"\"\n} &gt; .rvars\n</code></pre> <p>In subsequent Bash chunks, load the variables into memory to use them:</p> <pre><code>{bash load-bash-variables}\n# Load contents of .rvars into memory so varaibles are accessible\nsource .rvars\n\n# Create FastA index file\n\"${samtools} faidx \"${my_fasta}\"\n</code></pre>"},{"location":"code_Snippets/#git","title":"Git","text":""},{"location":"code_Snippets/#add-files-100mb-to-gitignore-file","title":"Add files &gt;100MB to .gitignore file","text":"<p><code>find ./* -size +100M | cat &gt;&gt; .gitignore</code></p> <p>Run this from top directory of your repo.</p> <p>This finds all files in your current directory (presumably a Git repo) greater than 100MB and writes the paths to those files in your .gitignore file. </p>"},{"location":"code_Snippets/#fastq-files","title":"FastQ files","text":""},{"location":"code_Snippets/#create-separate-arrays-for-r1-and-r2-reads","title":"Create separate arrays for R1 and R2 reads","text":"<ul> <li> <p>With a for loop   <pre><code># Declare arrays\nR1_array=()\nR2_array=()\n\n# Populate arrays\nfor fastq in *R1.fq\ndo\n  R1_array+=(${fastq})\ndone\n\nfor fastq in *R2.fq\ndo\n  R2_array+=(${fastq})\ndone\n</code></pre></p> </li> <li> <p>Using \"globbing\"   <pre><code># Declare arrays\nR1_array=()\nR2_array=()\n\n# Populate arrays\nR1_array=(*R1.fq)\nR2_array=(*R2.fq)\n</code></pre></p> </li> <li> <p>Create comma-separated lists of FastQ reads</p> <p>(E.g. This is useful when running <code>bowtie2</code> or <code>Trinity</code>)</p> <pre><code>R1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n</code></pre> </li> </ul>"},{"location":"code_Snippets/#creating-single-array-with-paired-reads","title":"Creating single array with paired reads","text":"<pre><code>## Assumes there is only a single set of paired reads per sample\n\n# Declare array\nfastq_array=()\n\n# Populate array\n# Corresponding reads will be placed next to each other in array\n# (e.g. sample01_R1.fq sample01_R2.fq sample02_R1.fq samples02_R2.fq)\nfastq_array=(*.fq)\n</code></pre> <ul> <li> <p>Loop through single array of paired reads</p> <pre><code>## Assumes there is only a single set of paired reads per sample\n\n# Declare array\nfastq_array=()\n\n# Populate array\nfastq_array=(*.fq)\n\n# Loop through read pairs\n# Increment by 2 to process next pair of FastQ files\nfor (( i=0; i&lt;${#fastq_array[@]} ; i+=2 ))\n  do\n  echo \"Read 1: ${fastq_array[i]}\"\n  echo \"Read 2: ${fastq_array[i+1]}\"\ndone\n</code></pre> </li> <li> <p>Create comma-separated lists of paired FastQ reads</p> <p>(E.g This is useful when running <code>bowtie2</code> or <code>Trinity</code>)</p> <pre><code># Create comma-separated lists of FastQ reads\n# Loop through read pairs\n# Increment by 2 to process next pair of FastQ files\nfor (( i=0; i&lt;${#fastq_array[@]} ; i+=2 ))\ndo\n  # Check array length for even number (i.e. paire end FastQs)\n  if [[ $(( \"${#fastq_array[@]}\" % 2 )) -ne 0 ]]; then\n    echo \"FastQ array contains uneven number of files.\"\n    exit\n  fi\n\n  # Handle \"fence post\" problem\n  # associated with comma placement\n  if [[ ${i} -eq 0 ]]; then\n    R1_list=\"${fastq_array[${i}]},\"\n    R2_list=\"${fastq_array[${i}+1]},\"\n\n  elif [[ ${i} -eq $(( ${#fastq_array[@]} - 1 )) ]]; then\n    R1_list=\"${R1_list}${fastq_array[${i}]}\"\n    R2_list=\"${R2_list}${fastq_array[${i}+1]}\"\n\n  else\n    R1_list=\"${R1_list}${fastq_array[${i}]},\"\n    R2_list=\"${R2_list}${fastq_array[${i}+1]},\"\n  fi\ndone\n</code></pre> </li> </ul>"},{"location":"code_Snippets/#file-transfers","title":"File Transfers","text":""},{"location":"code_Snippets/#backing-up-mox-files","title":"Backing up Mox files","text":"<pre><code>/volume2/web/seashell/bu-mox$ \nrsync -avz --exclude '*_to_*' --exclude 'CHG_*.txt' --exclude 'CHH_*.txt' --exclude 'CpG_*txt' \\\n--progress sr320@mox.hyak.uw.edu:/gscratch/scrubbed/sr320/ scrubbed/\n\n\n\n/volume2/web/seashell/bu-mox$ \nrsync -avz --progress sr320@mox.hyak.uw.edu:/gscratch/srlab/sr320/ .\n</code></pre>"},{"location":"code_Snippets/#backing-up-raven-files","title":"Backing up Raven files","text":"<pre><code>/home/shared/8TB_HDD_01/sr320/github$ \nrsync -avz . \\\nsr320@gannet.fish.washington.edu:/volume2/web/seashell/bu-github/\n</code></pre>"},{"location":"code_Snippets/#wget-a-lot-of-files-from-url","title":"wget a lot of files from url","text":"<pre><code>wget -r \\\n--no-directories --no-parent \\\n-P . \\\n-A \"*_001_val_1.fq.gz\" https://gannet.fish.washington.edu/metacarcinus/Salmo_Calig/analyses/20190806_TrimGalore/\n</code></pre>"},{"location":"code_Snippets/#git-clone-website","title":"git clone website","text":"<p>when in public_html</p> <pre><code>mkdir temp\ncd temp\ngit clone https://github.com/sr320/lab-website.git\ncd ..\ncp -r temp/lab-website/docs/* .\nrm -f -r temp\necho \"now done\"\n</code></pre>"},{"location":"code_Snippets/#transfer-sequencing-files-to-owl","title":"Transfer sequencing files to Owl","text":""},{"location":"code_Snippets/#standard-rsync-procedure","title":"Standard <code>rsync</code> procedure:","text":"<pre><code>rsync --archive --progress --verbose *.fastq.gz &lt;owl_username&gt;@owl.fish.washington.edu:/volume1/web/nightingales/&lt;species_directory&gt;\n</code></pre> <ul> <li> <p>Replace <code>&lt;owl_username_&gt;</code> with whatever username you use to login to owl (even replace the <code>&lt;</code> and the <code>&gt;</code>).</p> </li> <li> <p>Replace <code>&lt;species_directory&gt;</code> with whatever species you're working with  (even replace the <code>&lt;</code> and the <code>&gt;</code>). Example directory name format: <code>P_generosa</code>.</p> </li> <li> <p>If it doesn't work, Sam may need to change your user settings on Owl, so please post an issue in https://github.com/RobertsLab/resources/issues/</p> </li> </ul>"},{"location":"code_Snippets/#using-rsync-list-of-files","title":"Using <code>rsync</code> list of files:","text":"<pre><code>rsync -avP --files-from=:/volume1/web/nightingales/P_generosa/rsync_list.txt owl:/volume1/web/ .\n</code></pre> <pre><code>head rsync_list.txt\n\nnightingales/P_generosa/Geoduck-ctenidia-RNA-1_S3_L001_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-2_S11_L002_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-3_S19_L003_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-4_S27_L004_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-5_S35_L005_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-6_S43_L006_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-7_S51_L007_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-8_S59_L008_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-gonad-RNA-1_S1_L001_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-gonad-RNA-2_S9_L002_R2_001.fastq.gz\n</code></pre>"},{"location":"code_Snippets/#confirm-md5-checksums","title":"Confirm MD5 checksums","text":""},{"location":"code_Snippets/#multiple-md5-checksum-files-linux","title":"Multiple MD5 checksum files (Linux)","text":"<pre><code>for checksum_file in *.md5\ndo\n  md5sum --check ${checksum_file}\ndone\n</code></pre>"},{"location":"code_Snippets/#multiple-md5-checksum-files-mac-os","title":"Multiple MD5 checksum files (Mac OS)","text":"<pre><code>for checksum_file in *.md5\ndo\n  # Gets filename without any suffixes\n  filename=$(basename -s .md5 ${checksum_file})\n  # Generates MD5 checksum and compares to provided checksum in MD5 file\n  diff &lt;(md5 \"${filename}.fastq.gz\" | awk '{print $4}') &lt;(awk '  {print $1}' ${checksum_file})\ndone\n</code></pre>"},{"location":"code_Snippets/#download-file-from-google-drive","title":"Download file from Google Drive","text":"<p>Install <code>gdown</code>.</p> <p>Ideally, a checksum for the file hosted on Google Drive exists and be can be subsequently verified after downloading.</p> <pre><code>gdown -O PGA_assembly.fasta https://drive.google.com/uc?id=1Yanmb5yBXn-D4b_fzkR2GSxP\n</code></pre>"},{"location":"code_Snippets/#transfer-files-tofrom-mox-using-globus-connect-personal","title":"Transfer files to/from Mox using Globus Connect Personal","text":"<ol> <li> <p>Log into Mox.</p> </li> <li> <p>Activate anaconda (this might fail, let me know if it does and don't bother going to the next step): <code>conda activate</code></p> </li> <li> <p>Setup Globus collection: <code>/gscratch/srlab/programs/globusconnectpersonal-3.1.4/globusconnectpersonal -setup --no-gui</code></p> </li> <li> <p>Follow the instructions (copy/paste URL into browser, get code from webpage, enter code in Mox terminal, provide name for collection).</p> </li> <li> <p>Add desired Mox directory to config file and set permissions. Here's an example:</p> </li> </ol> <pre><code>$cat ~/.globusonline/lta/config-paths\n\n~/,0,1\n/gscratch/scrubbed/samwhite/,0,1\n</code></pre> <p>The config file does two things:</p> <ul> <li><code>~/,0,1</code>: Makes your home directory readable/writeable by Globus.</li> <li> <p><code>/gscratch/scrubbed/samwhite/,0,1</code>: Makes my directory on <code>/gscratch/scrubbed/</code> readable/writeable by Globus.</p> </li> <li> <p>Start Globus Connect Personal: <code>/gscratch/srlab/programs/globusconnectpersonal-3.1.4/globusconnectpersonal -start</code>. Nothing will happen after you hit enter. The cursor will simply flash - this is good.</p> </li> <li> <p>Login to your Globus Connect Personal account via a web browser.</p> </li> <li> <p>Click on Collections and you should now see your collection (name provided in Step 4), and it should have a green stack of papers(?) next to it; the green indicates that the connection is activate.</p> </li> <li> <p>Click on the collection name.</p> </li> <li> <p>Click on \"Open in File Manager\" (on the right side of the screen).</p> </li> <li> <p>Navigate to the directory you setup in Step 5. NOTE: You'll have to navigate up a directory out of your home directory in order to get to the <code>/gscratch</code> partition.</p> </li> <li> <p>Transfer data from other Globus Endpoint to Mox!</p> </li> </ul>"},{"location":"code_Snippets/#fasta","title":"FastA","text":""},{"location":"code_Snippets/#filter-fasta-file-by-minimum-sequence-length","title":"Filter FastA File by Minimum Sequence Length","text":"<p>Just change the number \"200\" in the code below to your desired minimum sequence length.</p> <pre><code>$ awk '!/^&gt;/ { next } { getline seq } length(seq) &gt;= 200 { print $0 \"\\n\" seq }' InputFastaFile.fasta\n</code></pre> <p>Code explanation:</p> <p><code>!/^&gt;/ { next }</code>:</p> <ul> <li>If a line (i.e. record) begins with a \u201c&gt;\u201d, go to the next line (record). The \"!\" tells awk to skip the regular expression that immediatley follows. The \"^\" tells awk that the regular expression it's looking for should only match if it's at the beginning of a line. Finally, the regular expression we're looking for in this example is the \"&gt;\", which denotes the sequence descriptor portion of FASTA files.</li> </ul> <p><code>{ getline seq }</code>:</p> <ul> <li>\u201cgetline\u201d reads the next record and assigns the entire record to a variable called \u201cseq\u201d</li> </ul> <p><code>length(seq) &gt;=200</code>:</p> <ul> <li>If the length of the \u201cseq\u201d record is greater than, or equal to, 200 then\u2026</li> </ul> <p><code>{print $0 \"\\n\" seq&gt;}</code>:</p> <ul> <li>Print all records (<code>$0</code>) of the variable \u201cseq\u201d in the file that matched our conditions, each on a new line (\u201c\\n\u201d)</li> </ul>"},{"location":"code_Snippets/#fasta-to-tab-delimited","title":"fasta to tab-delimited","text":"<pre><code>!perl -e '$count=0; $len=0; while(&lt;&gt;) {s/\\r?\\n//; s/\\t/ /g; if (s/^&gt;//) { if ($. != 1) {print \"\\n\"} s/ |$/\\t/; $count++; $_ .= \"\\t\";} else {s/ //g; $len += length($_)} print $_;} print \"\\n\"; warn \"\\nConverted $count FASTA records in $. lines to tabular format\\nTotal sequence length: $len\\n\\n\";' \\\n../data/GCF_000297895.1_oyster_v9_cds_from_genomic.fna &gt; ../analyses/GCF_000297895.1_oyster_v9_cds_from_genomic.tab\n</code></pre>"},{"location":"code_Snippets/#fastqc","title":"<code>FastQC</code>","text":""},{"location":"code_Snippets/#pass-space-delimited-list-of-fastq-files-to-fastqc","title":"Pass space-delimited list of FastQ files to FastQC","text":"<pre><code># Set CPU threads to use\nthreads=20\n\n# Populate array with FastQ files\nfastq_array=(*.fq.gz)\n\n# Pass array contents to new variable\nfastqc_list=$(echo \"${fastq_array[*]}\")\n\n# Run FastQC\n# NOTE: Do NOT quote ${fastqc_list}\nfastqc \\\n--threads ${threads} \\\n--outdir ${output_dir} \\\n${fastqc_list}\n</code></pre>"},{"location":"code_Snippets/#blast","title":"<code>BLAST</code>","text":"<pre><code>Applications/bioinfo/ncbi-blast-2.11.0+/bin/blastx \\\n-query ../data/GCF_000297895.1_oyster_v9_cds_from_genomic.fna \\\n-db ../blastdb/Caenorhabditis_elegans.WBcel235.pep  \\\n-out ../analyses/Cg-WBcel235_blastx.tab \\\n-evalue 1E-05 \\\n-num_threads 4 \\\n-max_target_seqs 1 \\\n-max_hsps 1 \\\n-outfmt \"6 qaccver saccver evalue\"\n</code></pre>"},{"location":"code_Snippets/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"code_Snippets/#remove-spaces-from-filenames-in-a-directory","title":"Remove spaces from filenames in a directory","text":"<pre><code>for file in *; do mv \"$file\" ${file// /}; done\n</code></pre> <p>Explanation:</p> <ul> <li> <p><code>for file in *;</code></p> </li> <li> <p>A for loop that looks at all files in the current directory. The word <code>file</code> is a variable that takes on the value of each file name in the directory (one file name per loop). The <code>;</code> is needed for bash for loop formatting.</p> </li> <li> <p><code>do mv \"$file\" ${file// /};</code></p> </li> <li> <p>Tells bash to use the move command (<code>mv</code>) and use the current contents of the variable <code>$file</code> as the initial filename. The <code>${file// /}</code> is a substitution command that tells bash to use the contents of the <code>file</code> variable and replace all spaces (<code>//</code> ; note - there should be a space after the last slash here) with nothing (<code>/</code> - you can add text after this slash to replace with information of your choice). The <code>;</code> is needed for bash for loop formatting.</p> </li> <li> <p><code>done</code></p> </li> <li>Ends the for loop</li> </ul>"},{"location":"klone_Adding-a-User/","title":"New User","text":"<p>The first step for being added to the Roberts Lab account is to submit an issue requesting access. Once you have been added into the UW-IT system (you will notified by a response in the GitHub issue), you can follow the steps below.</p> <p>Taken from here</p> <p>For the user:</p> <ol> <li>Go to https://uwnetid.washington.edu/manage/</li> <li>Click the \"Computing Services\" link on the left</li> <li>Click the \"Hyak Server\" and \"Lolo Server\" check boxes in the \"Inactive Services\" section.</li> <li>Click the \"Subscribe &gt;\" button at the bottom of the page.</li> <li>Read the notice and click the \"Finish\" button.</li> </ol> <p>For two factor authentication, you'll need to sign up for Duo here.</p>"},{"location":"klone_Adding-a-User/#steps-for-administrators-ie-steven-or-sam","title":"Steps for administrators (i.e. Steven or Sam):","text":"<ol> <li>Proceed to the UW-IT Groups Service.</li> <li>Click the \"Find my groups\" link in the \"Find groups\" section.</li> <li>In the search results section, there should be a link u_hyak_srlab. Click it</li> <li>It will bring up a description of your group. Click the \"Membership\" link.</li> <li>Type the UW NetID(s) into the \"Add members\" text field and click the \"Do it\" button. Newly added user(s) should now appear in the \"Membership\" section. An error window will appear if the user(s) cannot be added.</li> <li>Notify the users that they have been added.</li> </ol>"},{"location":"klone_Conda/","title":"Using Conda on Klone","text":""},{"location":"klone_Conda/#overview","title":"Overview","text":"<p>Warning</p> <p>As a best practice, please use our bioinformatics container(s) for your Conda workflows instead of installing conda packages directly on Klone. Containers provide a consistent and reproducible environment, reducing dependency issues and simplifying software management.</p> <p>Conda (including Miniforge, Miniconda, and Anaconda) is a popular package manager for Python and other languages. However, conda installations and environments can quickly consume significant disk space. This guide explains how to properly install and configure conda on Klone to avoid storage limitations.</p>"},{"location":"klone_Conda/#storage-considerations","title":"Storage Considerations","text":"<p>Klone has different storage locations with varying capacities:</p> <ul> <li>Home directory (<code>/mmfs1/home/&lt;UW_NetID&gt;</code>): Only 10GB - NOT recommended for conda</li> <li>Group storage (<code>/mmfs1/gscratch/srlab/&lt;UW_NetID&gt;</code>): 1.024TB shared - Recommended for conda</li> <li>Temporary storage (<code>/gscratch/scrubbed/&lt;UW_NetID&gt;</code>): 200TB but files deleted after 30 days</li> </ul> <p>Important: Always install conda in group storage (<code>/mmfs1/gscratch/srlab/&lt;UW_NetID&gt;</code>) to avoid hitting the 10GB home directory limit.</p>"},{"location":"klone_Conda/#fresh-conda-installation","title":"Fresh Conda Installation","text":""},{"location":"klone_Conda/#step-1-download-miniforge-recommended","title":"Step 1: Download Miniforge (Recommended)","text":"<pre><code># Navigate to your group storage directory\ncd /mmfs1/gscratch/srlab/${USER}\n\n# Download Miniforge (recommended over Anaconda for smaller size)\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n</code></pre>"},{"location":"klone_Conda/#step-2-install-to-group-storage","title":"Step 2: Install to Group Storage","text":"<pre><code># Run the installer\nbash Miniforge3-Linux-x86_64.sh\n\n# When prompted for installation location, specify:\n# /mmfs1/gscratch/srlab/${USER}/miniforge3\n\n# Answer \"yes\" when asked to initialize conda\n</code></pre>"},{"location":"klone_Conda/#step-3-configure-your-shell","title":"Step 3: Configure Your Shell","text":"<p>Add the following to your <code>~/.bashrc</code> file:</p> <pre><code># Initialize conda from group storage location\neval \"$(/mmfs1/gscratch/srlab/${USER}/miniforge3/bin/conda shell.bash hook)\"\n</code></pre> <p>Then reload your shell:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"klone_Conda/#moving-existing-conda-installation","title":"Moving Existing Conda Installation","text":"<p>If you already have conda installed in your home directory and are running out of space:</p>"},{"location":"klone_Conda/#step-1-check-current-installation","title":"Step 1: Check Current Installation","text":"<pre><code># Check where conda is currently installed\nwhich conda\nconda info --base\n\n# Check current storage usage\nhyakstorage\n</code></pre>"},{"location":"klone_Conda/#step-2-create-new-installation-location","title":"Step 2: Create New Installation Location","text":"<pre><code># Create directory in group storage\nmkdir -p /mmfs1/gscratch/srlab/${USER}\n</code></pre>"},{"location":"klone_Conda/#step-3-move-the-installation","title":"Step 3: Move the Installation","text":"<pre><code># Stop any running conda processes\nconda deactivate\n\n# Move the entire conda installation\nmv /mmfs1/home/${USER}/miniforge3 /mmfs1/gscratch/srlab/${USER}/\n\n# Or if you have anaconda3:\n# mv /mmfs1/home/${USER}/anaconda3 /mmfs1/gscratch/srlab/${USER}/\n</code></pre>"},{"location":"klone_Conda/#step-4-update-shell-configuration","title":"Step 4: Update Shell Configuration","text":"<p>Edit your <code>~/.bashrc</code> file to remove the old conda initialization and add the new one:</p> <pre><code># Remove or comment out old lines like:\n# eval \"$(/mmfs1/home/${USER}/miniforge3/bin/conda shell.bash hook)\"\n\n# Add new initialization:\neval \"$(/mmfs1/gscratch/srlab/${USER}/miniforge3/bin/conda shell.bash hook)\"\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"klone_Conda/#step-5-verify-the-move","title":"Step 5: Verify the Move","text":"<pre><code># Check new location\nwhich conda\nconda info --base\n\n# Check that environments are accessible\nconda env list\n\n# Verify storage usage improvement\nhyakstorage\n</code></pre>"},{"location":"klone_Conda/#configuring-conda-environment-location","title":"Configuring Conda Environment Location","text":"<p>To ensure all conda environments are created in group storage:</p>"},{"location":"klone_Conda/#method-1-set-default-environment-directory","title":"Method 1: Set Default Environment Directory","text":"<pre><code># Create conda configuration directory\nmkdir -p ~/.conda\n\n# Create/edit conda configuration file\ncat &gt; ~/.conda/condarc &lt;&lt; EOF\nenvs_dirs:\n  - /mmfs1/gscratch/srlab/${USER}/miniforge3/envs\n  - /mmfs1/gscratch/srlab/${USER}/conda_envs\npkgs_dirs:\n  - /mmfs1/gscratch/srlab/${USER}/miniforge3/pkgs\n  - /mmfs1/gscratch/srlab/${USER}/conda_pkgs\nEOF\n</code></pre>"},{"location":"klone_Conda/#method-2-always-specify-environment-location","title":"Method 2: Always Specify Environment Location","text":"<p>When creating environments, explicitly specify the location:</p> <pre><code># Create environment in group storage\nconda create --prefix /mmfs1/gscratch/srlab/${USER}/conda_envs/myenv_name package_name\n\n# Activate environment\nconda activate /mmfs1/gscratch/srlab/${USER}/conda_envs/myenv_name\n</code></pre>"},{"location":"klone_Conda/#best-practices","title":"Best Practices","text":""},{"location":"klone_Conda/#environment-management","title":"Environment Management","text":"<ul> <li>Use descriptive names: Name environments after projects or specific purposes</li> <li>Create project-specific environments: Avoid conflicts by keeping environments separate</li> <li>Regular cleanup: Remove unused environments to save space</li> <li>Document dependencies: Keep track of package requirements for reproducibility</li> </ul>"},{"location":"klone_Conda/#space-management","title":"Space Management","text":"<pre><code># Check conda disk usage\ndu -sh /mmfs1/gscratch/srlab/${USER}/miniforge3\n\n# Clean conda cache periodically\nconda clean --all\n\n# List environments and their sizes\nconda env list\ndu -sh /mmfs1/gscratch/srlab/${USER}/miniforge3/envs/*\n</code></pre>"},{"location":"klone_Conda/#backup-and-sharing","title":"Backup and Sharing","text":"<pre><code># Export environment for sharing/backup\nconda env export --name myenv &gt; environment.yml\n\n# Recreate environment from file\nconda env create --file environment.yml --prefix /mmfs1/gscratch/srlab/${USER}/conda_envs/myenv_restored\n</code></pre>"},{"location":"klone_Conda/#integration-with-slurm-jobs","title":"Integration with SLURM Jobs","text":"<p>When using conda environments in SLURM jobs, ensure you activate the environment correctly:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=my_conda_job\n#SBATCH --partition=compute\n#SBATCH --nodes=1\n#SBATCH --time=1:00:00\n\n# Initialize conda\neval \"$(/mmfs1/gscratch/srlab/${USER}/miniforge3/bin/conda shell.bash hook)\"\n\n# Activate your environment\nconda activate /mmfs1/gscratch/srlab/${USER}/conda_envs/myenv_name\n\n# Run your analysis\npython my_script.py\n</code></pre>"},{"location":"klone_Conda/#troubleshooting","title":"Troubleshooting","text":""},{"location":"klone_Conda/#environment-not-found","title":"Environment Not Found","text":"<p>If conda can't find your environments after moving:</p> <pre><code># Check conda configuration\nconda config --show envs_dirs\n\n# List all environments with full paths\nconda env list\n\n# Manually specify environment path\nconda activate /full/path/to/environment\n</code></pre>"},{"location":"klone_Conda/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission errors:</p> <pre><code># Check directory permissions\nls -la /mmfs1/gscratch/srlab/${USER}/\n\n# Fix permissions if needed\nchmod -R u+rwX /mmfs1/gscratch/srlab/${USER}/miniforge3\n</code></pre>"},{"location":"klone_Conda/#storage-still-full","title":"Storage Still Full","text":"<p>If home directory is still full after moving conda:</p> <pre><code># Check what's using space\ndu -sh /mmfs1/home/${USER}/*\ndu -sh /mmfs1/home/${USER}/.*\n\n# Common culprits to move to group storage:\n# - .nextflow directory\n# - .sra cache\n# - Large data files\n# - Git repositories\n</code></pre>"},{"location":"klone_Conda/#see-also","title":"See Also","text":"<ul> <li>Klone Data Storage and System Organization</li> <li>Klone Installing Programs</li> <li>Raven Conda Usage (for comparison)</li> </ul>"},{"location":"klone_Data-Storage-and-System-Organization/","title":"Data Storage and System Organization","text":""},{"location":"klone_Data-Storage-and-System-Organization/#hyak-klone-storage-locations-capacities","title":"Hyak (klone) Storage Locations &amp; Capacities","text":""},{"location":"klone_Data-Storage-and-System-Organization/#1-user-specific-storage","title":"1. User-specific storage","text":"<ul> <li>Storage allocation: 10GB (or 256,000 files)</li> <li>Located on your login node (e.g. <code>/mmfs1/home/&lt;UW_NetID&gt;</code>)</li> <li>To see space and file utilization: <code>hyakstorage</code></li> <li>For personal data, scripts, and other small files, or files you don't want potentially changed by others.</li> <li>Note: This space fills up quickly with large software installations like conda/miniforge, Nextflow cache, or SRA data. Consider installing these in group storage instead.</li> </ul>"},{"location":"klone_Data-Storage-and-System-Organization/#2-group-specific-storage","title":"2. Group-specific storage","text":"<ul> <li>Storage allocation: 1.024TB (or 1,000,000 files)</li> <li>Located: <code>/gscratch/srlab/</code></li> <li>Shared by all <code>srlab</code> members.</li> <li>To see space and file utilization: <code>hyakstorage</code></li> <li>Recommended for: Large software installations (conda/miniforge, Nextflow), analysis environments, shared datasets, and any files that might grow beyond a few GB.</li> </ul>"},{"location":"klone_Data-Storage-and-System-Organization/#3-temporary-storage-scrubbed","title":"3. Temporary storage (\"Scrubbed\")","text":"<ul> <li>Storage allocation: 200TB (or 200,000,000 files).</li> <li>Located: <code>/gscratch/scrubbed/&lt;UW_NetID&gt;</code></li> <li>Shared by all Hyak (Klone) users.</li> <li>Files are automatically deleted 30 days after creation.</li> </ul>"},{"location":"klone_Data-Storage-and-System-Organization/#suggested-user-organization","title":"Suggested User Organization","text":"<p>You should be aware of storage limits above, but here is a suggestion of how to organize your files.</p> <p>In our group-specific storage (<code>/gscratch/srlab/&lt;UW_NetID&gt;</code>) create clear subdirectories that any files that might be needed over the course of months or years and are not large in size. This is also the recommended location for:</p> <ul> <li>Software installations: conda/miniforge, Nextflow, and other large software packages</li> <li>Analysis environments: conda environments, virtual environments  </li> <li>Shared datasets: Reference genomes, databases, and other data used across projects</li> <li>Long-term analysis outputs: Results that need to persist beyond 30 days</li> </ul> <p>Generally you will need to  use the temporary storage. Roughly &gt;= 100GB of input or output would qualify for using this space. Of course this will always depend on our free space in group-specific storage. Just be aware of the 30 day limit in <code>/gscratch/scrubbed/</code>. </p> <p>An example of how Steven operates:</p> <ul> <li>For every job, he creates a directory (e.g. <code>/gscratch/scrubbed/sr320/020322-oly-snp</code>) and includes job shell script in this directory and write out to same directory. Once complete he transfers the directory via <code>rsync</code> to his personal directory on Gannet.</li> </ul>"},{"location":"klone_File-Transfers/","title":"File Transfers","text":""},{"location":"klone_File-Transfers/#rsync","title":"<code>rsync</code>","text":""},{"location":"klone_File-Transfers/#transferring-data-tofrom-klone-hyak-with-rsync","title":"Transferring data to/from Klone (Hyak) with <code>rsync</code>","text":"<p><code>rsync</code> is a file transfer program and is the recommended file transfer program for Roberts Lab member. It copies specified files/folders from one location to another. Importantly, it verifies data integrity after the files have been transferred. This feature is critical, due to the large file sizes we frequently work with.</p>"},{"location":"klone_File-Transfers/#copy-files-to-klone","title":"Copy files to Klone:","text":"<pre><code>rsync --archive --progress --verbose /path/to/file/on/your/computer/file.txt &lt;UW_NetID&gt;@klone.hyak.uw.edu:/gscratch/scrubbed/&lt;UW_NetID&gt;/directory\n</code></pre>"},{"location":"klone_File-Transfers/#copy-entire-folder-to-klone-it-is-important-to-make-sure-there-is-no-at-the-end-of-the-remote-path","title":"Copy entire folder to Klone (it is important to make sure there is no <code>/</code> at the end of the remote path):","text":"<p>Navigate to the directory immediately above the one which you are interested in copying and then run the following command):</p> <pre><code>rsync --archive --progress --verbose --relative ./directory &lt;UW_NetID&gt;@klone.hyak.uw.edu:/gscratch/scrubbed/&lt;UW_NetID&gt;/directory\n</code></pre>"},{"location":"klone_File-Transfers/#copy-files-from-klone","title":"Copy files from Klone:","text":"<pre><code>rsync --archive --progress --verbose &lt;UW_NetID&gt;@klone.hyak.uw.edu:/gscratch/scrubbed/&lt;UW_NetID&gt;/file.txt /path/to/local/directory\n</code></pre>"},{"location":"klone_Installing-Programs/","title":"Containers","text":"<p>Computing on Klone requires the use of containers. Specifically, the Univ. of Washington utilizes Apptainer (formerly Singularity) on Klone for building/executing/running containers. See the section about containers for more background info.</p> <p>The container the Roberts Lab uses hosts virtually all of the software we use. Its location on Klone:</p> <p><code>/gscratch/srlab/containers/srlab-bioinformatics-container-&lt;git_commit_hash&gt;.sif</code></p> <ul> <li><code>&lt;git_commit_hash&gt;</code> is the corresponding git commit for the container definition file from which the container was built. This allows users to re-build previous versions of containers, if desired. It also allows users to keep track of which version of the container is being used.</li> </ul>"},{"location":"klone_Installing-Programs/#alternative-conda-environments","title":"Alternative: Conda Environments","text":"<p>For users who prefer or need to use conda/miniforge for package management outside of containers, see the Klone Conda Guide. This guide covers proper installation locations and configuration to avoid storage limitations.</p>"},{"location":"klone_Installing-Programs/#definition-files","title":"Definition file(s)","text":"<p>The definition files are used to build the containers. They also contain all the instructions for software installation. Software cannot be installed in a container after it is built. To install new software, the container definition file needs to be updated with instructions for downloading and installing the software. Then, a new version of the container needs to be built, in order to incorporate the new software.</p> <p>The definition file is in a git repo on Klone:</p> <p><code>/gscratch/srlab/gitrepos/RobertsLab/code/apptainer_definition_files/srlab-bioinformatics-container.def</code></p> <ul> <li>To minimize conflicts, please do not modify the git repo on Klone (other than using <code>git pull</code> to update the repo). Any changes should be made on your own computer or on GitHub, and then pulled to Klone.</li> </ul>"},{"location":"klone_Installing-Programs/#building-containers","title":"Building containers","text":"<p>Containers are built using a definition file. Once built, they exist as a single file. Since we're using Apptainer (formerly Singularity), the container files will have the <code>.sif</code> suffix. Currently, we use the script <code>srlab-bioinformatics-build.sh</code> (GitHub) to build the container directly on Klone. However, the container could be built on any computer running Apptainer (formerly Singularity), and the resulting file could be transferred to Klone. </p> <p>The build process must be initiated manually. If the definition file(s) is updated, then the user must remember to re-build the container, in order to incorporate the new changes!</p>"},{"location":"klone_Installing-Programs/#more-resources","title":"More Resources","text":"<ul> <li>Klone Conda Guide - For installing and configuring conda/miniforge on Klone</li> <li>UW Hyak Documentation is a great way to start using Hyak (Klone) by providing (relatively) easy to follow walkthrough of how to access Klone, what the different nodes are, examples of how to build containers, and more.</li> </ul>"},{"location":"klone_Logging-In/","title":"Logging in","text":"<ol> <li>Open your favorite terminal</li> <li>Type <code>ssh &lt;YourUWNetID&gt;@klone.hyak.uw.edu</code> (replace <code>&lt;YourUWNetID&gt;</code> with your own UW Net ID)</li> <li>Input your UWNetID password</li> <li>Approve the two-factor authentication.</li> <li>You're logged in to a Login node for Hyak!</li> </ol> <p>Example:</p> <pre><code>D-69-91-141-150:~ Sean$ ssh seanb80@klone.hyak.uw.edu\nPassword:\nEnter passcode or select one of the following options:\n\n 1. Duo Push to iOS (XXX-XXX-1239)\n 2. Phone call to iOS (XXX-XXX-1239)\n\nDuo passcode or option [1-2]: 1\nPasscode or option (1-2): 1\nSuccess. Logging you in...\n     _    _                    _                 _\n    | | _| | ___  _ __   ___  | |__  _   _  __ _| | __\n    | |/ / |/ _ \\| '_ \\ / _ \\ | '_ \\| | | |/ _` | |/ /\n    |   &lt;| | (_) | | | |  __/ | | | | |_| | (_| |   &lt;\n    |_|\\_\\_|\\___/|_| |_|\\___| |_| |_|\\__, |\\__,_|_|\\_\\\n                                     |___/\n\nThis login node is meant for interacting with the job scheduler and \ntransferring data to and from KLONE. Please work by requesting an \ninteractive session on (or submitting batch jobs to) compute nodes.\n\nVisit the HYAK website for more documentation:\nhttps://hyak.uw.edu/docs/\n\nQuestions? E-mail help@uw.edu with \"hyak\" in the subject.\n\nRun \"scontrol show res\" to see any reservations in place that will \nprevent your jobs from running with the reason \"ReqNodeNotAvail\".\n\n\n[seanb80@klone2 ~]$\n</code></pre>"},{"location":"klone_Node-Types/","title":"Node Types","text":"<p>There are two types of Klone slices (i.e. nodes, computers, blades):</p> <ul> <li> <p>Login</p> </li> <li> <p>Compute</p> </li> </ul> <p>Each has a different function and different levels of connectivity.</p>"},{"location":"klone_Node-Types/#login-node","title":"Login Node","text":"<ul> <li>Shell prompt looks like <code>[&lt;UW_NetID&gt;@klone-login03 ~]$</code></li> <li>The first node you encounter upon logging in.</li> <li>Access to this node type is user-specific (i.e. only you have access to your login node).</li> <li>For file transfers and manipulation.</li> <li>This node has internet connectivity.     </li> <li>Not for running programs, program compiling, or other time/compute power intensive tasks.</li> </ul>"},{"location":"klone_Node-Types/#compute-node","title":"Compute Node","text":"<ul> <li>Runs computing jobs submitted via an <code>SLURM</code> script. or in an interactive session.</li> <li>For execution of large tasks. The \"heavy lifting\" node.</li> <li>This node has internet connectivity.</li> <li>Access to this node type is limited to the Roberts Lab group, but is limited to a single group member at one time.</li> <li>Cannot use interactively while node is in use.</li> <li>Creates <code>slurm-job#.out</code> files in working directory specified in <code>SLURM</code> execution script. This contains all standard out and error output from the program. This can be monitored via <code>cat</code> or <code>tail</code> from a Login node.</li> <li><code>top</code> and other task manager functions can only be accessed after <code>ssh</code>ing in to the node.</li> </ul>"},{"location":"klone_Node-Types/#interactive-node","title":"Interactive Node","text":"<p>Starting an interactive node allows us to use the compute node directly from a terminal without the need to submit a job to the SLURM scheduler. Like the SLURM scheduler, you still need to specify the resources you want to use (i.e. RAM and CPU count), as well as the time you'd like to reserve those resources. Unlike the SLURM scheduler, your session will hold the resources until the end of the time requested. The resources will not be returned when your commands finish! Thus, please be sure to use the <code>exit</code> command once you have finished with your intended computing when using an interactive node. This will ensure that you don't accidentally hold the node's resources and prevent other lab members from accessing it.</p> <p>Example command to start interactive node:</p> <p><code>srun -p compute -A srlab --time=02:00:00 --mem=50G --pty /bin/bash</code></p> <ul> <li> <p><code>srun</code>: Command to start interactive node.</p> </li> <li> <p><code>-p cpu-g2-mem2x</code>: Tells Hyak to use our partition, called <code>cpu-g2-mem2x</code>.</p> </li> <li> <p><code>-A srlab</code>: Tells Hyak to use our account, called <code>srlab</code>.</p> </li> <li> <p><code>--time=02:00:00</code>: Requests the resources reservation for 2hrs, 00mins, and 00secs.</p> </li> <li> <p><code>--mem=50G</code>: Requests 50GB of RAM from our node.</p> </li> <li> <p><code>--pty /bin/bash</code>: Tells Hyak to start a terminal session, using Bash.</p> </li> </ul>"},{"location":"klone_Node-Types/#execute-node","title":"Execute Node","text":""},{"location":"klone_RStudio-Server/","title":"RStudio Server","text":""},{"location":"klone_RStudio-Server/#quick-start-guide","title":"Quick Start Guide","text":"<p>Screen Recording How-to (UW sign-in required)</p> <p>Example SLURM Script to launch RStudio Server.</p> <p>The example will use the <code>srlab-bioinformatics-container-2bd5d44.sif</code> container in the SLURM script called <code>rstudio-server.job</code>.</p> <p>NOTE: the <code>srlab-bioinformatics-container-2bd5d44.sif</code> container needs to be copied into the {USER} directory and <code>RSTUDIO_CWD=</code> must point to this path.</p> <ul> <li> <p>User needs to set/change the following in the SLURM script before starting script:</p> <ul> <li><code>#SBATCH --time=02:00:00</code></li> <li><code>#SBATCH --mem=20G</code></li> <li><code>--chdir=/gscratch/scrubbed/${USER}/&lt;add_rest_of_path&gt;</code></li> <li><code>RSTUDIO_SIF=\"srlab-bioinformatics-container-2bd5d44.sif\" # UPDATE THIS LINE</code></li> </ul> </li> <li> <p>Users should add the following line in <code>~/.Renviron</code>. If you don't have a <code>~/.Renviron</code>, you can create it like this: <code>touch ~/.Renviron</code></p> <ul> <li> <p><code>R_LIBS_USER</code> in <code>~/.Renviron</code>. Example:</p> <pre><code>cat ~/.Renviron \n# Set local library installation path\nR_LIBS_USER=/gscratch/srlab/${USER}/R_libs_apptainer\n</code></pre> </li> </ul> </li> <li> <p>After submitting script (<code>sbatch rstudio-server.job</code>), view the SLURM output file located in <code>--chdir=/gscratch/scrubbed/${USER}/&lt;add_rest_of_path&gt;</code> for information on:</p> <ol> <li> <p>How to create tunnel to Mox node.</p> </li> <li> <p>NOTE: When logging into the tunnel, the terminal will not acknowledge when you've logged in. You need to leave this Terminal window open.</p> </li> <li> <p>What address to direct your web browser to (<code>localhost:8787</code>).</p> </li> <li> <p>Username/password to enter into RStudio Server interface.</p> </li> <li> <p>How to terminate RStudio Server and the SLURM job.</p> </li> </ol> </li> <li> <p>Example script uses the following Apptainer container image: <code>srlab-bioinformatics-container-2bd5d44.sif</code>.</p> </li> </ul> <pre><code>$ cat rstudio-server.job \n\n\n#!/bin/sh\n\n#SBATCH --job-name=rstudio-server\n#SBATCH --account=srlab\n#SBATCH --partition=cpu-g2-mem2x #update this line - use hyakalloc to find partitions you can use\n#SBATCH --time=02:00:00\n#SBATCH --nodes=1\n#SBATCH --mem=20G\n#SBATCH --signal=USR2\n#SBATCH --output=%x_%j.out\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/${USER}\n\n# This script will request a single CPU with four threads with 20GB of RAM for 2 hours. \n# You can adjust --time, --nodes, --ntasks, and --mem above to adjust these settings for your session.\n\n# --output=%x_%j.out creates a output file called rstudio-server_NNNNNNNN.out \n# where the %x is short hand for --job-name above and the N's are an 8-digit \n# jobID assigned by SLURM when our job is submitted.\n\nRSTUDIO_CWD=\"/gscratch/srlab/containers\" # UPDATE THIS LINE\nRSTUDIO_SIF=\"srlab-bioinformatics-container-2bd5d44.sif\" # UPDATE THIS LINE\n\n# Create temp directory for ephemeral content to bind-mount in the container\nRSTUDIO_TMP=$(/usr/bin/python3 -c 'import tempfile; print(tempfile.mkdtemp())')\n\nmkdir -p -m 700 \\\n        ${RSTUDIO_TMP}/run \\\n        ${RSTUDIO_TMP}/tmp \\\n        ${RSTUDIO_TMP}/var/lib/rstudio-server\n\ncat &gt; ${RSTUDIO_TMP}/database.conf &lt;&lt;END\nprovider=sqlite\ndirectory=/var/lib/rstudio-server\nEND\n\n# Set OMP_NUM_THREADS to prevent OpenBLAS (and any other OpenMP-enhanced\n# libraries used by R) from spawning more threads than the number of processors\n# allocated to the job.\n#\n# Set R_LIBS_USER to a path specific to rocker/rstudio to avoid conflicts with\n# personal libraries from any R installation in the host environment\n\ncat &gt; ${RSTUDIO_TMP}/rsession.sh &lt;&lt;END\n#!/bin/sh\n\nexport OMP_NUM_THREADS=${SLURM_JOB_CPUS_PER_NODE}\nexport R_LIBS_USER=${RSTUDIO_CWD}/R\nexec /usr/lib/rstudio-server/bin/rsession \"\\${@}\"\nEND\n\nchmod +x ${RSTUDIO_TMP}/rsession.sh\n\nexport APPTAINER_BIND=\"${RSTUDIO_CWD}:${RSTUDIO_CWD},/gscratch:/gscratch,${RSTUDIO_TMP}/run:/run,${RSTUDIO_TMP}/tmp:/tmp,${RSTUDIO_TMP}/database.conf:/etc/rstudio/database.conf,${RSTUDIO_TMP}/rsession.sh:/etc/rstudio/rsession.sh,${RSTUDIO_TMP}/var/lib/rstudio-server:/var/lib/rstudio-server\"\n\n# Do not suspend idle sessions.\n# Alternative to setting session-timeout-minutes=0 in /etc/rstudio/rsession.conf\nexport APPTAINERENV_RSTUDIO_SESSION_TIMEOUT=0\n\nexport APPTAINERENV_USER=$(id -un)\nexport APPTAINERENV_PASSWORD=$(openssl rand -base64 15)\n\n# get unused socket per https://unix.stackexchange.com/a/132524\n# tiny race condition between the python &amp; apptainer commands\nreadonly PORT=$(/mmfs1/sw/pyenv/versions/3.9.5/bin/python -c 'import socket; s=socket.socket(); s.bind((\"\", 0)); print(s.getsockname()[1]); s.close()')\ncat 1&gt;&amp;2 &lt;&lt;END\n1. SSH tunnel from your workstation using the following command:\n\n   ssh -N -L 8787:${HOSTNAME}:${PORT} ${APPTAINERENV_USER}@klone.hyak.uw.edu\n\n   and point your web browser to http://localhost:8787\n\n2. log in to RStudio Server using the following credentials:\n\n   user: ${APPTAINERENV_USER}\n   password: ${APPTAINERENV_PASSWORD}\n\nWhen done using RStudio Server, terminate the job by:\n\n1. Exit the RStudio Session (\"power\" button in the top right corner of the RStudio window)\n2. Issue the following command on the login node:\n\n      scancel -f ${SLURM_JOB_ID}\nEND\n\nsource /etc/bashrc\nmodule load apptainer\n\napptainer exec --cleanenv --home ${RSTUDIO_CWD} ${RSTUDIO_CWD}/${RSTUDIO_SIF} \\\n    rserver --www-port ${PORT} \\\n            --auth-none=0 \\\n            --auth-pam-helper-path=pam-helper \\\n            --auth-stay-signed-in-days=30 \\\n            --auth-timeout-minutes=0 \\\n            --rsession-path=/etc/rstudio/rsession.sh \\\n            --server-user=${APPTAINERENV_USER}\n\nAPPTAINER_EXIT_CODE=$?\necho \"rserver exited $APPTAINER_EXIT_CODE\" 1&gt;&amp;2\nexit $APPTAINER_EXIT_CODE\n</code></pre>"},{"location":"klone_RStudio-Server/#createcustomize-your-own-apptainer-rstudio-server-container","title":"Create/customize your own Apptainer Rstudio Server container","text":"<p>NOTE: These instructions are written to be performed on Klone (Hyak).</p> <ol> <li> <p>Create an Apptainer definition file:</p> <ul> <li> <p>Example filename: <code>rstudio-4.4.1.def</code></p> </li> <li> <p>Here's an example with a good set of basic installations for R 4.4.1:</p> </li> </ul> <pre><code>Bootstrap: docker\nFrom: rocker/rstudio:4.4.1\n%files\n    # Load file with R package installation commands in to container at /tmp\n    # Expects file called \"r_packages_installs.R\" to be in current directory.\n    r_packages_installs.R /tmp/\n\n%post\n    # Install additional system packages in container\n    # Most are needed for R/RStudio dependencies\n    apt -y update\n    apt -y install libxml2 libz-dev libbz2-dev liblzma-dev libxtst6 libxt6\n\n    # Run R package installation script file\n    Rscript /tmp/r_packages_installs.R\n</code></pre> </li> <li> <p>Create file <code>r_packages_installs.R</code> containing R package installation instructions.</p> <ul> <li> <p>NOTE: The container already has a base set of R packages (e.g. <code>ggplot2</code> installed).</p> </li> <li> <p>Here's an example with a set of commonly used packages:</p> </li> </ul> <pre><code># Update base packages\nupdate.packages(ask = FALSE)\n\n# Install BioConductor package manager\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\ninstall.packages(\"BiocManager\")\nBiocManager::install(version = \"3.19\")\n\n# Install tidyverse\ninstall.packages(\"tidyverse\")\n\n# Install matrixStats 0.61.0 (needed for DESeq2)\ninstall.packages(\"https://cran.rstudio.com/src/contrib/matrixStats_0.61.0.tar.gz\", repos=NULL, type=\"source\")\n\n# Install remotes package (allows for package installs from GitHub)\nBiocManager::install(\"remotes\")\n\n# Install GSEABase (a dependency for numerous gene ontology/enrichment analysis)\nBiocManager::install(\"Bioconductor/GSEABase\")\n\n# Install qvalue package\nBiocManager::install(\"qvalue\")\n\n# Install GO.db (annotation maps for Gene Ontology data)\nBiocManager::install(\"GO.db\")\n\n# Install MatrixGenerics (needed for DESeq2)\nBiocManager::install(\"MatrixGenerics\")\n\n# Install Methylkit\nBiocManager::install(\"methylKit\")\n\n# Install GOseq\nBiocManager::install(\"goseq\")\n\n# Install WGCNA\nBiocManager::install(\"WGCNA\")\n\n# Install DESeq2\nBiocManager::install(\"DESeq2\")\n</code></pre> </li> <li> <p>Initiate an interactive node.</p> </li> <li> <p>Build the container from the definition file:</p> <ul> <li>NOTE: Resulting container name will be <code>rstudio-4.4.1.sjw-v1.0.sif</code></li> </ul> <p><code>apptainer build --fakeroot rstudio-4.4.1.sjw-v1.0.sif rstudio-4.4.1.sjw-v1.0.def</code></p> </li> <li> <p>Exit the interactive node.</p> </li> <li> <p>Use the SLURM script above to start the container.</p> <ul> <li>NOTE: Be sure to update the script line to reflect your container name:</li> </ul> <pre><code># Set container name\ncontainer=\"rstudio-4.4.1.sif\"\n</code></pre> </li> </ol>"},{"location":"klone_RStudio-Server/#list-of-roberts-lab-apptainers","title":"List of Roberts Lab Apptainers","text":"<ul> <li><code>/gscratch/srlab/containers/srlab-R4.4-bioinformatics-container-f050784.sif</code></li> </ul> <p>https://github.com/RobertsLab/code/tree/master/apptainer_definition_files </p> <p><code>code/apptainer_definition_files</code></p>"},{"location":"klone_RStudio-Server/#apptainer-singularity-definition-files","title":"Apptainer (Singularity) Definition Files","text":"<p>This is a repository for all of the Roberts Lab definition files used for creating Apptainer images.</p> <ul> <li> <p><code>r_packages_installs.R</code>: R package installation instructions required for building the Roberts Lab bioinformatics container with <code>srlab-bioinformatics-container.def</code>.</p> </li> <li> <p><code>srlab-bioinformatics-build.sh</code>: A Bash script used to build the Apptainer container generated by <code>srlab-bioinformatics-container.def</code>. The script is specifically designed to be executed on the UW Hyak HPC, Klone. It will:</p> </li> <li> <p>Execute the most recent commit of <code>srlab-bioinformatics-container.def</code>.</p> </li> <li> <p>Copy <code>r_packages_installs.R</code> to <code>/tmp/</code> (needed for build process).</p> </li> <li> <p>Move completed Apptainer container to <code>/gscratch/srlab/containers/srlab-bioinformatics-container-&lt;commit&gt;.sif</code>.</p> </li> <li> <p><code>srlab-bioinformatics-container.def</code>: Apptainer definition file for the Roberts Lab bioinformatics container. Built on the <code>rocker/rstudio:4.4.1</code> image to allow usage of RStudio. `</p> </li> </ul>"},{"location":"klone_Running-a-Job/","title":"Running a job","text":"<p>NOTE - Use <code>/gscratch/scrubbed/&lt;UW_NetID&gt;</code> for running jobs (i.e. writing output files to). As the name suggests, you will need to move files to a \"bird\" for archival storage. If you are needing a set of large raw files for analysis - also place these in the <code>/gscratch/scrubbed/&lt;UW_NetID&gt;</code> directory.</p> <p><code>sbatch</code> is the main execution command for the job scheduler (SLURM). It spools up a compute node for long-term or compute-intensive tasks such as assemblies, blasts, alignments, etc.</p> <p><code>sbatch</code> can be run from a login node with the command:</p> <pre><code>sbatch &lt;slurm_script_name.sh&gt;\n</code></pre> <p><code>sbatch</code> requires a shell script to function, with two main parts: the header and the execute portion.</p>"},{"location":"klone_Running-a-Job/#the-header","title":"The Header","text":"<pre>\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=myjob\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=cpu-g2-mem2x\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=dd-hh:mm:ss\n## Memory per node\n#SBATCH --mem=450G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=$USER@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/srubbed//to/your/desired/directory\n\n\n\n<p>Bolded sections above must be changed prior to execution. Those specific sections are described in more detail.</p>\n<ul>\n<li>\n<p><code>--job-name=</code><code>myjob</code> is an identifier for your current job. It's what shows up in <code>scontrol</code> and <code>squeue</code> calls. Providing a unique-to-you job name may be helpful for distinguishing between different runs, by is not necessary.</p>\n</li>\n<li>\n<p><code>--time=</code><code>dd-hh:mm:ss</code> is the \"wall\" time, or how long we are reserving the node for our use. This argument requires some consideration and knowledge about the program you're running prior to execution. Selecting too little wall time will cause the scheduler to kill your process mid-run when time runs out. Selecting too much time limits other's ability to use Hyak functions, but the scheduler releases a node upon program completion usually, so this is a secondary consideration.</p>\n</li>\n<li>\n<p><code>--mem=</code><code>450G</code> specifies how much memory (RAM) to allocate to the process. We have a single slice with a maximum of 490GB of RAM. Specifying a value below the maximum allows for some additional processing overhead. Usually, setting this to the maximum is fine, but reserving only what you might need can allow for multiple users to use the slice at the same time.</p>\n</li>\n<li>\n<p><code>--chdir=</code><code>/gscratch/srubbed/&lt;UW_NetID&gt;/to/your/desired/directory</code> indicates the working directory where output will be written. All jobs should be executed in your <code>/gscratch/srubbed/&lt;UW_NetID&gt;</code> directory. See the Data Storage &amp; System Organization section of the wiki for more info.</p>\n</li>\n</ul>"},{"location":"klone_Running-a-Job/#the-execute-portion","title":"The Execute portion","text":"<p>This section contains the commands/programs you want executed. You can treat it like the command line, in that it executes commands sequentially as input. These can include program calls, module loading, making directories, etc. However, since Klone relies on the use of containers to run, your SLURM script will require the following:</p>\n<pre><code>  # Load modules\n  module load apptainer\n\n  # Execute Roberts Lab bioinformatics container\n  # Binds home directory\n  # Binds /gscratch directory\n  # Directory bindings allow outputs to be written to the hard drive.\n  apptainer exec \\\n  --home $PWD \\\n  --bind /mmfs1/home/ \\\n  --bind /mmfs1/gscratch/ \\\n  --bind /gscratch/ \\\n  /gscratch/srlab/containers/srlab-bioinformatics-container-&lt;git_commit_hash&gt;.sif \\\n  &lt;commands_script.sh&gt;\n</code></pre>"},{"location":"klone_Running-a-Job/#slurm-script-templateexample-multiple-commands","title":"SLURM Script Template/Example - Multiple Commands","text":"<p>If you need to execute multiple commands using a container, which will usually be the case and is shown in the example directly above this, you'll need to place those commands in a separate script.</p>"},{"location":"klone_Running-a-Job/#command-script-example","title":"Command script example","text":"<p>Here's an example script, called <code>commands.sh</code>. This is where we'll set all of our variables and execute various commands/programs we'd like for our analysis:</p>\n<pre><code>  #!/bin/bash\n\n  # Requires Bash &gt;=4.0, as script uses associative arrays.\n\n  ###################################################################################\n  # These variables need to be set by user\n\n  ## Number of CPU threads to use for programs (if applicable)\n  threads=28\n\n  ## Programs associative array\n  ## Using array is useful for logging program options (see end of script)\n  declare -A programs_array\n\n  programs_array=(\n  [bowtie2]=\"bowtie2\" \\\n  [bowtie2_build]=\"bowtie2-build\" \\\n  [samtools_index]=\"samtools index\" \\\n  [samtools_sort]=\"samtools sort\" \\\n  [samtools_view]=\"samtools view\" \\\n  [samtools_faidx]=\"samtools faidx\"\n  )\n\n\n  ## INPUT FILES ##\n  genome_fasta=\"./data/C_gigas/genomes/cgig-NCBI-genome.fasta\"\n  genome_name=\"cgig-NCBI-genome\"\n\n  ###################################################################################\n\n\n  # Create FastA index\n  ${programs_array[trinsamtools_faidxity]} \"${genome_fasta}\"\n\n\n  ###################################################################################\n\n  # Capture program options\n  if [[ \"${#programs_array[@]}\" -gt 0 ]]; then\n    echo \"Logging program options...\"\n    for program in \"${!programs_array[@]}\"\n    do\n      {\n      echo \"Program options for ${program}: \"\n      echo \"\"\n      # Handle samtools help menus\n      if [[ \"${program}\" == \"samtools_index\" ]] \\\n      || [[ \"${program}\" == \"samtools_sort\" ]] \\\n      || [[ \"${program}\" == \"samtools_view\" ]]\n      then\n        ${programs_array[$program]}\n\n      # Handle DIAMOND BLAST menu\n      elif [[ \"${program}\" == \"diamond\" ]]; then\n        ${programs_array[$program]} help\n\n      # Handle NCBI BLASTx menu\n      elif [[ \"${program}\" == \"blastx\" ]]; then\n        ${programs_array[$program]} -help\n\n      # Handle StringTie prepDE script\n      elif [[ \"${program}\" == \"prepDE\" ]]; then\n        python3 ${programs_array[$program]} -h\n      fi\n      ${programs_array[$program]} -h\n      echo \"\"\n      echo \"\"\n      echo \"----------------------------------------------\"\n      echo \"\"\n      echo \"\"\n    } &amp;&gt;&gt; program_options.log || true\n\n      # If MultiQC is in programs_array, copy the config file to this directory.\n      if [[ \"${program}\" == \"multiqc\" ]]; then\n        cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n      fi\n    done\n    echo \"Finished logging programs options.\"\n    echo \"\"\n  fi\n\n\n  # Document programs in PATH (primarily for program version ID)\n  echo \"Logging system $PATH...\"\n  {\n  date\n  echo \"\"\n  echo \"System PATH for $SLURM_JOB_ID\"\n  echo \"\"\n  printf \"%0.s-\" {1..10}\n  echo \"${PATH}\" | tr : \\\\n\n  } &gt;&gt; system_path.log\n  echo \"Finished logging system $PATH.\"\n</code></pre>\n<p>To run the <code>commands.sh</code> script above in our container on Klone, we would use the following SLURM script, which we'll call <code>example-SLURM-script.sh</code>.</p>\n<p>IMPORTANT: <code>&lt;commands.sh&gt;</code> needs to be executable!! Make sure to run <code>chmod +x &lt;commands.sh&gt;</code> to make it executable.</p>\n<p>This example will perform the following:</p>\n<ul>\n<li>Request the slice assigned to our account (<code>--account=srlab</code>)</li>\n<li>Request the parition on the <code>srlab</code> slice (<code>--partition=cpu-g2-mem2x</code>)</li>\n<li>Set a run time of 10 days (<code>--time=10-00:00:00</code>)</li>\n<li>Request 120GB of memory (<code>--mem=120G</code>)</li>\n<li>Identify the most recent version of the bioinformatics container to use.</li>\n<li>Run the <code>commands.sh</code> script from the bioinformatics container to construct a bowtie2 index of the provided genome FastA.</li>\n</ul>\n<p>NOTE: This is written to assume that the <code>commands.sh</code> script and the SLURM script are in the same directory.</p>\n<pre><code>#!/bin/bash\n## Job Name\n#SBATCH --job-name=DESCRIPTIVE_JOB_NAME\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=cpu-g2-mem2x\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=$USER@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/$USER/to/your/desired/directory\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Get most recent container git hash\ngit_commit_hash=$(find /gscratch/srlab/containers/ \\\n-name \"srlab-bioinformatics-container*\" \\\n-printf \"%T+ %p\\n\" \\\n| sort -n \\\n| awk -F[-.] 'NR == 1 {print $7}')\n\n# Load modules\nmodule load apptainer\n\n# Execute Roberts Lab bioinformatics container\n# Binds home directory\n# Binds /gscratch directory\n# Directory bindings allow outputs to be written to the hard drive.\napptainer exec \\\n--home \"$PWD\" \\\n--bind /mmfs1/home/ \\\n--bind /mmfs1/gscratch/ \\\n/gscratch/srlab/containers/srlab-bioinformatics-container-\"${git_commit_hash}$\".sif \\\ncommands.sh\n</code></pre>\n<p>Finally, to submit the job to SLURM:</p>\n<pre><code>sbatch example-SLURM-script.sh\n</code></pre>\n<p>This will execute <code>example-SLURM-script.sh</code> which contains instructions for submitting it into the SLURM job scheduler and onto our slice (the header portion). The rest of the script will then be executed, which will result in the execution of <code>commands.sh</code>.</p>"},{"location":"klone_Running-a-Job/#slurm-script-templateexample-single-command","title":"SLURM Script Template/Example - Single Command","text":"<p>Less likely to be used, as many of our analyses require multiple steps, but is still useful to know.</p>\n<pre><code>#!/bin/bash\n## Job Name\n#SBATCH --job-name=DESCRIPTIVE_JOB_NAME\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=cpu-g2-mem2x\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=$USER@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/$USER/to/your/desired/directory\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Get most recent container git hash\ngit_commit_hash=$(find /gscratch/srlab/containers/ \\\n-name \"srlab-bioinformatics-container*\" \\\n-printf \"%T+ %p\\n\" \\\n| sort -n \\\n| awk -F[-.] 'NR == 1 {print $7}')\n\n# Load modules\nmodule load apptainer\n\n# Execute Roberts Lab bioinformatics container\n# Binds home directory\n# Binds /gscratch directory\n# Directory bindings allow outputs to be written to the hard drive.\napptainer exec \\\n--home \"$PWD\" \\\n--bind /mmfs1/home/ \\\n--bind /mmfs1/gscratch/ \\\n/gscratch/srlab/containers/srlab-bioinformatics-container-\"${git_commit_hash}$\".sif \\\nbowtie2_build \\\n--threads 28 \\\n/gscratch/scrubbed/\"${USER}\"/data/C_gigas/genomes/cgig-ncbi-genome.fasta \\\ncgig-ncbi-genome\n</code></pre>"},{"location":"klone_VS-Code/","title":"VS Code on Klone via ProxyJump","text":""},{"location":"klone_VS-Code/#overview","title":"Overview","text":"<ol> <li>Provides a method to connect VS Code to a compute node on Klone, preserving the login nodes for the community. As a reminder, users running processes on the login node is prohibited.</li> <li>Runs VS Code on your local computer, but runs background processes on Klone. A local copy of VS Code is required.</li> <li>Requires: configuration files to be set up on your local computer, key-pair configuration, launching an interactive job, use of the Remote-SSH extension to connect to a compute node on klone.</li> </ol>"},{"location":"klone_VS-Code/#initial-set-up","title":"Initial set up","text":"<ul> <li>Follow UW-IT guide here: https://hyak.uw.edu/docs/tools/vsc-proxy-jump/</li> <li>An alternative way to using VS code on Klone is through Hyak OnDemand: https://hyak.uw.edu/docs/ood/vscode.<ul> <li>Pros: easier to get started</li> <li>Cons: extensions like GitHub Co-pilot are not freely available or accessible </li> </ul> </li> </ul>"},{"location":"klone_VS-Code/#running-vs-code-after-set-up","title":"Running VS code after set up","text":"<ol> <li>Login to Klone through terminal</li> <li>Start screen session<ul> <li><code>screen -S vscode</code> </li> </ul> </li> <li>Request compute node: <ul> <li>partitions you can use include those you have access to when you run the command <code>hyakalloc</code> on Klone.</li> <li>Examples<ul> <li>Using <code>srlab</code> partition:<ul> <li><code>salloc --partition=cpu-g2-mem2x --cpus-per-task=1 --mem=16G --job-name=vsc-proxy-jump    --time=24:00:00</code></li> </ul> </li> <li>Using <code>coenv</code> partition:<ul> <li><code>salloc \u2014-account coenv \u2014-partition cpu-g2 -\u2014cpus-per-task 1 --mem=50GB --time=24:00:00 --job-name=vsc-proxy-jump</code></li> </ul> </li> <li>Using <code>ckpt</code> partition:<ul> <li><code>salloc --partition=ckpt --cpus-per-task=1 --mem=100G --job-name=vsc-proxy-jump</code></li> </ul> </li> </ul> </li> </ul> </li> <li>Detach from screen:<ul> <li><code>ctrl + A + D</code></li> <li>Before you do this, you may need to note or copy the node name (e.g. <code>n3441</code>) for the next step. If you'll use set-hyak-node.sh in the next step, you do not need to note it.</li> </ul> </li> <li>Set the node in your local <code>.ssh/klone-node-config</code> file<ul> <li>This is described in the UW-IT documentation: https://hyak.uw.edu/docs/tools/vsc-proxy-jump/</li> <li>You can do this through your command line text editor (e.g. nano, vim). You\u2019ll paste the node name after the <code>Hostname</code> field</li> <li>Alternatively you can use the Run <code>set-hyak-node.sh</code> script<ul> <li><code>bash set-hyak-node.sh</code></li> </ul> </li> </ul> </li> <li>Open VS Code and run Remove-SSH Connect to Server<ul> <li>type <code>fn + F1</code> then in the top bar type <code>Remote-SSH: Connect to Host</code> and select <code>klone-node</code>.<ul> <li>If you don't see the function pop up in the bar, you may need to install the extention Remote-SSH.</li> <li>If prompted about fingerprinting select continue.</li> <li>If you are still having difficulty connecting, one hack is to log in to Klone through the terminal and delete the <code>.vscode-server</code> directory (<code>rm -r .vscode-server</code>). It is possible that it did not fully download when you initially tried to connect and this causes failure to connect. </li> </ul> </li> </ul> </li> </ol> <p>You should now be connected and the bottom left corner of the VS Code window should show <code>SSH: klone-node</code>. You should be able to navigate to the gscratch/scrubbed space and into your directory through the explorer. You can open a GitHub co-pilot chat and use the agent to help with some analysis. </p>"},{"location":"klone_VS-Code/#still-struggling","title":"Still struggling?","text":"<p>This is complicated and you don\u2019t have to struggle alone.      - Create a GitHub issue     - Contact UW-IT (help@uw.edu)     - Go to UW-IT office hours</p>"},{"location":"klone_containers/","title":"What is a container?","text":"<p>A container is a self-contained, virtual computer. It exists as a file on your computer, but when run, can be interacted with as though the user is using a different computer.</p>"},{"location":"klone_containers/#why-use-containers","title":"Why use containers?","text":"<p>For our use case(s), reproducibility is the biggest advantage. Since containers function as virtual computers, if everyone uses the same container, then we know the exact conditions and programs that were used to run analyses. There are no concerns about different people using different versions of software and/or operating systems. Another benefit to using containers, is that containers are portable. Because a container is just a file, it can easily be shared with someone else and that person will be able to run analyses exactly as you've run them, without the need to install the programs needed for the analyses.</p> <p>Additionally, using containers allows us to install software without modifying the underlying operating system. Some software installations are more complex than others and containers reduce the risk that we accidentally modify the underlying operating system in a way which screws things up.</p>"},{"location":"klone_containers/#creating-containers","title":"Creating containers","text":"<p>Containers are created from a definition file. A definition file provides all the instructions on what the resulting container should contain - things like which operating system, which programs, which files, directory stucture, etc). Once a definition file is set up, then the user can instruct the container program (Apptainer in our case) to build the container from the definition file. The resulting container functions as an independent computing system, but is actually just a file. This means a user can easily move this file (container) to other computers and run the container exactly the same way on any system.</p> <p>The Roberts Lab currently uses a single definition file: <code>srlab-bioinformatics-container.def</code>. Our goal is to keep things as simple as possible. Everyone will use the same container and same versions of programs. The downside to this is that the resulting container file is large (&gt; 2GB) and is time consuming to build, however, portability is not our primary concern, nor do we ancticipate having to update/rebuild the container regularly. Other labs may have completely separate containers for:</p> <ul> <li> <p>individual software/program</p> </li> <li> <p>dedicated pipeline (e.g. HISAT2, StringTie, DESeq2)</p> </li> </ul> <p>For lab-specific guides on building/using containers in the Roberts Lab, specifically written for use on our HPC system, Klone:</p> <ul> <li> <p>Klone Quick Start Guide</p> </li> <li> <p>Klone Installing Programs</p> </li> <li> <p>Klone Running a Job</p> </li> <li> <p>Klone RStudio Server</p> </li> </ul>"},{"location":"klone_quick-start/","title":"Quick start guide to running a job on Klone","text":"<p>See the \"Running a job\" instructions for a more detailed description of how set up and run a job on Klone.</p> <ol> <li> <p>SSH into Klone:</p> </li> <li> <p><code>ssh &lt;UW_NetID&gt;@klone.hyak.uw.edu</code></p> <ul> <li>You'll need to replace <code>&lt;UW_NetID&gt;</code> (including the <code>&lt;</code> and <code>&gt;</code>) with your UW NetID.</li> </ul> </li> <li> <p>Create a SLURM script (e.g. <code>20240917-cgig-ncbi-blastx.sh</code>) with the following commands (these come after the SLURM header):</p> <pre><code>module load apptainer\n\n\napptainer exec \\\n--home $PWD \\\n--bind /mmfs1/home/ \\\n--bind /mmfs1/gscratch/ \\\n--bind /gscratch/ \\\n/gscratch/srlab/containers/srlab-bioinformatics-container-&lt;git_commit_hash&gt;.sif \\\n&lt;commands-script.sh&gt;\n</code></pre> <ul> <li>You'll need to replace anything in <code>&lt;&gt;</code> (including the <code>&lt;</code> and <code>&gt;</code>) with your specific requirements.</li> <li><code>&lt;commands-script.sh&gt;</code> is a Bash script containing all of the commands/programs you wan to run.</li> </ul> </li> </ol> <p>IMPORTANT: <code>&lt;commands-script.sh&gt;</code> needs to be executable!! Make sure to run <code>chmod +x &lt;commands-script.sh&gt;</code> to make it executable.</p> <ol> <li> <p>Submit job to SLURM scheduler (i.e. start your job):</p> <ul> <li> <p><code>sbatch &lt;slurm_script_name.sh&gt;</code></p> <ul> <li>You'll need to replace anything in <code>&lt;&gt;</code> (including the <code>&lt;</code> and <code>&gt;</code>) with your specific requirements.</li> </ul> </li> </ul> </li> </ol> <p>For more information, check out the following:</p> <ul> <li> <p>Roberts Lab Klone guides:</p> <ul> <li>Using containers</li> <li>Storage on Klone</li> <li>Running a job on Klone</li> </ul> </li> <li> <p>UW Hyak Documentation</p> </li> </ul>"},{"location":"music/","title":"Spotify Playlists","text":""},{"location":"raven_Conda/","title":"Usage of Conda on Raven","text":""},{"location":"raven_Conda/#best-practices","title":"Best Practices","text":"<ul> <li>Use Environments: Always create a new Conda environment for each project or analysis to avoid dependency conflicts.</li> <li>Environment Naming: Use descriptive names for environments, such as <code>project_name_env</code>.</li> </ul>"},{"location":"raven_Conda/#activating-conda","title":"Activating Conda","text":"<p>To activate the base (default) environment, run:</p> <pre><code>eval \"$(/opt/anaconda/anaconda3/bin/conda shell.bash hook)\"\n</code></pre> <p>This should change your shell prompt to look like this (it'll have your username instead of <code>sam</code>):</p> <p><code>(base) sam@raven:</code></p>"},{"location":"raven_Conda/#creating-a-new-environment","title":"Creating a New Environment","text":"<p>To create a new Conda environment, use the following command:</p> <pre><code>conda create -n myenv_name conda_package_name1 conda_package_name2\n</code></pre>"},{"location":"raven_RStudio-Server/","title":"Using RStudio Server on Raven","text":"<p>IMPORTANT: If you're off-campus, you'll need to activate the Husky OnNet VPN (UW guide) to access RStudio Server!</p>"},{"location":"raven_RStudio-Server/#accessing-rstudio-server","title":"Accessing RStudio Server","text":"<p>Point your web browser to the following URL to access RStudio Server on Raven:</p> <p>http://raven.fish.washington.edu:8787</p> <p>NOTE: You may be prompted with a security warning, since the site uses <code>http</code> instead of <code>https</code>. You can safely ignore this warning and proceed to the site.</p>"},{"location":"raven_RStudio-Server/#logging-in","title":"Logging In","text":"<p>Log in with your Raven account credentials.</p>"},{"location":"protocols/ATPase/","title":"ATPase","text":""},{"location":"protocols/ATPase/#sei-buffer-recipe","title":"SEI Buffer Recipe","text":"Reagent Amount (g) Sucrose 42.79 Na2EDTA 1.86 Imidazole 1.7 <ol> <li>Dissolve ingredients into 475ml diH20</li> <li>Adjust pH to 7.3 and fill to 500ml</li> <li>Good for 1 month at 4C</li> </ol>"},{"location":"protocols/ATPase/#atpase-sample-collection-method","title":"ATPase Sample Collection Method","text":"<ol> <li>Place metal block and SEI buffer on ice. If no block, use a bucket of ice.</li> <li>Fill 0.5ml tube(s) about halfway full of SEI buffer.</li> <li>Place tissue into SEI buffer, about a 1:20 ratio of tissue to buffer is ideal. The tissue tends to get sticky if there is too much in the tube. Very little tissue is needed for this assay. 2-10 mg wet weight gill tissue from oyster worked fine. In salmon samples, a single gill filament was sufficient.</li> <li>Top off tubes with SEI buffer (not necessary for ~20 mg tissue samples). Make sure that the tissue is completely submerged.</li> <li>Keep as cold as possible until samples can be stored at -80C to minimize enzyme degredation.</li> </ol>"},{"location":"protocols/ATPase/#atpase-enzyme-activity-protocol","title":"ATPase Enzyme Activity Protocol","text":"<p>coming soon </p> <p>Questions? Contact Matt George at mngeorge@uw.edu.</p>"},{"location":"protocols/protocol-bullet_blender/","title":"Bullet Blender 5E Gold+","text":""},{"location":"protocols/protocol-bullet_blender/#standard-operating-protocol-sop","title":"Standard Operating Protocol (SOP)","text":"<p>Written 20250506 by Sam White.</p>"},{"location":"protocols/protocol-bullet_blender/#overview","title":"Overview","text":"<p>From the manufacturer: \"The Bullet Blender is a high-speed homogenizer that uses beads to disrupt cells and tissues. The Bullet Blender is not a centrifuge, but it does use centrifugal force to agitate the samples. The Bullet Blender is designed for use with 1.5mL, 2.0mL, and 5mL tubes. The Bullet Blender is not designed for use with glass or metal tubes.\"</p> <p>This SOP provides a general overview of the Bullet Blender, including safety information, personal protective equipment (PPE), and specific hazards. Please refer to the assay-specific protocols for detailed instructions on how to use the Bullet Blender for specific applications.</p>"},{"location":"protocols/protocol-bullet_blender/#reagents","title":"Reagents:","text":"<ul> <li>Beads (various sizes and materials)</li> <li>Dry ice or liquid nitrogen (for cooling)</li> <li>Buffer (as per your protocol)</li> </ul>"},{"location":"protocols/protocol-bullet_blender/#specific-hazards","title":"Specific Hazards:","text":"<ul> <li>Dry ice and liquid nitrogen are cryogenic materials and can cause frostbite. Use caution when handling.</li> <li>Beads can be hazardous if inhaled or ingested. Use appropriate PPE and work in a fume hood if necessary.</li> <li>The Bullet Blender is a high-speed device and can cause injury if not used properly. Follow all safety instructions provided by the manufacturer.</li> <li>The Bullet Blender is loud and can cause hearing damage if used without ear protection for extended periods. Use ear protection if necessary.</li> </ul>"},{"location":"protocols/protocol-bullet_blender/#personal-protective-equipment-ppe","title":"Personal Protective Equipment (PPE):","text":"<p>REQUIRED:  - Gloves</p> <p>OPTIONAL: - Lab coat - Ear protection (if necessary)</p>"},{"location":"protocols/protocol-bullet_blender/#general-guidelines","title":"General guidelines:","text":""},{"location":"protocols/protocol-bullet_blender/#manufacturers-protocols","title":"MANUFACTURER'S PROTOCOLS","text":"<p>Review the manufacturer's various information before using</p> <ul> <li> <p>Recommended protocols for various tissue types (NextAdvance website). Unsurprisingly, there aren't any protocols for oyster tissues, however we can probably follow any protocol for any soft tissues listed.</p> </li> <li> <p>Bullet Blender usage guide (PDF). This is a nice general overview of the basics of using a Bullet Blender, including buffer/bead/sample ratios, types of beads and how they differ, different types of tissues, tissue preparation, etc.</p> </li> <li> <p>Bullet Blender 5E Gold+ manual (PDF). The manual for the machine. Contains machine-specific instructions on how to use the machine, including tube requirements.</p> </li> </ul>"},{"location":"protocols/protocol-bullet_blender/#tubes","title":"TUBES","text":"<p>The machine is designed to use 5.0mL tubes.</p> <p>Use of 1.5mL or 2.0 mL tubes requires adapters. Adapters are stored next to the machine.</p> <p>All tubes must be of the SafeLock variety (Eppendorf) or GATOR tubes from NextAdvance (the machine's manufacturer).</p>"},{"location":"protocols/protocol-bullet_blender/#machine-usage","title":"MACHINE USAGE","text":"<ul> <li> <p>Should be pre-cooled (and cooled during a run) using dry ice or liquid nitrogen. The machine holds ~2.5lbs of dry ice. This will last for an entire day. I have not tried cooling with liquid nitrogen yet.</p> </li> <li> <p>A variety of beads are available (sizes and materials). These are stored next to the machine. Review the recommended protocols from NextAdvance (linked above) to determine appropriate bead sizes/combinations for the type of tissues you're working with.</p> </li> <li> <p>IT IS LOUD! Usage does not require ear protection, but if we are going to be using regularly while others are also in FTR 213, we might want to consider relocating it to FTR 228 where it's less likely to disturb people.</p> </li> <li> <p>Although it's not a centrifuge, it is still recommend to \"balance\" it by having tubes equally spaced across from each other. Additionally, any \"blanks\" should still be loaded with an equal volume which matches your samples.</p> </li> </ul>"},{"location":"protocols/protocol-qPCR/","title":"qPCR","text":""},{"location":"protocols/protocol-qPCR/#qpcr","title":"qPCR","text":"<p>One of the most used application is for gene quantification. Generally we will use SsoFast Evagreen Supermix (BioRad) (protocol). This requires that we start with cDNA.</p> <p>### Standard Operating Protocol (SOP)  Written 20150702 by Sam White.</p> <p>Reagents:  - SsoFast EvaGreen Supermix (BioRad: 172-5203)  - Primer working stocks (10uM)  - DNase-free H2O (NanoPure H2O)</p> <p>Personal Protective Equipment (PPE):  - Gloves</p> <p>Equipment:  - Pipettes (10 - 1000uL)  - Filtered pipette tips  - White PCR plates, non-skirted, low profile (USA Scientific: 1402-9590)  - Optically clear strip caps (USA Scientific: 1400-3800)  - Sterile 1.7mL snap-cap microfuge tubes (Genesee: 22-281S)  - Real-time PCR machine  - ice</p> <p>Procedure  Total Time: ~ 2.0 - 4.0hrs  Cost/sample: ~ $0.42</p> <ol> <li>Read the manufacturer's protocol.</li> <li>Read this protocol.</li> <li>Verify sufficient quantities of reagents and samples before beginning.</li> <li>Wear clean gloves.</li> <li> <p>Prepare master mix. Be sure to make a master mix volume that will accommodate the following: all of your samples, two water (i.e. no template controls; NTC) samples, plus an extra 10% to accommodate pipetting errors. A single reaction is shown below:</p> Component Volume(uL) Final Concentration 2x SsoFast EvaGreen Supermix 10 1x Forward Primer (10uM) 0.5uL 0.2uM Reverse Primer (10uM) 0.5uL 0.2uM Water Variable Use to bring reaction volume up to 20uL (including template) </li> <li> <p>Distribute appropriate amount of master mix (volume of master mix + template = 20uL) to white PCR plate.</p> </li> <li>Add template.</li> <li>Cap with optical PCR caps.</li> <li>Spin plate for 1min @ 3000g.</li> <li>Put plate in real-time PCR machine.</li> <li> <p>Recommended cycling parameters (40 cycles) are listed below. They may need to be changed to accommodate your specific primers/samples. See manufacturer's protocol for recommendations.</p> <p>Step 1 - 98C 2mins</p> <p>Step 2 - 98C 5secs</p> <p>Step 3 - 60C 5secs</p> <p>Step 4 - Plate read</p> <p>Step 5 - Got to Step 2 39 more times</p> <p>Step 6 - Melt curve 65C - 95C, increment 0.5C, wait 2secs, plate read.</p> </li> </ol> <p>### qPCR Data Analysis</p> <p>Step 1: Check for quality control of the qPCR data</p> <p>Before starting the analysis, it is important to check the quality control of the qPCR data to ensure that the data is reliable. Quality control can be done using the following methods:</p> <ul> <li>Check for amplification curves: Ensure that amplification curves are present for all the samples. Absence of amplification curves might indicate poor quality RNA or experimental errors.     </li> <li>Check for amplification efficiency: Calculate the amplification efficiency for the target and reference genes. The efficiency should be between 90-110%.    </li> <li>Check for melting curves: Ensure that melting curves show a single peak for all the samples. Presence of multiple peaks might indicate non-specific amplification or primer-dimer formation.    </li> <li>Check for threshold cycle (Ct) values: Ensure that Ct values are consistent across all the samples.  </li> </ul> <p>Step 2: Calculate the relative expression of the target gene    </p> <p>To calculate the relative expression of the target gene, use the following formula:</p> <p>\u0394Ct = Ct_target \u2013 Ct_reference</p> <p>Where Ct_target is the cycle threshold of the target gene and Ct_reference is the cycle threshold of the reference gene (in this case, actin).</p> <p>Step 3: Calculate the fold change of the target gene</p> <p>To calculate the fold change of the target gene, use the following formula:   </p> <p>Fold change = 2^(-\u0394Ct)</p> <p>Step 4: Statistical analysis</p> <p>After calculating the fold change, perform statistical analysis to determine the significance of the results. This can be done using t-tests or ANOVA. A p-value of less than 0.05 is considered significant.</p> <p>Step 5: Interpretation of results</p> <p>After obtaining the statistical results, interpret the results by comparing the fold change of the target gene in the experimental group to the control group. A fold change greater than 1 indicates upregulation, while a fold change less than 1 indicates downregulation.</p> <p>### CFX Maestro Software</p> <p>#### Plate Spreadsheet Import</p> <ol> <li> <p>Modify cfx_plate_template.csv (CSV) to your desired <code>Target Name</code> and <code>Sample Name</code> and save as a CSV file.</p> </li> <li> <p>In CFX Maestro, create a new plate: <code>File &gt; New &gt; Plate...</code>.</p> </li> <li> <p>Highlight all wells.</p> </li> <li> <p>Select <code>Sample Type</code> of <code>Unknown</code>.</p> </li> <li> <p>In the <code>Target Names</code> section, click on the empty box next to <code>SYBR</code>.</p> </li> <li> <p>Click on the <code>Spreadsheet View/Importer</code> tab along the top.</p> </li> <li> <p>Click <code>Import</code>.</p> </li> <li> <p>Find the file you saved in Step 1 and click <code>Open</code>.</p> </li> <li> <p>Click <code>Okay</code>.</p> </li> <li> <p>Update plate layout with any different <code>Sample Type</code> (e.g. NTC, Positive Control, etc.), <code>Technical Replicates</code> and/or <code>Trace Styles</code>.</p> </li> <li> <p>Save the file.</p> </li> </ol>"},{"location":"protocols/protocol-reverse_transcription/","title":"Reverse Transcription","text":""},{"location":"protocols/protocol-reverse_transcription/#reverse-transcription","title":"Reverse Transcription","text":"<p>#### Standard Operating Protocol (SOP)  Written 20150702 by Sam White.</p> <p>##### Reagents:  - M-MLV Reverse Transcriptase (Promega: M1701)  - Primers (oligo dT: Promega: C1101 OR random: Promega: C1181)  - 10mM dNTPs (Promega: U1511)</p> <p>##### Personal Protective Equipment (PPE):  - Gloves</p> <p>##### Equipment:  - Pipettes (10 - 1000uL)  - Filtered pipette tips  - 0.5mL snap-cap microfuge tubes (Genesee: 22-281A)  - Sterile 1.7mL snap-cap microfuge tubes (Genesee: 22-281S)  - Thermal cycler, water bath, or heating block capable of 37C OR 42C.  - vortexer  - ice</p> <p>#### Procedure  ##### Total Time: ~ 1.5 - 2.0hrs  ##### Cost/sample: ~ $1.50  IMPORTANT: A single reaction volume = 25uL. The volume of RNA, primer(s) and M-MLV RT used in this protocol are variable and will be specific to your current experiment. The directions below apply to a reaction using 1ug of total RNA. You may need to make changes to accommodate your own conditions.</p> <ol> <li>Read the manufacturer's protocol (PDF).</li> <li>Read this protocol.</li> <li>Verify sufficient quantities of reagents and samples before beginning.</li> <li>Wear clean gloves.</li> <li>Thaw all RNA and reagents on ice. Prepare all reactions on ice.</li> <li>Transfer 1ug of RNA to 0.5mL snap cap tubes or PCR plate. Adjust volumes of individual samples to 17.75uL with H2O.</li> <li>Add 0.25ug primer per 1ug of RNA in sample (= 0.5uL of Promega oligo dT Cat#C1101 in this example). Total volume (RNA + primers) should equal 18.25uL.</li> <li>Heat samples at 70C for 5 min in thermal cycler, heating block, or water bath.</li> <li>Place samples on ice IMMEDIATELY.</li> <li> <p>Make Master Mix:</p> <p>Per Reaction</p> <ul> <li> <p>5 uL 5x Buffer (M-MLV RT Buffer)</p> </li> <li> <p>VORTEX THOROUGHLY TO DISSOLVE PRECIPTATE</p> </li> <li> <p>1.25 uL 10mM dNTPs</p> </li> <li> <p>0.5 uL M-MLV RT per ug of RNA</p> </li> </ul> </li> <li> <p>Mix well by flicking; do not vortex.</p> </li> <li>Add 6.75uL of master mix to each reaction.</li> <li>Mix by pipetting; do not vortex.</li> <li>Incubate @ 42C for 1hr for oligo dT primers OR @ 37C for random primers.</li> <li>Heat inactivate @ 95C for 3 min.</li> <li>Spot spin and store @-20C.</li> </ol>"},{"location":"protocols/resazurin-assay/","title":"Resazurin Assay","text":""},{"location":"protocols/resazurin-assay/#resazurin-metabolic-assay","title":"Resazurin metabolic assay","text":"<p>Resazurin metabolic assays are used to measure the metabolic rate of marine organisms. This protocol has been developed for use in oysters, but can be adapted for other organisms.  This protocol is based off of the Renquist et al. (2013) protocol.  </p> <p>Contact: ashuff (at) uw (dot) edu</p>"},{"location":"protocols/resazurin-assay/#standard-operating-protocol-sop","title":"Standard Operating Protocol (SOP)","text":"<p>Written 20250401 by Ariana Huffmyer.  </p>"},{"location":"protocols/resazurin-assay/#overview","title":"Overview","text":"<p>This protocol is written for small oyster spat, but can be adapted for other life stages. This protocol is based on previous work in the lab by Colby E. and as used in our analysis of oyster seed metabolic response and survival.   </p>"},{"location":"protocols/resazurin-assay/#reagents","title":"Reagents","text":"<ul> <li>Resazurin salt (e.g., ThermoFisher Scientific)<ul> <li>Specific hazards<ul> <li>skin irritant</li> <li>eye irritant</li> </ul> </li> </ul> </li> <li>Dimethyl sulfoxide (DMSO) (e.g., ThermoFisher Scientific)<ul> <li>Specific hazards<ul> <li>flammable</li> <li>skin irritant</li> </ul> </li> </ul> </li> <li>Antibiotic/antifungal solution (e.g., HyClone antibiotic antimycotic (PEN/STREP/FUNGIZONE) solution)<ul> <li>Specific hazards<ul> <li>skin irritant</li> </ul> </li> </ul> </li> <li>Seawater (DI water with Instant Ocean adjusted to 23-25 ppt or filtered (&lt;1um) seawater)</li> </ul>"},{"location":"protocols/resazurin-assay/#personal-protective-equipment-ppe","title":"Personal Protective Equipment (PPE)","text":"<p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> <p>WHEN SPLASH POTENTIAL EXIST:</p> <ul> <li>Safety goggles</li> <li>Lab coat</li> </ul>"},{"location":"protocols/resazurin-assay/#waste-disposal","title":"Waste Disposal","text":"<ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for resazurin waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual resazurin/solution may be disposed of in regular trash.</li> </ul> </li> </ul>"},{"location":"protocols/resazurin-assay/#preparing-solutions","title":"Preparing solutions","text":"<ol> <li>Stock resazurin solution </li> </ol> <p>To make the resazurin stock solution (10 mL) mix the following. We will use this solution for multiple trials.  </p> <ul> <li>0.5 g resazurin salt</li> <li>10 mL DI water</li> <li>10 \u00b5L DMSO</li> </ul> <p>Store in a dark fridge or freezer.  </p> <ol> <li>Working resazurin solution</li> </ol> <p>First, determine the volume of resazurin required depending on the size of your organism and the container size. Here are some examples that we have used before. We recommend performing preliminary trials to ensure that a change in resazurin fluorescence can be detected over the time scale desired. This protocol was developed to detect a change in resazurin fluorescence within 5 hours in small seed (&lt;7mm) and larger seed (10-30mm).  </p> <ul> <li>Small seed (&lt;7mm length): trials conducted in 96 well plates (300uL volume in each well)</li> <li>Medium seed (15-40 mm length): trials conducted in small plastic cups (20 mL volume)</li> <li>Large seed/adults (&gt;40 mm length): trials can be conducted in tripour cups, beakers, or plastic cups. Scale volume appropriately. The animals should be fully submerged. </li> </ul> <p>To prepare the working solution of resazurin, prepare the following. </p> <p>This recipe is to make 150 mL of working stock. To run a single 96 well plate, approximately 35 mL will be required (allowing for extra for re-do's or errors). For example, if we are running 4 total plates, we will need to prepare 4 x 35 mL = 150 mL of working solution. Increase if more is required.  </p> <ul> <li>148 mL seawater (DI water with Instant Ocean adjusted to 23-25 ppt or filtered (&lt;1um) seawater) </li> <li>333 \u00b5L resazurin stock solution as made above in step 1 </li> <li>150 \u00b5L DMSO</li> <li>1.5 mL antibiotic solution 100x Penn/Strep &amp; 100x Fungizone - this should be kept frozen in a dark freezer and thawed before use (thaw in the dark or cover with aluminum foil) </li> </ul> <p>Store at 4\u00b0C in dark fridge until use. We recommend making a fresh batch of working stock within 7 days of use.    </p> <ol> <li> <p>Supplies </p> </li> <li> <p>Bench top incubators </p> </li> <li>Temperature loggers to be placed in incubators at treatment conditions </li> <li>Paper towels and bench paper/pads </li> <li>Tweezers, transfer pipettes, and forceps </li> <li>Dissecting microscope </li> <li>Spectrophotometer plate reader that detects fluorescence (e.g., FLx800) and software</li> <li>Plate reader filters with excitation wavelength of 530 and emission wavelength of 590 (we are currently using an excitation 528 wavelength filter with a bandpass of 20 and an emission 590 wavelength filter with a bandpass of 20)  </li> <li>P1000 pipette</li> <li>Scale bar/ruler</li> <li>Camera/phone camera</li> <li>Plastic cups, beakers, plates, or other vessel for incubations</li> <li>96 well plate (for taking readings, you will need this regardless of container type) </li> </ol> <p>Label plates with identifying number (e.g. \"Plate 1\", \"Plate 2\") or label cups with unique numbers/identifiers.    </p>"},{"location":"protocols/resazurin-assay/#protocol","title":"Protocol","text":"<p>Conduct measurements at treatments desired. We typically conduct measurements at a control temperature and a high temperature each day. If multiple treatments are desired over multiple days, be sure to run a control treatment each day as reference. Ensure you account for tank effects or other batch effects by randomizing loading order, position in incubators, etc. </p> <p>For oysters, we recommend the following treatments: </p> <ul> <li>For acute stress and survival testing: control temperature (10-20\u00b0C) and acute high temperature (40-44\u00b0C)</li> <li>For thermal performance testing: control temperature (10-20\u00b0C), 36\u00b0C, 38\u00b0C, 40\u00b0C, 42\u00b0C</li> </ul>"},{"location":"protocols/resazurin-assay/#schedule","title":"Schedule","text":"<p>Each day, the schedule will be as follows. Note that this schedule is written for a single person. If there are 2-3 people, the time frame for loading and assessing survival will be shorter than written here. </p> <p>08:00-09:00: Load plates with oysters, take size images, and load resazurin solution  09:00: Time 0 measurement  10:00: Time 1 measurement  11:00: Time 2 measurement 12:00: Time 3 measurement 13:00: Time 4 measurement  14:00: Time 5 measurement  14:00-16:00: Survival assessments and clean up   </p> <p>Note that it is critical to perform survival assessments so that you can analyze resazurin metabolic response for those that survive and those that die during the trials. If performing trials in 96 well plates or other small containers, we recommend performing survival assessment at the end of the incubation. If you are conducting trials in larger cups where you can see the animals without removing the resazurin solution, you can assess survival at each time point.  </p>"},{"location":"protocols/resazurin-assay/#load-and-prepare-samples","title":"Load and prepare samples","text":"<p>Before starting, set the incubator at the desired temperature.  </p> <ol> <li>Prepare animals for assays. Track the source tank, treatment, or other identifying information. </li> <li>Add animals into labeled plates or containers and placing them into the empty container.</li> <li>Have at least n=6 empty wells/containers at each temperature to serve as blanks. </li> <li>Write the location of wells on a plate map if using plates. </li> <li>Allocate the animals either into their designated cup or onto the lid of the plate. </li> <li>Take images of each animal with a scale bar with their identifying information in the photograph. See an example below.  </li> <li>Move the animals into their respective wells in the plate if you placed them on the lid for a photograph. </li> <li>Fill each well with the desired amount of resazurin working stock at ambient temperature using a microchannel pipette or graduated cylinder. </li> </ol> <p>An example of photograph for size measurements:  </p> <p> </p>"},{"location":"protocols/resazurin-assay/#measurements","title":"Measurements","text":"<ol> <li>Turn on the computer and plate reader. Open the plate reader software.</li> <li>Create a new protocol that conducts end point measurements from the top of the plate using an excitation wavelength of 530 and emission wavelength of 590 nm. </li> <li>Name the protocol and save. This process may vary depending on your instrument.</li> <li>Take a T0 initial measurement - this is critical! If using a 96-well plate with small animals, you can place the plate with the animals directly on the plate reader (do not have the lid on the plate). If you have animals in cups, take a small sample (250uL) of the resazurin liquid from each container, place into a 96-well plate, and then conduct the measurements. If you use this method, be sure to make a plate map of the location of the samples and identifying information. Conduct measurements for blanks and samples.  </li> <li>Put the first plate on the loading platform. </li> <li>Collect and export readings as directed in the plate software. </li> <li>Save the file as: <code>YYYYMMDD_TemperatureTreatment_Plate#_T0.xlsx</code>. For example, <code>20250128_40C_Plate#_T3.xlsx</code>. </li> <li>Save the data to a flash drive and add to GitHub or data repository. Here is an example of our files at the GitHub repository here. </li> <li>Record the time of the measurement.</li> <li>Repeat for any remaining plates or treatments. </li> <li>Move the animals to the incubator at their respective temperatures and record the temperature in the incubators. </li> <li>Repeat at 1, 2, 3, 4, and 5 hours of incubation. A minimum incubation time is 4 hours with 5-6 hours as optional time points.  </li> </ol> <p>Here is an example of the plate maps from our work.    </p> <p></p>"},{"location":"protocols/resazurin-assay/#survival-measurements","title":"Survival measurements","text":"<ol> <li>Either each hour (if you can easily see the animals in larger cups) or at the end of the incubation (for animals in 96 well plates), conduct survival assessments. </li> <li>If using plates, prepare a plate map for recording the assessments - this is an easy method to keep track of the assessments. If you are not using plates, make a list of all samples with columns for recording survival at each time point.  </li> <li>In the plate maps, you will record which wells have dead oysters. Use an \"X\" to mark wells with dead oysters. You can also record \"dead\" and \"alive\" in a list format. </li> <li>Start with high temperature plates. </li> <li>If working with shellfish, use tweezers/forceps to take each animal out and examine in a petri dish filled with DI water under a dissecting scope. Determine if the oyster is dead by placing the cup side of the oyster down and gently taping/moving the shell. If the shell is open and remains open after tapping, the oyster is dead. If the shell is closed tight or closes after tapping, the oyster is alive. Use other determination methods for other organisms. </li> <li>Record any notes of oysters that were damaged by the tweezers or record any other notes of interest. </li> <li>After examining each oyster, move it to a beaker. Discard oysters after the measurements are done. </li> <li>Repeat for all plates and samples. </li> <li>Discard of resazurin in the appropriate waste bin labeled for hazardous waste. Empty plates into a tripour and pour into a labeled waste container. </li> <li>Rise plates thoroughly in the sink and allow to dry for the next trial. Cups and materials can be re used.</li> <li>Generate a data frame that has columns for sample ID, treatments, date, and other relevant information. Add a column designated \"mortality\" and add a 0 for alive and 1 for dead animals. See examples below.    </li> </ol> <p>Here is an example of the data sheet in the notebook from our work. </p>"},{"location":"protocols/resazurin-assay/#size-measurements","title":"Size measurements","text":"<p>From the images, measure the size of the organism. For oysters, we often use maximum length (mm). Other measurements may be more appropriate for other organisms. This will be used to normalize resazurin measurements.  </p> <p>Record size from measurements of images (e.g., using ImageJ) in a data frame. See examples below.  </p>"},{"location":"protocols/resazurin-assay/#data-preparation-and-analysis","title":"Data preparation and analysis","text":"<p>Prepare the following data frames (see examples at the links below): </p> <ul> <li>Size measurements: columns for sample ID, date, treatment, and size measurement (e.g., length in mm)</li> <li>Mortality assessment: columns for sample ID, date, treatment, and mortality assessment (e.g., 0 for alive and 1 for dead)</li> <li>Metadata: columns for sample ID, date, treatment, tank or batch effects, species, well/cup ID, and sample type (i.e., \"blank\" or \"sample\") </li> <li>Resazurin files: files exported from plate reader software that contain fluorescence readings for each well of the plate</li> </ul> <p>Conduct the following analysis steps (see R scripts available for use below):  </p> <ul> <li>Read in data</li> <li>Normalize all fluorescence values to the initial time point (fluorescence at time X divided by fluorescence at time 0)</li> <li>Calculate the mean value for blanks within each batch (e.g., mean of all blanks in plate 1 at high temperature on day 1)</li> <li>Subtract the mean blank value from the fluorescence value of each sample from the respective batch</li> <li>Size normalize the data by dividing fluorescence values by size of each sample</li> <li>Proceed with visualization and statistical analyses, including testing for effects of treatment or other effects of interest and examining metabolic differences between animals that lived and animals that died during the trials. See examples in our GitHub repositories linked below. </li> </ul>"},{"location":"protocols/resazurin-assay/#data-sheet-and-script-examples","title":"Data sheet and script examples","text":"<p>Data will be stored on GitHub. Links are available below for examples.   </p> <p>Size image examples Size data sheet example Resazurin plate reader file examples Resazurin plate metadata example Survival data example </p> <p>Small seed project example: Scripts for analysis are available on GitHub here and figures of results are available here.    </p> <p>Large seed project example: Scripts for analysis are available on GitHub here and figures of results are available here.   </p>"}]}